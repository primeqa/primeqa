{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'question_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/dccstor/srosent2/primeqa/primeqa/notebooks/lfqa/generate_appen_data.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcccxl013.pok.ibm.com/dccstor/srosent2/primeqa/primeqa/notebooks/lfqa/generate_appen_data.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         info \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mjudgments\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcccxl013.pok.ibm.com/dccstor/srosent2/primeqa/primeqa/notebooks/lfqa/generate_appen_data.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39m# print(row['results'])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcccxl013.pok.ibm.com/dccstor/srosent2/primeqa/primeqa/notebooks/lfqa/generate_appen_data.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m         seen_ids\u001b[39m.\u001b[39madd(info[\u001b[39m'\u001b[39;49m\u001b[39munit_data\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mquestion_id\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcccxl013.pok.ibm.com/dccstor/srosent2/primeqa/primeqa/notebooks/lfqa/generate_appen_data.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(seen_ids))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcccxl013.pok.ibm.com/dccstor/srosent2/primeqa/primeqa/notebooks/lfqa/generate_appen_data.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# print(seen_ids)\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'question_id'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from glob import glob \n",
    "files = glob(\"/dccstor/srosent2/generative/appen/round2_jobs*/output/*json.zip\")\n",
    "#files = glob(\"/dccstor/srosent2/generative/appen/round1_jobs/*json.zip\") #[\"job_1999101.json\",\"job_1988758.json\", \"job_2004889.json\",\"job_2006984.json\", \"job_2022794.json\", \"job_2035917.json\"]\n",
    "\n",
    "seen_ids = set()\n",
    "\n",
    "for file_name in files:\n",
    "    # file_name = \"/dccstor/srosent2/generative/appen/round1_jobs/\" + file\n",
    "    data = pd.read_json(file_name, lines=True)\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        info = row['results']['judgments'][0]\n",
    "        # print(row['results'])\n",
    "            \n",
    "        seen_ids.add(info['unit_data']['question_id'])\n",
    "\n",
    "print(len(seen_ids))\n",
    "# print(seen_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "def load_json_from_file(gt_file_patterns):\n",
    "    data = []\n",
    "    if gt_file_patterns.endswith('gz'):\n",
    "        f = gzip.open(gt_file_patterns, 'rt', encoding='utf-8')\n",
    "    else:\n",
    "        f = open(gt_file_patterns, 'rt', encoding='utf-8')\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        data.append(json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tydi json\n",
    "import glob\n",
    "import spacy\n",
    "\n",
    "# spacy.cli.download('en_core_web_sm')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "train_data_dir = \"/dccstor/srosent2/primeqa/data/train/nq-lfqa/*jsonl\"\n",
    "dev_data_dir = \"/dccstor/srosent2/primeqa/data/dev/nq-lfqa/*jsonl\"\n",
    "\n",
    "train_files = glob.glob(train_data_dir)\n",
    "dev_files = glob.glob(dev_data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for train_file in train_files:\n",
    "    train_data.extend(load_json_from_file(train_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3393\n",
      "941\n"
     ]
    }
   ],
   "source": [
    "dev_data = []\n",
    "for dev_file in dev_files:\n",
    "    dev_data.extend(load_json_from_file(dev_file))\n",
    "\n",
    "print(len(dev_data))\n",
    "\n",
    "def is_majority_type(types, type):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for t in types:\n",
    "        if t == type:\n",
    "            count += 1\n",
    "    if count >= 3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "seen = 0\n",
    "not_la = 0\n",
    "seen_dev_ids = set()\n",
    "dev_data_la_ids = set()\n",
    "\n",
    "for example in dev_data:\n",
    "    if not is_majority_type(example['type'], 'la'):\n",
    "        continue\n",
    "    dev_data_la_ids.add(example['example_id'])\n",
    "    \n",
    "print(len(dev_data_la_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/dccstor/srosent2/primeqa/data/train/nq-lfqa/nq-train-tydiformat4.jsonl',\n",
       " '/dccstor/srosent2/primeqa/data/train/nq-lfqa/nq-train-tydiformat2.jsonl',\n",
       " '/dccstor/srosent2/primeqa/data/train/nq-lfqa/nq-train-tydiformat0.jsonl',\n",
       " '/dccstor/srosent2/primeqa/data/train/nq-lfqa/nq-train-tydiformat1.jsonl',\n",
       " '/dccstor/srosent2/primeqa/data/train/nq-lfqa/nq-train-tydiformat3.jsonl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61499"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12957\n"
     ]
    }
   ],
   "source": [
    "# get annotated ids\n",
    "import pandas as pd\n",
    "\n",
    "annotated_data = pd.read_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_single-12.20.23_wbool.json\", lines=True, orient='records', dtype={\"id\":str})\n",
    "\n",
    "annotated_ids = set(list(annotated_data['id']))\n",
    "\n",
    "# for i, row in annotated_data.iterrows():    \n",
    "#     if row['output'][0]['meta']['non_consecutive'] == False:\n",
    "#         annotated_ids.remove(row['id'])\n",
    "\n",
    "print(len(annotated_ids))\n",
    "annotated_ids = list(annotated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# part1 == also 2000?\n",
    "# up to 19505 to get part2 (2000 each)\n",
    "# up to 30209 to get part3 (2000 each)\n",
    "# up to 41213 to get part4 (2000 each)\n",
    "# up to 53351 to get part5 (2000 each)\n",
    "# 64067 part6 (2000)\n",
    "# to end part7 64504 (175)\n",
    "\n",
    "dev = False\n",
    "bool_only = True\n",
    "\n",
    "from statistics import mode\n",
    "\n",
    "def is_majority_type(types, type):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for t in types:\n",
    "        if t == type:\n",
    "            count += 1\n",
    "    if count >= 3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_majority_index(annotations):\n",
    "\n",
    "    candidates = []\n",
    "\n",
    "    for annotation in annotations:\n",
    "        candidates.append(annotation['passage_answer']['candidate_index'])\n",
    "    max_cand =  mode(candidates)\n",
    "    if candidates.count(max_cand) >= 3:\n",
    "        return candidates.index(max_cand), annotations[candidates.index(max_cand)]\n",
    "    else:\n",
    "        return -1, None\n",
    "\n",
    "def get_appen_data(data, type, exclude_ids, output_file, start):\n",
    "    f = open(output_file, 'w', encoding='UTF8', newline='')\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow([\"question_id\",\"question\",\"title\",\"url\",\"long_answer\",\"minimal_text\"])\n",
    "\n",
    "    count = 0\n",
    "    index = start\n",
    "    lines = []\n",
    "    excluded = 0\n",
    "    for example in data[start:]:\n",
    "        index += 1\n",
    "        # if index >= 19505:\n",
    "        #     continue\n",
    "        # qtype = example['type'][0]\n",
    "        \n",
    "        # if qtype != type:\n",
    "        #     continue\n",
    "\n",
    "        if dev and not is_majority_type(example['type'], type):\n",
    "            continue\n",
    "        elif not dev and example['type'][0] != 'boolean' and example['type'][0] != 'la':\n",
    "            continue\n",
    "        \n",
    "        example_id = example['example_id']\n",
    "\n",
    "        if str(example_id) in exclude_ids:\n",
    "            excluded += 1\n",
    "            continue\n",
    "\n",
    "        question = example[\"question_text\"]\n",
    "\n",
    "        q_word = question.split()[0]\n",
    "\n",
    "        if dev:\n",
    "            position, annotation = get_majority_index(example['annotations'])\n",
    "        else:\n",
    "            position = 0\n",
    "            annotation = example['annotations'][0]\n",
    "        \n",
    "        # already done or no agreement on index\n",
    "        if dev and position <= 0:\n",
    "            if position == -1 and str(example_id) in annotated_ids:\n",
    "                print(example_id)\n",
    "            continue\n",
    "        elif str(example_id) in annotated_ids or bool_only and annotation['yes_no_answer'] == \"NONE\":\n",
    "            continue \n",
    "\n",
    "        if annotation == None:\n",
    "            continue\n",
    "\n",
    "        minimal_text = \"\"\n",
    "        if annotation['minimal_answer']['plaintext_start_byte'] != -1:\n",
    "            minimal_text = example['document_plaintext'].encode('utf-8')[annotation['minimal_answer']['plaintext_start_byte']:annotation['minimal_answer']['plaintext_end_byte']].decode('utf-8')\n",
    "            continue\n",
    "        \n",
    "        passage_offsets = example['passage_answer_candidates'][annotation['passage_answer']['candidate_index']]\n",
    "        passage_text = example['document_plaintext'].encode('utf-8')[passage_offsets['plaintext_start_byte']:passage_offsets['plaintext_end_byte']].decode('utf-8')\n",
    "        \n",
    "        passage_sentences = \"\"\n",
    "        sentences = nlp(passage_text)\n",
    "        \n",
    "        num_sentences = 0\n",
    "        for sentence in sentences.sents:\n",
    "            num_sentences += 1\n",
    "            passage_sentences += sentence.text + \"&nbsp;\"\n",
    "\n",
    "        if num_sentences <= 5 or num_sentences > 50:\n",
    "            continue\n",
    "\n",
    "        if example['annotations'][0]['minimal_answer']['plaintext_start_byte'] == -1:\n",
    "            print(example['annotations'][0])\n",
    "\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "            print(index)\n",
    "        if count > 2000:\n",
    "            break\n",
    "\n",
    "        writer.writerow([str(example_id), question, example['document_title'], example['document_url'], passage_sentences, minimal_text])\n",
    "    print(count)\n",
    "    print(excluded)\n",
    "    f.close()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotation_id': 1656017641967908910, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 126}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12303299547654541082, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5930037986053518599, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 971602403605155409, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 69}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13750017001613321741, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 132}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4026421058131660642, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4612914453625035998, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11314162411821442880, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10510279887805739831, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 677212877709130315, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4835465100708612044, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 222326308022059421, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3387348111857870092, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 38}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11887686856488289052, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13208788718356547059, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7422662855613640298, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10510379772988359516, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12867486417362320458, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16392616983090021223, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15421109645553143334, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7274896220269395995, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17691872719144818501, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 67}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3371173031346805628, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9182990316533886399, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 448}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 663770030400756033, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18190400907681843633, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10548721829709015815, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4874200150826549476, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 855343370950705324, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3519796488778897154, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9585899263222571695, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8224830337791193635, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 980043119666701551, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 129}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5412634448195176893, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16206855724646924118, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5247389293400576474, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 62}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5747084545008268997, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15666079458984030602, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7877782812327752840, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 47}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9365941506559758103, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 153}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17748386625418235469, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 72}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6184077643541869810, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8616890291144209917, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 8}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2443100080490462399, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12461534191531635225, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 15}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16177505660182915254, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11644150625470849650, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 15}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1591777160806272249, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3787879751347564775, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5775205772308631616, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 56}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6271157883442109704, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17725171231096320246, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6027692611765049412, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5343504472740988761, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10003498029746812707, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 67}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12890232445145328169, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11802725679410056387, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 49}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 377059404826800961, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8249051211250445676, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 468911124885014693, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 48}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10543661390309101515, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9094754707009593139, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 72}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3097442061044533248, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 61}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7579233605266292063, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 53}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15482829804469014638, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 125}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16178446674602679807, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14770870335334780317, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 5}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12585510437982518979, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2874404235110326887, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18361038650735874905, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10426633583689885907, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 176}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14076237243877830914, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15071736341919962810, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4335931259368581273, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13421534361310598724, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7371837529366769711, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 45}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3531776250922954976, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10665548797509724524, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 66}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17831973900287483887, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 48}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10486611543270210302, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 34}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3718044556927145538, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 25}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10510006843793858559, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14888037042182068587, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8134958062763103904, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9572128127396237304, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2957901792939136551, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 36}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2608434307561098630, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 84}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5668089100907739824, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 69}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2912186139803327400, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 265541613346027569, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 47}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12224825077991943041, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 34}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3559894783556555489, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14471122668978522651, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6434616297771818505, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7763741271220798061, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7335424312501863659, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12586699357785827573, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 58}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12852678299634938052, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12660529193441848396, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 54}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11022722792514777168, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'NO'}\n",
      "100\n",
      "6718\n",
      "{'annotation_id': 18361730815472540022, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2086957577307481300, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 97}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3545527522619964867, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5521297147722275031, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5628537722402487033, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10602306665338471521, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 115}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14049529591290644924, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3591353410948660116, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 410967225502373692, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 529115846743877783, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8087201233200004376, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16132611483693141094, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15392231799208330479, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 46}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2954274097413109200, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6820220231649469498, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 25}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15929181698466039215, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 85}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8750533819212611627, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8754850455802531317, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 15}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15413670930949449382, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11956436306786785493, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12696240925924639328, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15460202235540633356, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9010435052252781427, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 50}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5995466042456895655, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 61}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5435050011956006679, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15094169582591950811, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8833813466636856411, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 64}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15713964403940788433, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2994719805043879255, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 67619900516146859, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5206848810506875684, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7141548342296520295, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5855802545558631014, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 62}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13168674308808027907, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5787448266740211075, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10656976880285271582, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 50}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9598304275279590618, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13314955862433807730, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12080436091490426253, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 93}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5266285763958150070, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17164583028276363362, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13875591300492924372, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1272815562395462847, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 51}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 497978451106908176, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9738112896368614533, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5092381415339446245, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 125}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15997744775941280538, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 96}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18432843861088409528, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 18284028578212536407, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 64}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5403624031777419641, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11963015546938311389, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 54}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7174195764550476651, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3258568125901913290, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3498360007613376346, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 69}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4762785975143636821, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 368}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5930255638052733710, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 89}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6309358262935352082, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6122386012266527403, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14176794334131563991, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 45}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3823688900910488466, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14879562539212831588, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5499677784729331457, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 54}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14934717391801159833, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15849315824768276213, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 45}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 861728812311827747, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5276801147677130159, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1773955780869188829, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9707812132448233788, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2999191970599591141, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 42}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18434491614415811724, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7202053397122668998, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10147731016695708131, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8845555361681705301, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14232650115816500042, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3065316446299387015, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13149494774959977515, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4585300534603661003, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 49}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12435439652094604700, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 80}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16144826121289352407, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8868889219615056089, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6110885089509683030, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 316647353610982754, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 56}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11911814937906137364, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 34}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10374433375009981201, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 713592147400653224, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 66}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8910957493293913409, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 60}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13879656436372336932, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 196}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 579792300226208503, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2168799024732898875, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8709777449166772163, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13309615638545784867, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 63}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18291541498105206623, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 214}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14448819378601579410, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1534477925533403886, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 52}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17294949813957919645, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2218572312956555652, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14140200420723038940, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4648063346808660903, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2114139859043044047, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 40}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2657537134477606044, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 46}, 'yes_no_answer': 'YES'}\n",
      "200\n",
      "12946\n",
      "{'annotation_id': 9978456317455149731, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8269454190628106864, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 49}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16901732737139133111, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2787020914199603973, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17439130352406964124, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13559644234796823653, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4092303765454403776, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2208383060393751572, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 469}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13672457197057778319, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 53}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18064525820345318695, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 41}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6666924648019113263, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 42}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16548268879117043710, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 78}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3349761183006740846, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16643086826123932207, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 5}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9102082686127767937, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10617584860336563670, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9926924775623968962, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 82}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17746175158884458583, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11960161087571517247, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18107224965861096795, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11017929503242039141, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7553259219367489830, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 54}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10344870169217091897, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16618186471805790926, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8342840617451850585, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 34}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17770341353461347838, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17013517390933446882, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 50}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1271495304671838098, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 118}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15597907547179979247, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 91}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17412268981122589590, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13968051799228625956, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12804759323708579171, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9767438468894480205, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 148}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7271854020061677418, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8222582470047192245, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14795004943668310232, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 8}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7743190020425835460, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14217849273044342916, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10295320185604312437, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 36}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7517994227608425757, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 90}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17498777168450049059, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 88}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18113752780944348480, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3953333799247968774, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10046495303427930692, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 36}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1639669371431654391, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 52}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4879922286194827656, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15130942226338631097, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 5}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5398491721030714516, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14634644226846922701, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14943920315294651332, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16296636907672718582, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3046069563515857055, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9281300797953771637, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14442876673512654532, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12868837572898913765, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 244}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14454474602159482869, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10919824241062857711, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17767699560357845657, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 43}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14281206895221353952, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 118}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14851549854914936179, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9384331661183972131, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17819556359982845782, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 81755647483732285, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15256382443300383186, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12016070584547711676, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 38}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10908594103947341626, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8606041256161920029, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9022440164516619387, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 45}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8809100317720114434, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18338967497757161696, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18394742617547374944, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14262740888096088882, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15099728665042706055, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11186922797188158376, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11206107117362425225, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1871008715912816060, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17749104225168813118, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12193130157127434494, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3323231529632765898, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 68}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 18334571288438077414, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14751880814255797610, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 150}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5845320002218944388, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 40}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9322340254891059965, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 45}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 363107121434133125, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9318410434868879953, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16639775110437672745, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 910231869365766278, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6004733297625215475, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9329064407765360234, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14413064913590494491, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11139125048707404204, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10977159875461317605, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17056484532112286627, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9429794657455491871, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 60}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6582354759739284893, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4125689165293709645, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15519574271794154503, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13075582973750308270, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 38}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7285161567291097795, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14050852021677576074, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 43}, 'yes_no_answer': 'YES'}\n",
      "300\n",
      "18488\n",
      "{'annotation_id': 11971463105516485952, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1959357562702813497, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 15}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1198242247451843719, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13255244246891527902, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 949865842903143712, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1928297200735787605, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6712626183616419288, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 8}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3689754239915245815, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11081547326839220244, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4592613919877155113, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15416733647621754939, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10677502681849714900, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6473116001705322670, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6729080602859023074, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3905577564513176061, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 15}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17882699005208172731, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 39}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13984391665512830648, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7151487250068856271, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 630754994798218584, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6468633553940021994, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9646490873101066694, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17707892071583377356, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 87}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10951439701611782394, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 167}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8023105307365762734, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11098618789548968289, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14553784963997261090, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7254973461188287742, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 451989467959836880, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12125575852780562952, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 103}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15733066038785185988, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 469}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11059000201191648293, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 182}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8370302126102764495, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11415555149505199356, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 288425226797088291, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 629466774883121060, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7402294630754687141, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 47}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15846768211558796337, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 63}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6241418795771333024, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 595818584224378162, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 45}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 416227308298517330, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15363388499995345467, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3410565470109213467, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8971274770552615657, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 784083931259456876, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 704443152870676913, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11002253804146583318, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 45}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4633163771128999581, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 39}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14944870723054850626, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15681087491703781491, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 95}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5104339298925318489, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13831056092682507278, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18080241334882858242, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11718766959673777102, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9053562502997409881, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 651995941600483451, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12862271759584130746, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14349073415153523059, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 305436086178016777, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 48}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14968142329879758872, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 70}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12550586093980150375, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 96}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8094578093650389144, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12170508243244890772, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 25}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13518686896715101805, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8952065412528237517, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 100}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6374578334653462661, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15599237235656320857, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7645774626374458256, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 54}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4797419621661672430, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9552846195493903450, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 65}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6385359460627361168, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15706611703907758041, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11279588383278434175, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3331398760919128722, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 38}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8177997560424943113, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18043875733786632437, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8459853853394812482, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7016676666743399721, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18055762226651029526, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5752804860228448949, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15789401005741281616, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 357}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9166737759467627427, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1159281093692904187, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6566495250241330020, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 263}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6609153432398553262, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9287896843983196286, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 34}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2130310320494335605, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12824826160461829080, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 43}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17091571593630606929, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 34}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3962838256155010754, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 73}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7087670442721218746, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2567960635815922483, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11657969170067663460, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 473717021919341466, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 38}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6699836540866279690, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12459819803141275873, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6410066514731141172, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14663761074351106242, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17976823766762179588, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 15}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7583423837346199792, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10948908535138464990, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'NO'}\n",
      "400\n",
      "24668\n",
      "{'annotation_id': 2600961841380472817, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7907777817782272324, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10764545493150251636, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7876368090857424870, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9858808829659096079, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6721171701347412139, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8790380568340509936, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 104}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13458152582164082532, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 575984336319993078, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11981201165449801803, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3741656327513248015, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16782462392226279694, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 34}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8813773197822508517, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3792672109184685554, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16999630876865900578, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7264708891606414619, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 40}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3155306540428884542, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 73}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17374371246633821095, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 113}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8771494462039173126, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 56}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1534117630071060163, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15450555456341307636, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6713338460863627614, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9224222384681893398, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 677291384936353193, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 72}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 105320002239593188, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2592885931851227333, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4424517351055563320, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 34}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4772222959764631440, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16107048478386087436, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14834143894664139034, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6367035256500127456, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 686472161502508575, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13806299488346988428, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3162894406669577579, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15450623443630366315, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9454720947368653935, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17654290161186645221, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 313185738663951775, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 95}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5642200037494709507, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 66}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8218335582686172726, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 228166308787163276, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1509396992112799672, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7360804574666636440, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 41}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9541131630531050738, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12491273767748760896, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 175}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13034093902676091750, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17007190446007999386, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3261030915154908384, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 46}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15573409070783749587, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11447329915420048030, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9155734994733200113, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 131}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15932801782114013815, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12664799734773339347, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1457842933899907602, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14424114400194897463, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2886128672407957766, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17210804852841061563, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15193995267880498927, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6912391063077223979, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2479559601912646334, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 861048691444725292, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1263357940779241262, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18426913112359397490, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4578049886034192351, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9198701472362671934, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 554410781954674957, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13684915947443059190, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15040218006314348191, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3539620875025182343, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 36}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16326047602556793183, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15330613347802298522, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14000953943229023836, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4837046756252545228, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10088036688943705231, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10285067897145462498, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 56}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9987932954598055996, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12032222781402270855, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 25}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2965767182868791221, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 959474492894234965, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 93}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6182426443837490759, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16290066264198698724, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 173}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16282476860641980434, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7383106016079470509, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1352305613071627246, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14656460912796008317, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 53617326798563019, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13917048610093437226, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1679852646985610414, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5918278941423494794, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4958813532319885451, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 61}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2116485540961257235, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17713503533275673614, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 994038132610524256, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15418227647265302871, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 84}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17706231688122993513, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4569327730464196793, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13512192892447456433, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12526613558299849373, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15274447367707190684, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 52}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15291108974902724532, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 81}, 'yes_no_answer': 'NO'}\n",
      "500\n",
      "30635\n",
      "{'annotation_id': 7359254653027490651, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 898112707852738803, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11011108594141882384, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10922043153691360000, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7858983574966453401, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 25}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6535878726107541789, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13585781075813836016, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1002051009720525492, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12308409092649398684, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6527121842406507708, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 66}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9582312939897394612, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10900234988882907971, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6855386743974487101, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9058245062055251438, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12553381911879432022, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5677268507646767587, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10067115143026055166, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5508679199336407332, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5677606096113442412, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 827011198462756676, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2420875225885247288, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6370110290101888859, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11293632144360667467, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 52}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3381924624203165072, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 43}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7772975428155142061, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12059354648949930441, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8658063990852640232, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 60}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8954628247609326966, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 47}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2365554207304679661, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2430284405808693383, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 15}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2586161870511682842, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 786182014574856631, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5022778931373656002, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 272372448672163555, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 36}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16619356040226092283, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12970111704016284893, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2021876669499168297, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4915439145288284669, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 144}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11509290636767664772, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3504982191273878421, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2498281613000860653, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14551398549126786304, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8692836602370730270, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4212988944619012728, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 106066765663150950, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 8}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4541185866193572860, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10984060105956766951, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 74}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 723707080411479415, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 62}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10627553348395784108, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10118254302791786428, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12230720851044413806, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9603007559678932837, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 110}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1291223336054583437, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17031844214920864959, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6840100620425996256, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15609902795652663936, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 73}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 18378503096955462249, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 48}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3423013027907643527, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1707330308908837913, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18386790485252674296, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4549693640674942167, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 5}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1868759802689305057, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 57}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8437342705293296758, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13414204247145897711, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9953453752551968383, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7868429275269854896, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16205199007928524428, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 15}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17790992896355208880, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1366698933681668754, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10319297988521992765, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 183901050272302194, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7176062182325383213, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10853448398945160658, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 65}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6700856295721674407, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15656604342585581418, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 82}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 617249316421871971, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12499933693073253042, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3316843647970776538, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7547437406208870411, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2340406523427513962, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9767632924048383064, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15518047201499491299, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2693434190224718907, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18059124278076128703, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1588029798628768457, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 56}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9561931018378288943, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 41}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15780304929234652661, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 136}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4035049091468305143, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 15}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13669093157192067075, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 90}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10349762303679688861, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4360248113047613203, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4018829240745610120, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3648984325943387613, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17973897183991602757, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10566798179279952270, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6041637974726689273, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3818677558932793965, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 40}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16837326781696475751, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16322596567890119448, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 61}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9244453519750339409, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'YES'}\n",
      "600\n",
      "37570\n",
      "{'annotation_id': 15421928518287559273, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1867751918216181566, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 361}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2484882456058329430, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8020543523987428153, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8236363239224248578, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18256561190612317746, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 62}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 80811388823729106, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 62}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1242758769840921877, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 5}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6546150314246052963, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16191992670089355125, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9540169731733781107, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14925595409040498081, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15561892962553622243, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4347116145350183585, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 539544380645911002, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 24}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14439246158685398943, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 58}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1634272022750758312, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 49}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12273255628783749674, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 57}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 970839832214852828, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11276796312097479719, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17455604792769272250, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 38}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7767274912639772494, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15975863457835247747, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16695525541960282287, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9234540479108269595, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7862636300986909974, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4083326886982550329, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6129210730264861140, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 42}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1142364705255644304, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5528128972950606719, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5431503133164451186, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14538870506518643808, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3074256377990088963, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6352277119660250854, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 65}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6209913687210963292, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 25}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3303554092851808184, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8473375542238062618, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15133808074671828175, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16121043612361140884, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5257086669495338965, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7693750108617465583, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 97}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16076121650467803057, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16051566416881131224, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13402829203929552646, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 50}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5923807020930241909, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8801428673618588565, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15978717669720145940, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18048738111094111463, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7789411694272811726, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5413299109543673671, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2960201785470548343, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9210519251002818683, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8397865180449997571, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 56}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9047791001896528305, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 120}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3112348119296134200, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 55}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5146278874619699156, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5342797275943727038, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 5}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 777496089483041496, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1895769211499054783, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9422894450031584790, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12141616583552862953, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15110912642246183047, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17791247575933390240, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 54}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3631785984644681237, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1625091300161292248, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17739670787744380735, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 63}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5385387954374431788, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10735176032908185464, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 40}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6915505923455021005, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9518233674982701549, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7763363054569489949, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16314998271173913591, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2595394665548080464, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17200283500938851279, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 46}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11017553191799815822, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3366560464660645485, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9629169207051995101, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11797134452515695196, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12254199465667585555, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3331344850227943032, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14521182123645965667, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6923837248806357604, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 65}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6912770497892303083, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9926149969654787669, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16715646448111915382, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15884828665492220900, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14573849664030568970, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4695784689673982316, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 40}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11900220491017066558, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14814489937313116354, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6708628840168659364, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9730286220606248333, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 5}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12787177527358639214, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13534978141564870139, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6410851684715036138, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 51}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8696610880407054434, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1052897553140585135, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4583864483440210450, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6359811509503500497, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 41}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12935454720526424201, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 122}, 'yes_no_answer': 'NO'}\n",
      "700\n",
      "43320\n",
      "{'annotation_id': 4967199208342434934, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3556139696768618646, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4890418319463771153, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5347575452779053591, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2854831015595978575, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13381459054737847772, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15527619980201729960, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16215357381682614809, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12907020712089054160, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 135}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3082700970027619998, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1628325518962856132, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17740084681683310786, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17773809431272290432, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17748888229840222779, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6630298631294132256, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 68}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3212769729908127381, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6643844754621001290, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 90}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1225884074881719583, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11248052079029935184, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16124543627184694396, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 71}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10026371458880307978, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12534439849481755666, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1597186341744841287, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 94}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1541692091709471945, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 8}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4240975991811157477, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9244787734811494762, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3673823929733218278, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11446505819706154152, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 8}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14656717021686192982, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 44}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 968981775629439411, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 42}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2842845599814384630, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17993756684410552069, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11171957502132045634, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 49}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14931331379572027254, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16667449723529111180, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4630451307811897197, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15932332734849471627, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13199370537702778392, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 5}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8158540979362581071, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16220983366905730366, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4666290136251065349, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17661701850666848097, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11556842016795439573, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 61}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10950036588945849152, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8098498546231693471, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5077908125147004057, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17579355993497682489, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14665803181217535009, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16198084610623447513, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1578748862544860738, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 40}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3954167017347347540, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8297070872842339088, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6894180125041427640, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16483357979413989701, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16813527245758211675, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5545003499558504057, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 60}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1762976171271830404, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14069677522418265479, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17293056418797477584, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11564965528566417697, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6430346315708788998, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2747013733165747080, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14412779424629018229, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11554846959986643343, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12992741646192714614, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 59}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 993484387715050383, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 36}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15434899730781674806, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7149974698866129897, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12706084513230214099, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 48}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4885943531997144728, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 18032268365366123303, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17084917286551362921, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15679567794703519944, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 69}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11210058137898894393, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 50}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1104799726101297690, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11637485548810168344, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 60}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4064322340022494218, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15456871805844410225, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 39}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11092704508955619047, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 37}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7314594362304707488, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3599398786372287989, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 555466820666539591, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7359245991641266442, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8579711207922950424, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15608106095254327714, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 5}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14088703531308809841, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 38}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15324196057347027375, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15625054826504589463, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 8}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13711652716613538966, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 201}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7254248922294338305, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17328113397608152305, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11711195604722857611, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4948264915557101737, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9847394148869973469, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 98}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5375872782250599102, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18247717558419555541, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 43}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13912431797438473054, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 52}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17110986197531759262, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 59}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 18065541245976186833, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 41}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14182159110953622287, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'NO'}\n",
      "800\n",
      "49324\n",
      "{'annotation_id': 11817088965148070013, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17069901008677828275, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 387874189496001417, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 486363871615514550, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9894338791284430827, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1395501610474308039, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4480947762713282638, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16422604322106225270, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9729661907322583113, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2247492023209689991, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8394832972999086429, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 60}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14504041236247356804, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 75}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17589498470826701630, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 44}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7290475054082796232, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9585053034676090368, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1033554758151011476, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 70}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1319113942468975504, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8124350980695763971, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 105}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4192992262214331355, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 25}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10418546738687829924, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4770319576538151846, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8422395957359403421, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 857407634768729621, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 91}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15011135474622855809, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2680216734841609316, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1006963555650863441, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10621372448592279788, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12247636355429674893, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 18112776734892644026, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 34}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7258146205031895165, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18236977915647215121, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17357178201168810097, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18351415134110935500, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13775171567121578687, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1956616042918400775, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 288}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 130261831207178265, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10242746282221482744, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14757173053832569051, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 41}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2378558028428664338, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 92}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10728882969904316715, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 10368907908261995993, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12024816531599107585, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2838794173711705790, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1508409189924826934, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13185187973422035305, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 620}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 5250532222125509999, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 39}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6068448113010260844, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12427251613842366944, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11000174774608966350, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 63}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12078973906839326201, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 75}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14479205062499812098, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 49}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3655798243112419511, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9355275448492408599, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 40}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9617820630238085806, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15140744738895724179, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 532919185788773044, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9510076305565905426, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 381}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16746637710656026818, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 5}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10623900410290243253, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 21}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10162370218648056313, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10661916957704307061, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9362195735214218851, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14845583346113205549, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10391145546082602338, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5866662503146233183, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 14}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16408910883348063079, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 42}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15309634687943443654, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 1936668107444014985, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 86}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13805193738154058661, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7828549566619499071, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3902031843968027434, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 495153247485073482, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 17135511696149250289, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9616910441500163497, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1625152709017749547, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 56}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6984003362854260340, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4313244955672616665, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3832978760070615717, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3195273769142644466, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 75}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9965247874400972996, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6111742698611542804, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5817531086692227153, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11038260756044664835, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1281723271113547172, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 151}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13029167530809282147, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10263041420745431057, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17272800593239643024, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 45}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15381332948442059594, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 42}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 331315428952095460, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3621371946963283668, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10891776128647538812, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6965801371691938307, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 47}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 4868253697095965179, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15293510981450170573, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4324214773574185405, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11099262363507785897, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 17}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 3860923017517664102, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2915716328616977243, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2023142787174021707, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 9923072367403257549, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'YES'}\n",
      "900\n",
      "56721\n",
      "{'annotation_id': 4159296396137417752, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2580254113616440442, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17176578775131681253, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 25}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 13465982638546574730, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9334693856075935631, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 64}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2054346966246246712, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14155744709556072064, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3124032207264740877, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17097071848249995084, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10744815759798479580, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 15}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16611228933409477173, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1850904294629578939, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 18}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8984752767058777058, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 20}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17401953537107362779, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7134867252372781376, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10239182930852830560, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10373449226116114187, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 4}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12877806613163233129, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 29}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17416319939967446548, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13328441480653479440, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4126344459705930189, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 68}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16634609313771087252, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 8}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 8994189202273699442, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 30}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 438332020787792655, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14112523793999689342, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2887503640551585657, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12726626659607102181, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 13}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6709917049353311585, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7513874992480853965, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17167070533784664545, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2038826558786020319, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 253}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 11894256937102700754, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 70}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7016248430176931945, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 39}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15968518484718557722, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16477046236800883316, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10479606634644224008, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 17160456746189562813, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 15501799047483206570, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 2}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15588377339539060024, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 22}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4872525317319130686, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 11}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 12764486535333193189, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16481166079997108288, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 8}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 337953843226342123, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14255248626879480034, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8224198442536084015, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11522709411984281523, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 12}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 9503318536346240430, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2106240153185852054, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 11862051040594778685, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 16031942570501391593, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6595822117425956571, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 3}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1167248715888265486, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 16}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 1670298030930120669, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 9}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 7092429227717059695, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 33}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 2545926775220030658, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14350452340867226004, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 47}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4537784512546918222, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 7}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 7990074910468572451, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 28}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 16041576084451050785, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 31}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 6582732847402974836, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 19}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 10992616677922103854, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 106}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 2057381273906762672, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 26}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 3533620141600602282, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 122}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13383445250214969240, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 6}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 18312999997761660368, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 15064859013341950119, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 27}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 18372326644196291423, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5229560221917896974, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 54}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 12713011820902825249, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 4772721875655918917, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 10}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 14909387470450417024, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 43}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 13459465276708515859, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 23}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 6795598576694551692, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 35}, 'yes_no_answer': 'NO'}\n",
      "{'annotation_id': 5886228479337643021, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 1}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 14222982915779231827, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 0}, 'yes_no_answer': 'YES'}\n",
      "{'annotation_id': 8586573520953730590, 'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1}, 'passage_answer': {'candidate_index': 32}, 'yes_no_answer': 'NO'}\n",
      "976\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "get_appen_data(train_data, \"la\", seen_ids, \"/dccstor/srosent2/generative/data_for_appen/full_nq_task_nomin_train_boolean.tsv\", 0)\n",
    "seen_ids = {}\n",
    "# get_appen_data(dev_data, \"la\", seen_ids, \"/dccstor/srosent2/generative/data_for_appen/full_nq_task_nomin_dev_notfirst.tsv\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input</th>\n",
       "      <th>passages</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>-7208598982885375738</td>\n",
       "      <td>when did australia day start on the 26th of ja...</td>\n",
       "      <td>[{'title': 'Australia Day', 'text': 'The meani...</td>\n",
       "      <td>[{'answer': '26 January 1788 marked the procla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-8135288146662086849</td>\n",
       "      <td>where is india located name its neighbouring c...</td>\n",
       "      <td>[{'title': 'India', 'text': 'India ( IAST : Bh...</td>\n",
       "      <td>[{'answer': 'India is a country in South Asia....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>8715745057149579179</td>\n",
       "      <td>where have the detroit pistons played the last...</td>\n",
       "      <td>[{'title': 'Detroit Pistons', 'text': 'The Det...</td>\n",
       "      <td>[{'answer': 'The Detroit Pistons are an Americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-34625453215101117</td>\n",
       "      <td>what's the difference between buttermilk pie a...</td>\n",
       "      <td>[{'title': 'Buttermilk pie', 'text': 'Buttermi...</td>\n",
       "      <td>[{'answer': 'Buttermilk pie is a custard like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>-4800726608572882679</td>\n",
       "      <td>is rogue one an official star wars movie</td>\n",
       "      <td>[{'title': 'Rogue One', 'text': 'Rogue One : A...</td>\n",
       "      <td>[{'answer': 'Yes, Rogue One is a Star Wars Sto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                              input  \\\n",
       "1599  -7208598982885375738  when did australia day start on the 26th of ja...   \n",
       "297   -8135288146662086849  where is india located name its neighbouring c...   \n",
       "352    8715745057149579179  where have the detroit pistons played the last...   \n",
       "171     -34625453215101117  what's the difference between buttermilk pie a...   \n",
       "1039  -4800726608572882679           is rogue one an official star wars movie   \n",
       "\n",
       "                                               passages  \\\n",
       "1599  [{'title': 'Australia Day', 'text': 'The meani...   \n",
       "297   [{'title': 'India', 'text': 'India ( IAST : Bh...   \n",
       "352   [{'title': 'Detroit Pistons', 'text': 'The Det...   \n",
       "171   [{'title': 'Buttermilk pie', 'text': 'Buttermi...   \n",
       "1039  [{'title': 'Rogue One', 'text': 'Rogue One : A...   \n",
       "\n",
       "                                                 output  \n",
       "1599  [{'answer': '26 January 1788 marked the procla...  \n",
       "297   [{'answer': 'India is a country in South Asia....  \n",
       "352   [{'answer': 'The Detroit Pistons are an Americ...  \n",
       "171   [{'answer': 'Buttermilk pie is a custard like ...  \n",
       "1039  [{'answer': 'Yes, Rogue One is a Star Wars Sto...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load final data and split into train and dev\n",
    "import pandas as pd\n",
    "\n",
    "annotated_data = pd.read_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_multiple-12.20.23_wbool.json\", dtype={'id':str}, lines=True)\n",
    "annotated_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3393\n",
      "['-6570496346595660652', '4111902318448915849', '3599421094587589904', '3367999921663366204', '-2103986527722712835']\n"
     ]
    }
   ],
   "source": [
    "dev_ids = []\n",
    "\n",
    "for item in dev_data:\n",
    "    dev_ids.append(str(item['example_id']))\n",
    "\n",
    "print(len(dev_ids))\n",
    "print(dev_ids[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2542\n",
      "67\n",
      "2475\n"
     ]
    }
   ],
   "source": [
    "dev_annotated_data = annotated_data[annotated_data['id'].isin(dev_ids)]\n",
    "train_annotated_data = annotated_data[~annotated_data['id'].isin(dev_ids)]\n",
    "\n",
    "train_annotated_data.to_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_multiple-12.20.23_wbool_train.json\", lines=True, orient='records')\n",
    "dev_annotated_data.to_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_multiple-12.20.23_wbool_dev.json\", lines=True, orient='records')\n",
    "\n",
    "print(len(annotated_data))\n",
    "print(len(dev_annotated_data))\n",
    "print(len(train_annotated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    }
   ],
   "source": [
    "single_annotated_data = annotated_data[annotated_data['id'].isin(dev_ids)]\n",
    "\n",
    "print(len(single_annotated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what          642\n",
       "where         498\n",
       "who           384\n",
       "when          243\n",
       "how           174\n",
       "why            98\n",
       "the            46\n",
       "which          19\n",
       "what's         17\n",
       "is             15\n",
       "difference     13\n",
       "in             10\n",
       "describe        9\n",
       "meaning         8\n",
       "summary         8\n",
       "can             7\n",
       "do              6\n",
       "a               5\n",
       "explain         4\n",
       "does            4\n",
       "give            3\n",
       "last            3\n",
       "list            3\n",
       "whats           3\n",
       "song            3\n",
       "indian          3\n",
       "average         2\n",
       "role            2\n",
       "state           2\n",
       "rhyme           2\n",
       "Name: input, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data_first_word  = annotated_data['input'].str.split().str.get(0)\n",
    "annotated_data_first_word.value_counts()[0:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what          2827\n",
       "who           2414\n",
       "where         2059\n",
       "when          1464\n",
       "how            904\n",
       "why            455\n",
       "the            256\n",
       "which          143\n",
       "is              91\n",
       "in              77\n",
       "what's          54\n",
       "a               49\n",
       "difference      49\n",
       "meaning         33\n",
       "summary         26\n",
       "can             26\n",
       "does            23\n",
       "do              23\n",
       "describe        22\n",
       "explain         20\n",
       "whats           19\n",
       "who's           19\n",
       "name            19\n",
       "list            16\n",
       "during          11\n",
       "are             10\n",
       "an              10\n",
       "main             9\n",
       "did              9\n",
       "this             9\n",
       "Name: input, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load final data and split into train and dev\n",
    "import pandas as pd\n",
    "\n",
    "annotated_single_data = pd.read_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_single-11.16.23.json\", dtype={'id':str}, lines=True)\n",
    "\n",
    "annotated_single_data_first_word  = annotated_single_data['input'].str.split().str.get(0)\n",
    "annotated_single_data_first_word.value_counts()[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12022\n",
      "384\n",
      "11638\n"
     ]
    }
   ],
   "source": [
    "dev_annotated_data_s = annotated_single_data[annotated_single_data['id'].isin(dev_ids)]\n",
    "train_annotated_data_s = annotated_single_data[~annotated_single_data['id'].isin(dev_ids)]\n",
    "\n",
    "train_annotated_data_s.to_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_single-11.16.23_train.json\", lines=True, orient='records')\n",
    "dev_annotated_data_s.to_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_single-11.16.23_dev.json\", lines=True, orient='records')\n",
    "\n",
    "print(len(annotated_single_data))\n",
    "print(len(dev_annotated_data_s))\n",
    "print(len(train_annotated_data_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61499\n",
      "0\n",
      "SA\n"
     ]
    }
   ],
   "source": [
    "sa_train_data = {}\n",
    "\n",
    "def is_majority_type(types, type):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for t in types:\n",
    "        if t == type:\n",
    "            count += 1\n",
    "    if count >= 3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(len(train_data))\n",
    "count_sa = 0\n",
    "\n",
    "for d in train_data:\n",
    "    first_word = d['question_text'].split()[0]\n",
    "    if d['type'][0] == 'sa':\n",
    "        if first_word not in sa_train_data:\n",
    "            sa_train_data[first_word] = 1\n",
    "        else:\n",
    "            sa_train_data[first_word] += 1\n",
    "        count_sa += 1\n",
    "    \n",
    "\n",
    "print(count_sa)\n",
    "print(\"SA\")\n",
    "for word in sa_train_data:\n",
    "    if sa_train_data[word] > 3:\n",
    "        print(f'{word} {sa_train_data[word]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_plaintext': \"Over the Rainbow - wikipedia Over the Rainbow This article is about the 1939 song . For other uses , see Over the Rainbow ( disambiguation ) . `` Over the Rainbow '' Song by Judy Garland Published 1939 Genre Ballad Composer ( s ) Harold Arlen Lyricist ( s ) E.Y. Harburg `` Over the Rainbow '' is a ballad , with music by Harold Arlen and lyrics by Yip Harburg . It was written for the movie The Wizard of Oz and was sung by actress Judy Garland , in her starring role as Dorothy Gale . It won the Academy Award for Best Original Song and became Garland 's signature song , as well as one of the most enduring standards of the 20th century . About five minutes into the film , Dorothy sings the song after failing to get Aunt Em , Uncle Henry , and the farmhands to listen to her relate an unpleasant incident involving her dog , Toto , and the town spinster , Miss Gulch ( Margaret Hamilton ) . Aunt Em tells her to `` find yourself a place where you wo n't get into any trouble '' . This prompts her to walk off by herself , musing to Toto , `` Some place where there is n't any trouble . Do you suppose there is such a place , Toto ? There must be . It 's not a place you can get to by a boat , or a train . It 's far , far away . Behind the moon , beyond the rain ... '' , at which point she begins singing . Contents 1 Influence and legacy 2 The Wizard of Oz 3 Original Garland recordings 4 Lyrics 5 International artists 6 Israel Kamakawiwoʻole version 7 Eva Cassidy version 7.1 Track listings 7.2 Charts 8 Danielle Hope version 8.1 Track listings 8.2 Chart performance 9 Ariana Grande version 9.1 Chart performance 10 Other versions 10.1 On albums and singles 10.2 On film and television 11 See also 12 References 13 External links Influence and legacy ( edit ) The song is number one on the `` Songs of the Century '' list compiled by the Recording Industry Association of America and the National Endowment for the Arts . The American Film Institute also ranked the song the greatest movie song of all time on the list of `` AFI 's 100 Years ... 100 Songs '' . The very first artist to record the song was actually big band singer Bea Wain , who at the time was a featured vocalist with the Larry Clinton Orchestra . MGM prohibited release of this version until The Wizard of Oz ( 1939 ) had opened and audiences heard Judy Garland perform it . It was adopted ( along with Irving Berlin 's 1942 hit `` White Christmas '' ) by American troops in Europe in World War II , as a symbol of the United States . In April 2005 , the United States Postal Service issued a commemorative stamp recognizing lyricist Yip Harburg 's accomplishments ; it features the opening lyric from the song . The song was used as an audio wakeup call in the STS - 88 space shuttle mission in Flight Day 4 , which was dedicated to astronaut Robert D. Cabana from his daughter , Sara . The song was honored with the 2014 Towering Song Award by the Songwriters Hall of Fame and was sung at its dinner on June 12 , 2014 , by Jackie Evancho . In April 2016 , The Daily Telegraph listed the song as number 8 on its list of the 100 greatest songs of all time . In March 2017 , Garland 's original rendition of the song was selected for preservation in the National Recording Registry by the Library of Congress as being `` culturally , historically , or artistically significant '' . The Wizard of Oz ( edit ) The song 's sequence and the entirety of the Kansas scenes were directed by King Vidor , though he was not credited . The song was initially deleted from the film after a preview in San Luis Obispo , because MGM chief executive Louis B. Mayer and producer Mervyn LeRoy thought it `` slowed down the picture '' and that `` the song sounds like something for Jeanette MacDonald , not for a little girl singing in a barnyard '' . However , the persistence of associate producer Arthur Freed and Garland 's vocal coach / mentor Roger Edens to keep it in the film eventually paid off -- it is for this sequence that the film is best known and remembered . At the start of the film , part of the song is played by the MGM orchestra over the opening credits . A reprise of it was deleted after being filmed . An additional chorus was to be sung by Dorothy while she was locked in the Witch 's castle , helplessly awaiting death as the hourglass ran out . However , although the visual portion of that reprise is presumably lost , the soundtrack of it survives and was included in the 2 - CD Deluxe Edition of the film 's soundtrack , released by Rhino Entertainment in 1995 . In that extremely intense and fear - filled rendition , Dorothy cries her way through it , unable to finish , concluding with a tear - filled , `` I 'm frightened , Auntie Em , I 'm frightened ! '' This phrase was retained in the film and is followed immediately by Aunt Em 's brief appearance in the crystal ball , where she is soon replaced by the visage of the witch ( Hamilton ) , mocking and taunting Dorothy before turning toward the camera to cackle . Another instrumental version is played in the underscore in the final scene , and over the closing credits . Original Garland recordings ( edit ) `` Over the Rainbow '' from The Wizard of Oz A sample of the original version of `` Over the Rainbow '' from The Wizard of Oz , sung by Judy Garland . Problems playing this file ? See media help . On October 7 , 1938 , Judy Garland first recorded the song on the MGM soundstages , using an arrangement by Murray Cutter . In September 1939 , a studio recording of the song , not from the actual film soundtrack , was recorded and released as a single by Decca Records . In March 1940 , that same recording was included on a Decca 78 - RPM four - record studio cast album entitled The Wizard of Oz . Although this is not the version of the song featured in the film , Decca would continue to re-release the so - called `` Cast Album '' well into the 1960s after it was re-issued as a single - record 33 \\u200b ⁄ RPM LP . It was not until 1956 , when MGM released the true soundtrack album from the film , that the film version of the song was made available to the public . The 1956 soundtrack release was timed to coincide with the television premiere of the film . The soundtrack version has been re-released several times over the years , including in a `` Deluxe Edition '' from Rhino Records in 1995 . ' Over the Rainbow ' has become part of my life . It 's so symbolic of everybody 's dreams and wishes that I 'm sure that 's why some people get tears in their eyes when they hear it . I 've sung it thousands of times and it 's still the song that 's closest to my heart . -- Judy Garland , in a letter to Harold Arlen Following the film 's release in 1939 , the song became Garland 's signature song and she would perform it for the next 30 years , until her death in 1969 . She performed it without altering it , singing exactly as she did for the film . She explained her fidelity by saying that she was staying true to the character of Dorothy and to the message of really being somewhere over the rainbow . In 2017 , Garland 's recorded rendition of the film was selected for preservation in the National Recording Registry by the Library of Congress as being `` culturally , historically , or artistically significant '' . Lyrics ( edit ) An introductory verse ( `` When all the world is a hopeless jumble ... '' ) that was not used in the film is often used in theatrical productions of The Wizard of Oz and is included in the piano sheet music book of songs from the film . It was also used in renditions by Frank Sinatra , by Al Bowlly , by Doris Day on her album Hooray For Hollywood ( 1958 ) ( Vol. 1 ) , by Tony Bennett on his albums Tony Bennett Sings a String of Harold Arlen ( 1961 ) and Here 's to the Ladies ( 1995 ) , by Ella Fitzgerald , by Sarah Vaughan , and by Norma Waterson , among others . Garland herself sang the introductory verse only once , on a 1948 radio broadcast of The Louella Parsons Show . Lyrics for a second verse ( `` Once by a word only lightly spoken ... '' ) appear in the British edition of the sheet music . International artists ( edit ) The first German version in the English language was recorded by the Swing Orchestra Heinz Wehner ( 1908 -- 1945 ) in March 1940 in Berlin . Wehner , at this time an international well - known German Swing Artist , also took over the vocals . The first German version in German language was sung by Inge Brandenburg ( 1929 -- 1999 ) in 1960 . Israel Kamakawiwoʻole version ( edit ) Main article : Somewhere Over the Rainbow / What a Wonderful World `` Somewhere Over the Rainbow / What a Wonderful World '' Single by Israel Kamakawiwoʻole from the album Facing Future Released 1993 Format CD single Recorded 1988 Label Mountain Apple Company Songwriter ( s ) E.Y. Harburg , Bob Thiele , George David Weiss Israel Kamakawiwoʻole 's album Facing Future , released in 1993 , included a ukulele medley of the song and Louis Armstrong 's `` What a Wonderful World '' . It reached number 12 on Billboard 's Hot Digital Tracks chart the week of January 31 , 2004 ( for the survey week ending January 18 , 2004 ) . In the UK , it was released as a single under the title `` Somewhere Over the Rainbow '' . It entered the UK Official Singles Chart in April 2007 at number 68 . In Germany , the single also returned to the German Singles Chart in September 2010 . After only 2 weeks on that chart , it had already received gold status for having sold 150,000 copies . In October 2010 , it reached No. 1 in the German charts and 2011 it has been certified 5x Gold for selling more than 750,000 copies . It stayed 12 non-consecutive weeks at the top spot and was the most successful single in Germany in 2010 . As of March 2012 , it 's the 2nd best - selling download ever in Germany with digital sales between 500,000 and 600,000 . In France , it debuted at number 4 in December 2010 and reached number one . In the USA , it was certified Platinum for 1,000,000 downloads sold . To date it has sold over 4.2 million digital copies as of October 2014 . In Switzerland , it received Platinum , too , for 30,000 copies sold . This version of the song has been used in several commercials , films and television programs including Finding Forrester , Meet Joe Black , 50 First Dates , Son of the Mask , Snakes on a Plane , Charmed , South Pacific , Cold Case , ER , Life on Mars , Horizon , and Scrubs . The Kamakawiwoʻole version of the song was covered by the cast of Glee on the season one finale , `` Journey , '' and included on the extended play Glee : The Music , Journey to Regionals , charting at number 30 in the UK , 31 in Canada and Ireland , 42 in Australia , and 43 in the US . Cliff Richard recorded his own version of the medley based on this one with a medley of `` Over the Rainbow / What A Wonderful World '' released as a single from the album Wanted , which charted in the UK in 2001 and Aselin Debison recorded the medley for her 2002 album Sweet is the Melody . This version of the song was recorded in 1988 , in Honolulu , in just one take . Israel called the recording studio at 3 am . He was given 15 minutes to arrive by Milan Bertosa . Bertosa is quoted as saying '' And in walks the largest human being I had seen in my life . Israel was probably like 500 pounds . And the first thing at hand is to find something for him to sit on . '' The building security found Israel a large steel chair . `` Then I put up some microphones , do a quick sound check , roll tape , and the first thing he does is ' Somewhere Over the Rainbow . ' He played and sang , one take , and it was over . '' Eva Cassidy version ( edit ) `` Over the Rainbow '' Single by Eva Cassidy from the album The Other Side / Songbird Released January 29 , 2001 ( UK ) Format CD single Label Blix Street Producer ( s ) Chris Biondo Eva Cassidy recorded a version of the song for the 1992 Chuck Brown / Eva Cassidy album The Other Side . After her death in 1996 , it was included in her posthumously - released compilation album Songbird , released in 1998 and was released as a CD single in 2001 . It was popularized by the BBC on BBC Radio 2 and on the television show Top of the Pops 2 ; the latter featured a video recording of Cassidy performing it . When released as a single , `` Over the Rainbow '' debuted at number 88 on the UK Singles Chart in February 2001 and climbed to number 42 in May , becoming Cassidy 's first single to chart in the United Kingdom . In Scotland , the cover was slightly more successful , reaching number 36 and giving Cassidy her first top 40 hit in that region . The publicity of the song helped push sales of the compilation album Songbird to number one on the UK Albums Chart in March 2001 . Cassidy 's recording was selected by the BBC for their Songs of the Century album in 1999 . Her performance of it at Blues Alley was published for the first time in January 2011 on her Simply Eva album . Track listings ( edit ) CD single `` Over the Rainbow '' `` Dark End of the Street '' Charts ( edit ) Chart ( 2001 ) Peak Position Scotland ( Official Charts Company ) 36 UK Singles ( Official Charts Company ) 42 Danielle Hope version ( edit ) `` Over the Rainbow '' Single by Danielle Hope Released May 23 , 2010 ( UK ) Format Digital download , CD single Genre Pop Length 2 : 58 Label Polydor Records Danielle Hope , the winner of the Wizard of Oz - themed BBC talent show Over the Rainbow , released a cover version of the song . It was released by digital download on May 23 , 2010 and a CD single was released May 31 , 2010 . As it was recorded before a winner was announced , runners - up Lauren Samuels and Sophie Evans also recorded versions of it . These were both later made available for download on June 6 , 2010 . All three finalists appeared on the CD single 's B - side : a Wizard of Oz medley . The single was a charity record , raising money for both the BBC Performing Arts Fund and Prostate UK . Track listings ( edit ) UK digital download `` Over the Rainbow '' -- 2 : 58 CD single `` Over the Rainbow '' `` The Wizard of Oz medley '' -- Sophie Evans , Danielle Hope and Lauren Samuels Chart performance ( edit ) Chart ( 2010 ) Peak Position UK Singles ( Official Charts Company ) 29 Ariana Grande version ( edit ) `` Somewhere Over the Rainbow '' Single by Ariana Grande Released June 6 , 2017 ( 2017 - 06 - 06 ) Format Digital download Genre Pop Length 4 : 32 Label Republic Producer ( s ) E.Y. Harburg Harold Arlen Ariana Grande singles chronology `` Heatstroke '' ( 2017 ) `` Somewhere Over the Rainbow '' ( 2017 ) `` No Tears Left to Cry '' ( 2018 ) American singer Ariana Grande released the song on June 6 , 2017 as a single to raise money as part of her benefit concert One Love Manchester , after 22 people were killed in the Manchester Arena bombing at Grande 's concert on May 22 , 2017 . Grande performed the single for the first time on TV at the One Love Manchester concert on June 4 , 2017 . Beginning on June 7 , the singer added the song to her Dangerous Woman Tour setlist for the remainder of that tour . Chart performance ( edit ) Chart ( 2017 ) Peak position UK Singles ( Official Charts Company ) 60 Other versions ( edit ) On Albums and Singles ( edit ) Glenn Miller ( 1939 ) Boyd Raeburn ( 1946 ) Bud Powell ( 1951 ) Dave Brubeck , Jazz at Storyville ( 1952 ) Art Tatum , The Art Tatum Solo Masterpieces Volume 6 ( 1953 ) Ray Charles , Ingredients in a Recipe for Soul ( 1963 ) Stanley Jordan , Stolen Moments ( 1990 ) James Booker , Spiders On The Keys ( 1993 ) Keith Jarrett , La Scala ( 1995 ) Katharine McPhee ( 2006 ) Jewel , Lullaby ( 2009 ) Jeff Beck recorded a version on his album Emotion & Commotion ( 2010 ) . The Demensions recorded a version that reached No. 16 on the Billboard Hot 100 in 1960 . Nicholas David , a contestant on the third season of The Voice , recorded a version that went to No. 96 on the Billboard Hot 100 in 2012 with sales of 48,000 copies . Billy Thorpe and the Aztecs 's version topped the Australian music charts in 1965 . Another version charted in 1974 after Thorpe 's blues - based revival of the song at the 1973 Sunbury Pop Festival . Cosmic Gate released a trance cover called `` Somewhere Over the Rainbow '' that reached No. 29 on the Gfk Entertainment Charts and No. 82 in the Swiss Singles Charts On film and television ( edit ) In the film Third Finger , Left Hand ( 1940 ) with Myrna Loy and Melvyn Douglas the tune is played throughout the film in short sequences . In the film The Philadelphia Story ( 1940 ) , James Stewart sings the song while carrying Katharine Hepburn . The tune appeared throughout the film I Wake Up Screaming ( 1941 ) starring Betty Grable and Victor Mature . The song can be heard in an ironic context in the Vincent Price horror film Dr. Phibes Rises Again ( 1972 ) . Sam Harris 's version appeared in an episode of Beavis and Butt - head . In 1995 , Jewel played Dorothy Gale in the television concert special The Wizard of Oz in Concert : Dreams Come True . Olivia Newton - John 's version was used in the 1997 movie Face / Off . Nora Ephron used two versions of the song in two movies she directed : Sleepless in Seattle ( 1993 ) and You 've Got Mail ( 1998 ) . The songs were sung by Ray Charles and Harry Nilsson , but only Nilsson 's is included on a soundtrack . Mariah Carey sang the song in a medley to her godmother , Patti LaBelle , during the Essence Awards in 1998 . Jane Monheit 's version is used over the end credits of the film `` Sky Captain and the World of Tomorrow '' ( 2004 ) . A version of the song was appeared in an episode of The Grim Adventures of Billy and Mandy . The song appeared at the end of the Scrubs episode `` My Way Home '' . The song appears in the second episode of Salad Fingers , sung by the character of the same name . Beyoncé sang this song at the Live Movies Rocks in 2007 . This song inspired the soundtrack of the short Lava ( Pixar , 2014 ) that was theatrically released alongside Pixar 's Inside Out in 2015 . Nick Jonas sang it in the TV movie Elvis , based on Elvis Presley and his illegalmate children . The film premiered on June 29 , 2018 on TNT . See also ( edit ) Musical selections in The Wizard of Oz List of 1930s jazz standards List of best - selling singles List of best - selling singles in the United States References ( edit ) ^ Jump up to : Roberts , David ( 2006 ) . British Hit Singles & Albums ( 19th ed . ) . London : Guinness World Records Limited . p. 134 . ISBN 1 - 904994 - 10 - 5 . Jump up ^ http://www.hollywoodreporter.com/news/bea-wain-dead-big-band-singer-was-100-1031758 Jump up ^ http://www.mercurynews.com/2017/06/07/somewhere-over-the-rainbow-a-classic-now-linked-to-a-tragedy/ Jump up ^ `` NASA Human Spaceflight Database - STS - 88 Wakeup Calls '' . Jump up ^ Shriver , Jerry ( June 13 , 2014 ) . `` Songwriters gala links old and new with a ' Rainbow ' '' . USA Today . Jump up ^ `` 100 greatest songs of all time '' . ^ Jump up to : `` National Recording Registry Picks Are ' Over the Rainbow ' '' . Library of Congress . March 29 , 2016 . Retrieved March 29 , 2016 . Jump up ^ `` The Movie - Post-Production and Premiere - OzWiki '' . Thewizardofoz.info . Retrieved 2012 - 11 - 22 . Jump up ^ `` The Wizard of Oz Soundtracks ( MGM label ) '' . The Judy Room . Archived from the original on 2011 - 09 - 27 . Jump up ^ `` The Wizard of Oz ( Rhino Movie Music label ) '' . The Judy Room . Archived from the original on 2012 - 01 - 26 . Jump up ^ The Wonderful World of Oz Documentary , The Wizard of Oz ( 3 - Disc Collector 's Edition DVD , 2005 ) . Jump up ^ Garland , Judy . `` The Wizard of Oz ( Decca label ) '' . The Judy Room . Archived from the original on 2007 - 09 - 26 . Jump up ^ Scott Brogan . `` Judy Garland MP3 's '' . Thejudyroom.com . Archived from the original on 2012 - 11 - 16 . Retrieved 2012 - 11 - 22 . Jump up ^ Over the Rainbow . London : Francis , Day , & Hunter , Ltd . Jump up ^ Dick McBougall , Down Beat 12 / 1937 Jump up ^ Over the Rainbow , Swing - Orchester Heinz Wehner , engl . Refraingesang Heinz Wehner , Telefunken A 10101 , Matrizennummer 24836 , recorded March 23 , 1940 Jump up ^ Wenn Du in meinen Träumen ( Over The Rainbow ) , Inge Brandenburg mit dem NDR - Tanzorchester , recorded November 2 , 1960 Jump up ^ Billboard , page 65 ( February 7 , 2004 ) . ^ Jump up to : `` Gold - / Platin - Datenbank ( ' Over the Rainbow ' ) '' ( in German ) . Bundesverband Musikindustrie . Jump up ^ `` Musik - Jahrescharts : `` Sanfter Riese '' und der Graf setzen sich durch - media control `` . Media-control.de . Archived from the original on 2011 - 01 - 07 . Retrieved 2012 - 11 - 22 . Jump up ^ `` '' Poker Face '' knackt 500.000 er - Download - Marke - media control `` . Media-control.de . Retrieved 2012 - 11 - 22 . Jump up ^ `` 600.000 Verkäufe : Michel Teló legt Download - Rekord hin - media control '' . Media-control.de. 2012 - 03 - 30 . Retrieved 2012 - 11 - 22 . Jump up ^ musicline.de Jump up ^ `` Gold & Platinum Searchable Database - November 22 , 2012 '' . RIAA . Retrieved 2012 - 11 - 22 . Jump up ^ Gary Trust ( October 21 , 2014 ) . `` Ask Billboard : The Weird Connections Between Mary Lambert '' . Billboard . Retrieved October 22 , 2014 . Jump up ^ Steffen Hung . `` Die Offizielle Schweizer Hitparade und Music Community '' . Hitparade.ch . Retrieved 2012 - 11 - 22 . Jump up ^ Flandez , Raymund ( June 9 , 2010 ) . `` ' Glee ' Season One Finale , ' Journey : ' TV Recap '' . The Wall Street Journal . Les Hinton . Retrieved December 2 , 2010 . Jump up ^ `` Glee is number 1 Again '' ( Press release ) . PR Newswire . May 26 , 2010 . Retrieved December 2 , 2010 . Jump up ^ `` Top 40 Official UK Singles Archive : 26th June 2010 '' . The Official Charts Company . June 26 , 2010 . Archived from the original on January 31 , 2011 . Retrieved December 2 , 2010 . Jump up ^ `` Canadian Hot 100 : Week of June 26 , 2010 ( Biggest Jump ) '' . Billboard . June 26 , 2010 . Retrieved December 2 , 2010 . Jump up ^ `` Irish Music Charts Archive : Top 50 Singles , Week Ending 17 June 2010 '' . Chart Track . GfK . Retrieved December 2 , 2010 . Jump up ^ `` The ARIA Report : Week Commencing July 12 , 2010 '' ( PDF ) ( 1064 ) . Australian Recording Industry Association . July 12 , 2010 . Retrieved December 2 , 2010 . Jump up ^ `` Hot 100 : Week of June 26 , 2010 ( Biggest Jump ) '' . Billboard . June 26 , 2010 . Retrieved December 2 , 2010 . Jump up ^ `` Israel Kamakawiwo'ole : The Voice Of Hawaii '' . 50 Great Voices . NPR . December 6 , 2010 . Archived from the original on March 9 , 2011 . Retrieved December 16 , 2015 . Then I put up some microphones , do a quick sound check , roll tape , and the first thing he does is ' Somewhere Over the Rainbow . ' He played and sang , one take , and it was over . Jump up ^ `` Official Scottish Singles Sales Chart Top 100 '' . Official Charts Company . Retrieved March 21 , 2018 . Jump up ^ `` Eva Cassidy : Artist Chart History '' . Official Charts Company . ^ Jump up to : `` Winning Dorothy to release ' Rainbow ' '' . Retrieved May 21 , 2010 . Jump up ^ `` Danielle Hope ( ' Over the Rainbow ' ) '' . Retrieved May 27 , 2010 . Jump up ^ `` Danielle Hope : Artist Chart History '' . Official Charts Company . Jump up ^ Reporters , Telegraph ( June 7 , 2017 ) . `` Ariana Grande releases Somewhere Over the Rainbow as charity single for Manchester benefit '' . The Telegraph . ISSN 0307 - 1235 . Retrieved April 11 , 2018 . Jump up ^ `` Ariana Grande resumes Dangerous Woman tour in Paris and says she 's thinking of Manchester terror victims ' every step of the way ' in poignant Instagram '' . The Sun . June 7 , 2017 . Retrieved April 11 , 2018 . Jump up ^ Tanzer , Myles . `` Ariana Grande '' , The Fader , May 30 , 2018 Jump up ^ `` UK Charts June 22 , 2017 '' . auspOp. April 1 , 2017 . Retrieved April 10 , 2017 . ^ Jump up to : Gioia , Ted ( 2012 ) . The Jazz Standards . Oxford : Oxford University Press . p. 330 . ISBN 978 - 0 - 19 - 993739 - 4 . Jump up ^ Phares , Heather . `` Katharine McPhee '' . AllMusic . Retrieved 13 May 2018 . Jump up ^ Gill , Andy ( 9 April 2010 ) . `` Album : Jeff Beck , Emotion & Commotion '' . The Independent . Retrieved April 5 , 2018 . Jump up ^ Milosheff , Peter ( March 24 , 2010 ) . `` The Demensions , White Doo Wop From The Bronx '' . The Bronx Times . Archived from the original on December 8 , 2010 . Jump up ^ `` The Billboard Hot 100 Week of 22 December 2012 '' . Billboard . Retrieved December 14 , 2012 . Jump up ^ Pop Archives . Retrieved June 7 , 2010 . Jump up ^ Savorelli , Antonio ( 13 April 2010 ) . Beyond Sitcom : New Directions in American Television Comedy . McFarland . pp. 39 -- . ISBN 978 - 0 - 7864 - 5843 - 1 . Retrieved July 18 , 2017 . External links ( edit ) The Judy Garland Online Discography Lyrics of this song at MetroLyrics Judy Garland Discography Performances Songs Awards and honors Studio albums Miss Show Business Judy Alone Judy in Love The Letter That 's Entertainment ! The Garland Touch Live albums Garland at the Grove Judy at Carnegie Hall Judy Garland Live ! `` Live '' at the London Palladium Judy Garland at Home at the Palace : Opening Night Soundtracks Summer Stock A Star Is Born Gay Purr - ee I Could Go On Singing Other Biographies As gay icon Rufus Does Judy at Carnegie Hall Rufus ! Rufus ! Rufus ! Does Judy ! Judy ! Judy ! : Live from the London Palladium Liza Minnelli The Judy Monologues ( 2010 play ) The Wizard of Oz Elements `` Surrender Dorothy '' Ruby slippers Music `` Over the Rainbow '' `` Ding - Dong ! The Witch Is Dead '' `` We 're Off to See the Wizard '' `` If I Only Had a Brain '' `` Optimistic Voices '' `` The Merry Old Land of Oz '' `` If I Were King of the Forest '' `` The Jitterbug '' ( cut from final film ) Versions , sequels , and adaptations Stage musicals : 1942 , 1987 , 2011 The Wizard of Oz in Concert : Dreams Come True On television Was Apocalypse Oz Off to See the Wizard Journey Back to Oz The Wiz The Wizard of Oz ( TV series ) Return to Oz ( 1985 ) Tom and Jerry and the Wizard of Oz Wicked Oz the Great and Powerful Legends of Oz : Dorothy 's Return Tom and Jerry : Back to Oz Lost In Oz Dorothy and the Wizard of Oz Games Arcade game Pinball Video game Related The Making of The Wizard of Oz Friend of Dorothy Over the Rainbow Dark Side of the Rainbow Meco Plays The Wizard of Oz Lego Dimensions L. Frank Baum The Wonderful Wizard of Oz Academy Award for Best Original Song 1934 -- 1940 `` The Continental '' Music : Con Conrad Lyrics : Herb Magidson ( 1934 ) `` Lullaby of Broadway '' Music : Harry Warren Lyrics : Al Dubin ( 1935 ) `` The Way You Look Tonight '' Music : Jerome Kern Lyrics : Dorothy Fields ( 1936 ) `` Sweet Leilani '' Music and lyrics : Harry Owens ( 1937 ) `` Thanks for the Memory '' Music : Ralph Rainger Lyrics : Leo Robin ( 1938 ) `` Over the Rainbow '' Music : Harold Arlen Lyrics : E.Y. Harburg ( 1939 ) `` When You Wish Upon a Star '' Music : Leigh Harline Lyrics : Ned Washington ( 1940 ) 1941 -- 1950 `` The Last Time I Saw Paris '' Music : Jerome Kern Lyrics : Oscar Hammerstein II ( 1941 ) `` White Christmas '' Music and lyrics : Irving Berlin ( 1942 ) `` You 'll Never Know '' Music : Harry Warren Lyrics : Mack Gordon ( 1943 ) `` Swinging on a Star '' Music : Jimmy Van Heusen Lyrics : Johnny Burke ( 1944 ) `` It Might as Well Be Spring '' Music : Richard Rodgers Lyrics : Oscar Hammerstein II ( 1945 ) `` On the Atchison , Topeka and the Santa Fe '' Music : Harry Warren Lyrics : Johnny Mercer ( 1946 ) `` Zip - a-Dee - Doo - Dah '' Music : Allie Wrubel Lyrics : Ray Gilbert ( 1947 ) `` Buttons and Bows '' Music : Jay Livingston Lyrics : Ray Evans ( 1948 ) `` Baby , It 's Cold Outside '' Music and lyrics : Frank Loesser ( 1949 ) `` Mona Lisa '' Music and lyrics : Ray Evans and Jay Livingston ( 1950 ) 1951 -- 1960 `` In the Cool , Cool , Cool of the Evening '' Music : Hoagy Carmichael Lyrics : Johnny Mercer ( 1951 ) `` High Noon ( Do Not Forsake Me , Oh My Darlin ' ) '' Music : Dimitri Tiomkin Lyrics : Ned Washington ( 1952 ) `` Secret Love '' Music : Sammy Fain Lyrics : Paul Francis Webster ( 1953 ) `` Three Coins in the Fountain '' Music : Jule Styne Lyrics : Sammy Cahn ( 1954 ) `` Love Is a Many Splendored Thing '' Music : Sammy Fain Lyrics : Paul Francis Webster ( 1955 ) `` Que Sera , Sera ( Whatever Will Be , Will Be ) '' Music and lyrics : Jay Livingston and Ray Evans ( 1956 ) `` All the Way '' Music : Jimmy Van Heusen Lyrics : Sammy Cahn ( 1957 ) `` Gigi '' Music : Frederick Loewe Lyrics : Alan Jay Lerner ( 1958 ) `` High Hopes '' Music : Jimmy Van Heusen Lyrics : Sammy Cahn ( 1959 ) `` Never on Sunday '' Music and lyrics : Manos Hatzidakis ( 1960 ) 1961 -- 1970 `` Moon River '' Music : Henry Mancini Lyrics : Johnny Mercer ( 1961 ) `` Days of Wine and Roses '' Music : Henry Mancini Lyrics : Johnny Mercer ( 1962 ) `` Call Me Irresponsible '' Music : Jimmy Van Heusen Lyrics : Sammy Cahn ( 1963 ) `` Chim Chim Cher - ee '' Music and lyrics : Richard M. Sherman and Robert B. Sherman ( 1964 ) `` The Shadow of Your Smile '' Music : Johnny Mandel Lyrics : Paul Francis Webster ( 1965 ) `` Born Free '' Music : John Barry Lyrics : Don Black ( 1966 ) `` Talk to the Animals '' Music and lyrics : Leslie Bricusse ( 1967 ) `` The Windmills of Your Mind '' Music : Michel Legrand Lyrics : Alan and Marilyn Bergman ( 1968 ) `` Raindrops Keep Fallin ' on My Head '' Music : Burt Bacharach Lyrics : Hal David ( 1969 ) `` For All We Know '' Music : Fred Karlin Lyrics : Robb Royer and Jimmy Griffin ( 1970 ) 1971 -- 1980 `` Theme from Shaft '' Music and lyrics : Isaac Hayes ( 1971 ) `` The Morning After '' Music and lyrics : Al Kasha and Joel Hirschhorn ( 1972 ) `` The Way We Were '' Music : Marvin Hamlisch Lyrics : Alan and Marilyn Bergman ( 1973 ) `` We May Never Love Like This Again '' Music and lyrics : Al Kasha and Joel Hirschhorn ( 1974 ) `` I 'm Easy '' Music and lyrics : Keith Carradine ( 1975 ) `` Evergreen ( Love Theme from A Star Is Born ) '' Music : Barbra Streisand Lyrics : Paul Williams ( 1976 ) `` You Light Up My Life '' Music and lyrics : Joseph Brooks ( 1977 ) `` Last Dance '' Music and lyrics : Paul Jabara ( 1978 ) `` It Goes Like It Goes '' Music : David Shire Lyrics : Norman Gimbel ( 1979 ) `` Fame '' Music : Michael Gore Lyrics : Dean Pitchford ( 1980 ) 1981 -- 1990 `` Arthur 's Theme ( Best That You Can Do ) '' Music and lyrics : Burt Bacharach , Carole Bayer Sager , Christopher Cross and Peter Allen ( 1981 ) `` Up Where We Belong '' Music : Jack Nitzsche and Buffy Sainte - Marie Lyrics : Will Jennings ( 1982 ) `` Flashdance ... What a Feeling '' Music : Giorgio Moroder Lyrics : Keith Forsey and Irene Cara ( 1983 ) `` I Just Called to Say I Love You '' Music and lyrics : Stevie Wonder ( 1984 ) `` Say You , Say Me '' Music and lyrics : Lionel Richie ( 1985 ) `` Take My Breath Away '' Music : Giorgio Moroder Lyrics : Tom Whitlock ( 1986 ) `` ( I 've Had ) The Time of My Life '' Music : Franke Previte , John DeNicola and Donald Markowitz Lyrics : Franke Previte ( 1987 ) `` Let the River Run '' Music and lyrics : Carly Simon ( 1988 ) `` Under the Sea '' Music : Alan Menken Lyrics : Howard Ashman ( 1989 ) `` Sooner or Later ( I Always Get My Man ) '' Music and lyrics : Stephen Sondheim ( 1990 ) 1991 -- 2000 `` Beauty and the Beast '' Music : Alan Menken Lyrics : Howard Ashman ( 1991 ) `` A Whole New World '' Music : Alan Menken Lyrics : Tim Rice ( 1992 ) `` Streets of Philadelphia '' Music and lyrics : Bruce Springsteen ( 1993 ) `` Can You Feel the Love Tonight '' Music : Elton John Lyrics : Tim Rice ( 1994 ) `` Colors of the Wind '' Music : Alan Menken Lyrics : Stephen Schwartz ( 1995 ) `` You Must Love Me '' Music : Andrew Lloyd Webber Lyrics : Tim Rice ( 1996 ) `` My Heart Will Go On '' Music : James Horner Lyrics : Will Jennings ( 1997 ) `` When You Believe '' Music and lyrics : Stephen Schwartz ( 1998 ) `` You 'll Be in My Heart '' Music and lyrics : Phil Collins ( 1999 ) `` Things Have Changed '' Music and lyrics : Bob Dylan ( 2000 ) 2001 -- 2010 `` If I Did n't Have You '' Music and lyrics : Randy Newman ( 2001 ) `` Lose Yourself '' Music : Eminem , Jeff Bass and Luis Resto Lyrics : Eminem ( 2002 ) `` Into the West '' Music and lyrics : Fran Walsh , Howard Shore and Annie Lennox ( 2003 ) `` Al otro lado del río '' Music and lyrics : Jorge Drexler ( 2004 ) `` It 's Hard out Here for a Pimp '' Music and lyrics : Juicy J , Frayser Boy and DJ Paul ( 2005 ) `` I Need to Wake Up '' Music and lyrics : Melissa Etheridge ( 2006 ) `` Falling Slowly '' Music and lyrics : Glen Hansard and Markéta Irglová ( 2007 ) `` Jai Ho '' Music : A.R. Rahman Lyrics : Gulzar ( 2008 ) `` The Weary Kind '' Music and lyrics : Ryan Bingham and T Bone Burnett ( 2009 ) `` We Belong Together '' Music and lyrics : Randy Newman ( 2010 ) 2011 -- present `` Man or Muppet '' Music and lyrics : Bret McKenzie ( 2011 ) `` Skyfall '' Music and lyrics : Adele Adkins and Paul Epworth ( 2012 ) `` Let It Go '' Music and lyrics : Kristen Anderson - Lopez and Robert Lopez ( 2013 ) `` Glory '' Music and lyrics : John Stephens and Lonnie Lynn ( 2014 ) `` Writing 's on the Wall '' Music and lyrics : James Napier and Sam Smith ( 2015 ) `` City of Stars '' Music : Justin Hurwitz Lyrics : Benj Pasek and Justin Paul ( 2016 ) `` Remember Me '' Music and lyrics : Kristen Anderson - Lopez and Robert Lopez ( 2017 ) Israel Kamakawiwoʻole Studio albums Ka ' Ano'i ( 1990 ) Facing Future ( 1993 ) E Ala E ( 1995 ) N Dis Life ( 1996 ) Compilation albums Alone in IZ World ( 2001 ) Wonderful World ( 2009 ) Songs `` Over the Rainbow '' `` What a Wonderful World '' `` Kaleohano '' `` Somewhere Over the Rainbow / What a Wonderful World '' Related Mākaha Sons Eva Cassidy Studio albums The Other Side ( 1992 ) Eva by Heart ( 1997 ) Time After Time ( 2000 ) Imagine ( 2002 ) American Tune ( 2003 ) Somewhere ( 2008 ) Simply Eva ( 2011 ) Live albums Live at Blues Alley ( 1996 ) Nightbird ( 2015 ) Compilations Songbird ( 1998 ) No Boundaries ( 2000 ) Wonderful World ( 2004 ) The Best of Eva Cassidy ( 2012 ) Singles `` People Get Ready '' `` Over the Rainbow '' `` Fields of Gold '' `` It Does n't Matter Anymore '' `` Imagine '' `` Songbird '' `` What a Wonderful World '' ( with Katie Melua ) Related Discography Ariana Grande Discography Awards and nominations Songs Live performances Studio albums Yours Truly My Everything Dangerous Woman Sweetener Other releases Christmas Kisses The Remix Christmas & Chill The Best Singles `` Put Your Hearts Up '' `` The Way '' `` Baby I '' `` Right There '' `` Last Christmas '' `` Santa Tell Me '' `` Problem '' `` Break Free '' `` Bang Bang '' `` Love Me Harder '' `` One Last Time '' `` E Più Ti Penso '' `` Focus '' `` Dangerous Woman '' `` Into You '' `` Side to Side '' `` Everyday '' `` Beauty and the Beast '' `` Somewhere Over the Rainbow '' `` No Tears Left to Cry '' `` God Is a Woman '' Other songs `` Almost Is Never Enough '' `` Best Mistake '' `` Be Alright '' `` Let Me Love You '' `` Greedy '' `` The Light Is Coming '' `` Goodnight n Go '' `` Get Well Soon '' Collaborations `` Popular Song '' `` All My Love '' `` Adore '' `` Research '' `` Boys Like You '' `` Over and Over Again '' `` My Favorite Part '' `` Faith '' `` Heatstroke '' `` Dance to This '' `` Bed '' Concert tours The Listening Sessions The Honeymoon Tour Dangerous Woman Tour The Sweetener Sessions Related articles Frankie Grande One Love Manchester Book Portal Jerry Lee Lewis Studio albums Jerry Lee Lewis Jerry Lee 's Greatest Golden Hits of Jerry Lee Lewis The Return of Rock Country Songs for City Folks Memphis Beat Soul My Way Another Place , Another Time She Still Comes Around Sings the Country Music Hall of Fame Hits , Vol. 1 Sings the Country Music Hall of Fame Hits , Vol. 2 The Golden Cream of the Country She Even Woke Me Up to Say Goodbye In Loving Memories : The Jerry Lee Lewis Gospel Album There Must Be More to Love Than This Touching Home Would You Take Another Chance on Me ? The Killer Rocks On Who 's Gonna Play This Old Piano ? The Session ... Recorded in London with Great Artists Sometimes a Memory Ai n't Enough Southern Roots : Back Home to Memphis I - 40 Country Boogie Woogie Country Man Odd Man In Country Class Country Memories Jerry Lee Keeps Rockin ' Jerry Lee Lewis When Two Worlds Collide Killer Country Young Blood Last Man Standing Mean Old Man Rock & Roll Time Collaborations Together ( with Linda Gail Lewis Million Dollar Quartet ( with Johnny Cash , Carl Perkins and Elvis Presley ) The Survivors Live ( with Johnny Cash and Carl Perkins ) Class of ' 55 ( with Johnny Cash , Carl Perkins and Roy Orbison ) Live albums Live at the Star Club , Hamburg The Greatest Live Show on Earth By Request : More of the Greatest Live Show on Earth Live at the International , Las Vegas Last Man Standing Live Soundtrack albums Jamboree ( 1957 ) American Hot Wax ( 1978 ) Great Balls of Fire ! ( 1989 ) Dick Tracy ( 1990 ) Compilation albums Original Golden Hits , Vol. 1 Original Golden Hits , Vol. 2 Rockin ' Rhythm and Blues A Taste of Country Best of Jerry Lee Lewis All Killer , No Filler : The Anthology Songs `` Baby Baby Bye Bye '' `` Baby , Hold Me Close '' `` Breathless '' `` Chantilly Lace '' `` Cold , Cold Heart '' `` Come as You Were '' `` Crown Victoria Custom ' 51 '' `` Crazy Arms '' `` Do n't Let Me Cross Over '' ( with Linda Gail Lewis ) `` Down the Line '' `` End of the Road '' `` Great Balls of Fire '' `` Hi - Heel Sneakers '' `` High School Confidential '' `` I 'm So Lonesome I Could Cry '' `` In the Mood '' `` Invitation to Your Party '' `` It 'll Be Me '' `` Jackson '' ( with Linda Gail Lewis ) `` Lewis Boogie '' `` Me and Bobby McGee '' `` Old Black Joe '' `` One Has My Name ( The Other Has My Heart ) '' `` One Minute Past Eternity '' `` She Even Woke Me Up to Say Goodbye '' `` She Still Comes Around ( To Love What 's Left of Me ) '' `` Sixteen Candles '' `` Somewhere Over the Rainbow '' `` Sweet Little Sixteen '' `` There Must Be More to Love Than This '' `` To Make Love Sweeter for You '' `` Turn On Your Love Light '' `` What 's Made Milwaukee Famous ( Has Made a Loser Out of Me ) '' `` What 'd I Say '' `` When He Walks on You ( Like You Have Walked On Me ) '' `` Whole Lotta Shakin ' Goin ' On '' `` Would You Take Another Chance on Me '' `` You Win Again '' Filmography Jamboree ( 1957 ) High School Confidential ( 1958 ) Be My Guest ( 1965 ) American Hot Wax ( 1978 ) Family Mickey Gilley Linda Gail Lewis Carl McVoy Jimmy Swaggart Related articles Discography Great Balls of Fire ! Walk the Line Kenny Lovelace Mack Vickery Cliff Richard singles discography 1950s `` Move It '' ( 1958 ) `` High Class Baby '' ( 1958 ) `` Livin ' Lovin ' Doll '' ( 1959 ) `` Mean Streak '' ( 1959 ) `` Living Doll '' ( 1959 ) `` Travellin ' Light '' ( 1959 ) 1960s `` Please Do n't Tease '' ( 1960 ) `` I Love You '' ( 1960 ) `` A Girl Like You '' ( 1961 ) `` When the Girl in Your Arms ... '' ( 1961 ) `` The Young Ones '' / `` We Say Yeah '' ( 1962 ) `` I 'm Lookin ' Out the Window '' / `` Do You Want to Dance ? '' ( 1962 ) `` It 'll Be Me '' ( 1962 ) `` The Next Time '' / `` Bachelor Boy '' ( 1962 ) `` Summer Holiday '' ( 1963 ) `` Lucky Lips '' ( 1963 ) `` It 's All in the Game '' ( 1963 ) `` I Only Have Eyes for You '' ( 1964 ) `` Constantly ( L'Edera ) '' ( 1964 ) `` The Twelfth of Never '' ( 1964 ) `` The Minute You 're Gone '' ( 1965 ) `` Blue Turns to Grey '' ( 1966 ) `` Visions '' ( 1966 ) `` The Day I Met Marie '' ( 1967 ) '' `` All My Love '' ( 1967 ) `` Congratulations '' ( 1968 ) `` Girl , You 'll Be a Woman Soon '' ( 1968 ) `` Marianne '' ( 1968 ) `` Early in the Morning '' ( 1969 ) 1970s `` Sunny Honey Girl '' ( 1971 ) `` Power to All Our Friends '' ( 1973 ) `` Honky Tonk Angel '' ( 1975 ) `` Miss You Nights '' ( 1976 ) `` Devil Woman '' ( 1976 ) `` Hey Mr. Dream Maker '' ( 1976 ) `` My Kinda Life '' ( 1977 ) `` When Two Worlds Drift Apart '' ( 1977 ) `` Green Light '' ( 1979 ) `` We Do n't Talk Anymore '' ( 1979 ) 1980s `` Carrie '' ( 1980 ) `` Dreamin ' '' ( 1980 ) `` Suddenly '' ( 1980 ) `` A Little in Love '' ( 1980 ) `` Wired for Sound '' ( 1981 ) `` Daddy 's Home '' ( live ) ( 1981 ) `` The Only Way Out '' ( 1982 ) `` True Love Ways '' ( live ) ( 1983 ) `` Baby You 're Dynamite '' / `` Ocean Deep '' ( 1984 ) `` Donna '' ( 1984 US ) `` Two to the Power of Love '' ( 1984 ) `` Living Doll '' ( 1986 ) `` All I Ask of You '' ( 1986 ) `` My Pretty One '' ( 1987 ) `` Some People '' ( 1987 ) `` Remember Me '' ( 1987 ) `` Two Hearts '' ( 1988 ) `` Mistletoe and Wine '' ( 1988 ) `` The Best of Me '' ( 1989 ) `` I Just Do n't Have the Heart '' ( 1989 ) `` Lean On You '' ( 1989 ) `` Whenever God Shines His Light '' ( 1989 ) 1990s `` Stronger Than That '' ( 1990 ) `` Silhouettes '' ( live ) ( 1990 ) `` From a Distance '' ( live ) ( 1990 ) `` Saviour 's Day '' ( 1990 ) `` Scarlet Ribbons '' ( 1991 ) `` We Should Be Together '' ( 1991 ) `` Peace in Our Time '' ( 1993 ) `` All I Have to Do Is Dream '' ( live ) / `` Miss You Nights '' ( 1994 ) `` Ca n't Keep this Feeling In '' ( 1998 ) `` The Millennium Prayer '' ( 1999 ) 2000s `` Somewhere Over the Rainbow '' / `` What a Wonderful World '' ( medley ) ( 2001 ) `` Yesterday Once More '' ( 2006 ) `` Move It '' ( 2006 ) `` When I Need You '' ( 2007 ) `` Mistletoe and Wine '' ( re-entry ) ( 2008 ) `` Thank You for a Lifetime '' ( 2008 ) `` Singing the Blues '' ( 2009 ) 2010s `` Rip It Up '' ( 2013 ) `` Since I Lost My Baby '' ( 2014 ) `` Roll Over Beethoven '' ( 2016 ) `` Blue Suede Shoes '' ( 2017 ) Book : Cliff Richard Jewel singles Discography 1990s releases Pieces of You `` Who Will Save Your Soul '' `` You Were Meant for Me '' `` Foolish Games '' `` Morning Song '' Spirit `` Hands '' `` Down So Long '' `` Jupiter ( Swallow the Moon ) '' `` What 's Simple Is True '' `` Life Uncommon '' 2000s and 2010s releases This Way `` Standing Still '' `` Break Me '' `` This Way '' `` Serve the Ego '' 0304 `` Intuition '' `` Stand '' `` 2 Become 1 '' Goodbye Alice in Wonderland `` Goodbye Alice in Wonderland '' `` Again and Again '' `` Good Day '' `` Only One Too '' `` Stephenville , TX '' Perfectly Clear `` Stronger Woman '' `` I Do '' `` Till It Feels Like Cheating '' Lullaby `` Somewhere Over the Rainbow '' Sweet and Wild `` Stay Here Forever '' `` Satisfied '' `` Ten '' Greatest Hits `` Two Hearts Breaking '' Soundtrack singles `` Quest for Love '' Guest singles `` That 's the Way Love Goes '' Promotional singles `` Winter Wonderland '' `` Hark ! The Herald Angels Sing '' `` Twinkle Twinkle Little Star '' `` Have Yourself a Merry Little Christmas '' `` The Christmas Song '' Willie Nelson singles discography 1950s and 1960s 1957 `` No Place for Me '' / `` Lumberjack '' 1959 `` Man With the Blues '' / `` The Storm Has Just Begun '' 1960 `` What a Way to Live '' / `` Misery Mansion '' `` Nite Life '' / `` Rainy Day Blues '' 1961 `` The Part Where I Cry '' / `` Mr. Record Man '' 1962 `` Willingly '' / `` Chain of Love '' `` Touch Me '' / `` Where My House Lives '' `` Wake Me When It 's Over '' / `` There 's Gonna Be Love In My House '' `` You Dream About Me '' / `` Is This My Destiny '' 1963 `` Half a Man '' / `` The Last Letter '' `` Take My Word '' / `` Feed it a Memory '' 1964 `` How Long is Forever '' / `` You Took My Happy Away '' `` Am I Blue '' / `` There 'll Be No Teardrops Tonight '' `` River Boy '' / `` Opportunity to Cry '' `` I Never Cared For You '' / `` You Left Me ( A Long Time Ago ) '' `` Pretty Paper '' / `` What A Merry Christmas This Could Be '' 1965 `` She 's Not For You '' / `` Permanently Lonely '' `` Healing Hands of Time '' / `` One Day at the Time '' `` I Just Ca n't Let You Say Goodbye '' / `` And So Will You , My Love '' 1966 `` One In A Row '' / `` San Antonio Rose '' `` Colombus Stockade Blues '' / `` He Sits at my Table '' `` I 'm Still Not Over You '' / `` I Love You Because '' 1967 `` The Party 's Over '' / `` Make Way for a Better Man '' `` Blackjack County Chain '' / `` Some Other World '' `` San Antonio '' / `` To Make a Long Story Short '' 1968 `` Little Things '' / `` Sweet Memories '' `` Good Times '' / `` Where Do You Stand '' `` Johnny One Time '' / `` She 's Still Gone '' 1969 `` Bring Me Sunshine '' / `` Do n't Say Love or Nothing '' `` I Hope So '' / `` Right or Wrong '' 1970s 1970 `` Once More With Feeling '' / `` Who Do I Know in Dallas '' `` Laying My Burdens Down '' / `` Truth Number One '' 1971 `` I 'm a Memory '' / `` Fire and Rain '' `` Yesterday 's Wine '' / `` Me and Paul '' 1972 `` Words Do n't Fit the Picture '' / `` A Moment '' 1973 `` Shotgun Willie '' ( mono ) / `` Sad Songs and Waltzes '' `` Stay All Night ( Stay a Little Longer ) '' / `` Devil in a Sleepin ' Bag '' `` I Still Ca n't Believe You 're Gone '' / `` Heaven and Hell '' `` Bloody Mary Morning '' / `` After the Fire is Gone '' ( with Tracy Nelson ) `` Sister 's Comin ' Home '' ( mono ) / `` Pick Up The Tempo '' `` Blue Eyes Crying in the Rain '' / `` Bandera '' 1976 `` Remember Me ( When the Candle Lights Are Gleaming ) '' / `` Time of the Preacher '' `` I 'd Have to Be Crazy '' ( mono ) / `` Amazing Grace '' `` If You 've Got the Money I 've Got the Time '' / `` The Sound in Your Mind '' 1977 `` Uncloudy Day '' / `` Precious Memories '' `` I Love You A Thousand Ways '' / `` Mom and Dad 's Waltz '' 1978 `` Georgia on My Mind '' / `` On The Sunny Side Of The Street '' `` Blue Skies '' / `` Moonlight in Vermont '' `` All of Me '' / `` Unchained Melody '' 1979 `` Whiskey River '' / `` Under the Double Eagle '' `` September Song '' / `` Do n't Get Around Much Anymore '' `` White Christmas '' / `` Blue Christmas '' 1980s 1980 `` Help Me Make It Through the Night '' / `` The Pilgrim , Chapter 33 '' `` My Heroes Have Always Been Cowboys '' / `` Rising Stars '' `` Midnight Rider '' / `` So You Think You 're A Cowboy '' `` On the Road Again '' / `` Jumpin ' Cotton Eyed Joe '' ( performed by Johnny Gimble ) 1981 `` Angel Flying Too Close to the Ground '' / `` I Guess I 've Come to Live Here in Your Eyes '' `` Mona Lisa '' / `` Twinkle , Twinkle , Little Star '' `` I 'm Gonna Sit Right Down and Write Myself a Letter '' / `` Over the Rainbow '' `` Heartaches of a Fool '' / `` Uncloudy Day '' 1982 `` Always on My Mind '' / `` The Party 's Over '' `` Let It Be Me '' / `` Permanently Lonely '' `` Last Thing I Needed First Thing This Morning '' / `` Old Fords and a Natural Stone '' `` Little Old Fashioned Karma '' / `` Beer Barrel Polka '' `` Why Do I Have to Choose '' / `` Would You Lay with Me ( In a Field of Stone ) '' `` Take It to the Limit '' / `` Till I Gain Control Again '' `` Without a Song '' 1984 `` City of New Orleans ( Unedited version ) '' / `` Why Are You Pickin ' On Me '' 1985 `` Forgiving You Was Easy '' / `` You Would n't Cross the Street '' `` Me and Paul '' / `` I Let My Mind Wander '' 1986 `` Living in the Promiseland '' / `` Bach Minuet in G '' `` I 'm Not Trying to Forget You '' / `` I 've Got the Craziest Feeling '' `` Partners After All '' / `` Home Away From Home '' `` Heart of Gold '' / `` So Much Like My Dad '' `` Island in the Sea '' / `` There Is No Easy Way '' 1988 `` Nobody There But Me '' / `` Wake Me When It 's Over '' `` Spanish Eyes '' ( with Julio Iglesias ) / `` Ole Buttermilk Sky '' `` Twilight Time '' / `` Ac - Cent - Tchu - Ate the Positive '' `` Nothing I Can Do About It Now '' / `` If I Were a Painting '' `` There You Are '' / `` Spirit '' `` Is The Better Part Over '' / `` Mr. Record Man '' 1990s `` The Highway '' / `` Spirit '' `` Ai n't Necessarily So '' / `` I Never Cared For You '' ( `` Ai n't Necessarily So '' also on CD Single ) 1991 `` The Piper Came Today '' / `` ( I Do n't Have a Reason ) To Go To California Anymore '' ( `` The Piper Came Today '' also on CD Single ) `` Ten With a Two '' / `` You Decide '' 1993 `` Graceland '' `` Still is Still Moving to Me '' / `` Valentine '' 1995 `` Turn Me Loose and Let Me Swing '' 1998 `` I Never Cared for You '' 2000s and 2010s 2002 `` Mendocino County Line '' ( with Lee Ann Womack ) / `` Maria ( Shut Up and Kiss Me ) '' ( Both single tracks released on CD and 7 '' record ) 2003 `` Wurlitzer Prize '' ( with Norah Jones ) `` Beer for My Horses '' ( with Toby Keith ) 2005 `` I 'm a Worried Man '' ( with Toots Hibbert ) `` The Harder They Come '' 2006 `` You Do n't Know Me '' `` Cowboys Are Frequently , Secretly Fond of Each Other '' 2008 `` Gravedigger '' `` You Do n't Think I 'm Funny Anymore '' 2011 `` The Scientist '' 2012 `` Roll Me Up and Smoke Me When I Die '' `` Just Breathe '' `` Come On Back Jesus '' 2013 `` From Here to the Moon and Back '' ( with Dolly Parton ) `` Grandma 's Hands '' ( with Mavis Staples ) `` It Wo n't Be Long '' ( with The Secret Sisters ) `` Somewhere Between '' ( with Loretta Lynn ) 2014 `` The Wall '' `` Bring It On '' `` Laws of Nature '' `` Who 'll Buy My Memories '' `` Summer of Roses '' / `` December Day '' 2015 `` It 's All Going to Pot '' `` Alice in Hulaland '' 2016 `` Lay Me Down '' 2017 `` Still Not Dead '' 2018 `` Last Man Standing '' Book : Willie Nelson Category : Willie Nelson BNF : cb13856523g ( data ) GND : 7863238 - 9 LCCN : no99041403 VIAF : 180865957 Retrieved from `` https://en.wikipedia.org/w/index.php?title=Over_the_Rainbow&oldid=856167199 '' Categories : 1939 songs Best Original Song Academy Award - winning songs American songs Pop ballads Songs with music by Harold Arlen Songs with lyrics by Yip Harburg Songs from The Wizard of Oz ( 1939 film ) Judy Garland songs Grammy Hall of Fame Award recipients United States National Recording Registry recordings 1930s jazz standards Pop standards Grammy Award for Best Instrumental Arrangement Accompanying Vocalist ( s ) Jazz compositions in A-flat major Hidden categories : CS1 German - language sources ( de ) Use mdy dates from April 2018 Articles with hAudio microformats Audio sample to be checked Singlechart usages for Scotland Singlechart usages for UKchartstats Song articles with missing songwriters Wikipedia articles with BNF identifiers Wikipedia articles with GND identifiers Wikipedia articles with LCCN identifiers Wikipedia articles with VIAF identifiers Talk Contents About Wikipedia Bân - lâm - gú Български Čeština Dansk Deutsch Eesti Ελληνικά Español Esperanto Euskara فارسی Français 한국어 Italiano עברית Nederlands 日本 語 Norsk Polski Português Русский Sardu Simple English Slovenčina Suomi Svenska Tagalog Türkçe Українська Tiếng Việt 中文 22 more Edit links This page was last edited on 23 August 2018 , at 09 : 49 ( UTC ) . Text is available under the Creative Commons Attribution - ShareAlike License ; additional terms may apply . By using this site , you agree to the Terms of Use and Privacy Policy . Wikipedia ® is a registered trademark of the Wikimedia Foundation , Inc. , a non-profit organization . About Wikipedia \",\n",
       " 'document_title': 'Over the Rainbow',\n",
       " 'document_url': 'https://en.wikipedia.org//w/index.php?title=Over_the_Rainbow&amp;oldid=856167199',\n",
       " 'example_id': '-5436994632006702327',\n",
       " 'language': 'english',\n",
       " 'question_text': 'who sings new version of somewhere over the rainbow',\n",
       " 'passage_answer_candidates': [{'plaintext_start_byte': 143,\n",
       "   'plaintext_end_byte': 270},\n",
       "  {'plaintext_start_byte': 143, 'plaintext_end_byte': 165},\n",
       "  {'plaintext_start_byte': 166, 'plaintext_end_byte': 186},\n",
       "  {'plaintext_start_byte': 187, 'plaintext_end_byte': 201},\n",
       "  {'plaintext_start_byte': 202, 'plaintext_end_byte': 214},\n",
       "  {'plaintext_start_byte': 215, 'plaintext_end_byte': 242},\n",
       "  {'plaintext_start_byte': 243, 'plaintext_end_byte': 270},\n",
       "  {'plaintext_start_byte': 271, 'plaintext_end_byte': 641},\n",
       "  {'plaintext_start_byte': 642, 'plaintext_end_byte': 1312},\n",
       "  {'plaintext_start_byte': 1770, 'plaintext_end_byte': 2070},\n",
       "  {'plaintext_start_byte': 2071, 'plaintext_end_byte': 2354},\n",
       "  {'plaintext_start_byte': 2355, 'plaintext_end_byte': 2514},\n",
       "  {'plaintext_start_byte': 2515, 'plaintext_end_byte': 2692},\n",
       "  {'plaintext_start_byte': 2693, 'plaintext_end_byte': 2867},\n",
       "  {'plaintext_start_byte': 2868, 'plaintext_end_byte': 3021},\n",
       "  {'plaintext_start_byte': 3022, 'plaintext_end_byte': 3137},\n",
       "  {'plaintext_start_byte': 3138, 'plaintext_end_byte': 3360},\n",
       "  {'plaintext_start_byte': 3387, 'plaintext_end_byte': 4037},\n",
       "  {'plaintext_start_byte': 4038, 'plaintext_end_byte': 5123},\n",
       "  {'plaintext_start_byte': 5161, 'plaintext_end_byte': 5357},\n",
       "  {'plaintext_start_byte': 5161, 'plaintext_end_byte': 5311},\n",
       "  {'plaintext_start_byte': 5312, 'plaintext_end_byte': 5357},\n",
       "  {'plaintext_start_byte': 5358, 'plaintext_end_byte': 5481},\n",
       "  {'plaintext_start_byte': 5482, 'plaintext_end_byte': 5629},\n",
       "  {'plaintext_start_byte': 5630, 'plaintext_end_byte': 5978},\n",
       "  {'plaintext_start_byte': 5979, 'plaintext_end_byte': 6366},\n",
       "  {'plaintext_start_byte': 6638, 'plaintext_end_byte': 6683},\n",
       "  {'plaintext_start_byte': 6684, 'plaintext_end_byte': 7076},\n",
       "  {'plaintext_start_byte': 7077, 'plaintext_end_byte': 7293},\n",
       "  {'plaintext_start_byte': 7310, 'plaintext_end_byte': 8117},\n",
       "  {'plaintext_start_byte': 8149, 'plaintext_end_byte': 8491},\n",
       "  {'plaintext_start_byte': 8599, 'plaintext_end_byte': 8856},\n",
       "  {'plaintext_start_byte': 8599, 'plaintext_end_byte': 8656},\n",
       "  {'plaintext_start_byte': 8657, 'plaintext_end_byte': 8689},\n",
       "  {'plaintext_start_byte': 8690, 'plaintext_end_byte': 8718},\n",
       "  {'plaintext_start_byte': 8719, 'plaintext_end_byte': 8732},\n",
       "  {'plaintext_start_byte': 8733, 'plaintext_end_byte': 8749},\n",
       "  {'plaintext_start_byte': 8750, 'plaintext_end_byte': 8763},\n",
       "  {'plaintext_start_byte': 8764, 'plaintext_end_byte': 8792},\n",
       "  {'plaintext_start_byte': 8793, 'plaintext_end_byte': 8856},\n",
       "  {'plaintext_start_byte': 8857, 'plaintext_end_byte': 10163},\n",
       "  {'plaintext_start_byte': 10164, 'plaintext_end_byte': 11022},\n",
       "  {'plaintext_start_byte': 11023, 'plaintext_end_byte': 11650},\n",
       "  {'plaintext_start_byte': 11680, 'plaintext_end_byte': 11862},\n",
       "  {'plaintext_start_byte': 11680, 'plaintext_end_byte': 11702},\n",
       "  {'plaintext_start_byte': 11703, 'plaintext_end_byte': 11724},\n",
       "  {'plaintext_start_byte': 11725, 'plaintext_end_byte': 11765},\n",
       "  {'plaintext_start_byte': 11766, 'plaintext_end_byte': 11799},\n",
       "  {'plaintext_start_byte': 11800, 'plaintext_end_byte': 11816},\n",
       "  {'plaintext_start_byte': 11817, 'plaintext_end_byte': 11834},\n",
       "  {'plaintext_start_byte': 11835, 'plaintext_end_byte': 11862},\n",
       "  {'plaintext_start_byte': 11863, 'plaintext_end_byte': 12285},\n",
       "  {'plaintext_start_byte': 12286, 'plaintext_end_byte': 12760},\n",
       "  {'plaintext_start_byte': 12761, 'plaintext_end_byte': 12964},\n",
       "  {'plaintext_start_byte': 12999, 'plaintext_end_byte': 13050},\n",
       "  {'plaintext_start_byte': 12999, 'plaintext_end_byte': 13021},\n",
       "  {'plaintext_start_byte': 13022, 'plaintext_end_byte': 13050},\n",
       "  {'plaintext_start_byte': 13067, 'plaintext_end_byte': 13177},\n",
       "  {'plaintext_start_byte': 13067, 'plaintext_end_byte': 13095},\n",
       "  {'plaintext_start_byte': 13096, 'plaintext_end_byte': 13135},\n",
       "  {'plaintext_start_byte': 13136, 'plaintext_end_byte': 13177},\n",
       "  {'plaintext_start_byte': 13209, 'plaintext_end_byte': 13367},\n",
       "  {'plaintext_start_byte': 13209, 'plaintext_end_byte': 13231},\n",
       "  {'plaintext_start_byte': 13232, 'plaintext_end_byte': 13255},\n",
       "  {'plaintext_start_byte': 13256, 'plaintext_end_byte': 13285},\n",
       "  {'plaintext_start_byte': 13286, 'plaintext_end_byte': 13321},\n",
       "  {'plaintext_start_byte': 13322, 'plaintext_end_byte': 13331},\n",
       "  {'plaintext_start_byte': 13332, 'plaintext_end_byte': 13345},\n",
       "  {'plaintext_start_byte': 13346, 'plaintext_end_byte': 13367},\n",
       "  {'plaintext_start_byte': 13368, 'plaintext_end_byte': 13875},\n",
       "  {'plaintext_start_byte': 13876, 'plaintext_end_byte': 13979},\n",
       "  {'plaintext_start_byte': 14004, 'plaintext_end_byte': 14023},\n",
       "  {'plaintext_start_byte': 14004, 'plaintext_end_byte': 14023},\n",
       "  {'plaintext_start_byte': 14024, 'plaintext_end_byte': 14056},\n",
       "  {'plaintext_start_byte': 14024, 'plaintext_end_byte': 14056},\n",
       "  {'plaintext_start_byte': 14057, 'plaintext_end_byte': 14066},\n",
       "  {'plaintext_start_byte': 14067, 'plaintext_end_byte': 14170},\n",
       "  {'plaintext_start_byte': 14067, 'plaintext_end_byte': 14089},\n",
       "  {'plaintext_start_byte': 14090, 'plaintext_end_byte': 14170},\n",
       "  {'plaintext_start_byte': 14198, 'plaintext_end_byte': 14268},\n",
       "  {'plaintext_start_byte': 14198, 'plaintext_end_byte': 14226},\n",
       "  {'plaintext_start_byte': 14227, 'plaintext_end_byte': 14268},\n",
       "  {'plaintext_start_byte': 14300, 'plaintext_end_byte': 14639},\n",
       "  {'plaintext_start_byte': 14300, 'plaintext_end_byte': 14332},\n",
       "  {'plaintext_start_byte': 14333, 'plaintext_end_byte': 14356},\n",
       "  {'plaintext_start_byte': 14357, 'plaintext_end_byte': 14398},\n",
       "  {'plaintext_start_byte': 14399, 'plaintext_end_byte': 14422},\n",
       "  {'plaintext_start_byte': 14423, 'plaintext_end_byte': 14432},\n",
       "  {'plaintext_start_byte': 14433, 'plaintext_end_byte': 14446},\n",
       "  {'plaintext_start_byte': 14447, 'plaintext_end_byte': 14461},\n",
       "  {'plaintext_start_byte': 14462, 'plaintext_end_byte': 14502},\n",
       "  {'plaintext_start_byte': 14477, 'plaintext_end_byte': 14502},\n",
       "  {'plaintext_start_byte': 14503, 'plaintext_end_byte': 14535},\n",
       "  {'plaintext_start_byte': 14536, 'plaintext_end_byte': 14639},\n",
       "  {'plaintext_start_byte': 14536, 'plaintext_end_byte': 14639},\n",
       "  {'plaintext_start_byte': 14536, 'plaintext_end_byte': 14639},\n",
       "  {'plaintext_start_byte': 14640, 'plaintext_end_byte': 14884},\n",
       "  {'plaintext_start_byte': 14885, 'plaintext_end_byte': 15108},\n",
       "  {'plaintext_start_byte': 15136, 'plaintext_end_byte': 15206},\n",
       "  {'plaintext_start_byte': 15136, 'plaintext_end_byte': 15164},\n",
       "  {'plaintext_start_byte': 15165, 'plaintext_end_byte': 15206},\n",
       "  {'plaintext_start_byte': 15262, 'plaintext_end_byte': 16353},\n",
       "  {'plaintext_start_byte': 15262, 'plaintext_end_byte': 15283},\n",
       "  {'plaintext_start_byte': 15284, 'plaintext_end_byte': 15305},\n",
       "  {'plaintext_start_byte': 15306, 'plaintext_end_byte': 15325},\n",
       "  {'plaintext_start_byte': 15326, 'plaintext_end_byte': 15368},\n",
       "  {'plaintext_start_byte': 15369, 'plaintext_end_byte': 15430},\n",
       "  {'plaintext_start_byte': 15431, 'plaintext_end_byte': 15486},\n",
       "  {'plaintext_start_byte': 15487, 'plaintext_end_byte': 15527},\n",
       "  {'plaintext_start_byte': 15528, 'plaintext_end_byte': 15571},\n",
       "  {'plaintext_start_byte': 15572, 'plaintext_end_byte': 15605},\n",
       "  {'plaintext_start_byte': 15606, 'plaintext_end_byte': 15631},\n",
       "  {'plaintext_start_byte': 15632, 'plaintext_end_byte': 15656},\n",
       "  {'plaintext_start_byte': 15657, 'plaintext_end_byte': 15729},\n",
       "  {'plaintext_start_byte': 15730, 'plaintext_end_byte': 15818},\n",
       "  {'plaintext_start_byte': 15819, 'plaintext_end_byte': 15985},\n",
       "  {'plaintext_start_byte': 15986, 'plaintext_end_byte': 16186},\n",
       "  {'plaintext_start_byte': 16187, 'plaintext_end_byte': 16353},\n",
       "  {'plaintext_start_byte': 16386, 'plaintext_end_byte': 18191},\n",
       "  {'plaintext_start_byte': 16386, 'plaintext_end_byte': 16525},\n",
       "  {'plaintext_start_byte': 16526, 'plaintext_end_byte': 16635},\n",
       "  {'plaintext_start_byte': 16636, 'plaintext_end_byte': 16744},\n",
       "  {'plaintext_start_byte': 16745, 'plaintext_end_byte': 16854},\n",
       "  {'plaintext_start_byte': 16855, 'plaintext_end_byte': 16927},\n",
       "  {'plaintext_start_byte': 16928, 'plaintext_end_byte': 17046},\n",
       "  {'plaintext_start_byte': 17047, 'plaintext_end_byte': 17118},\n",
       "  {'plaintext_start_byte': 17119, 'plaintext_end_byte': 17356},\n",
       "  {'plaintext_start_byte': 17357, 'plaintext_end_byte': 17466},\n",
       "  {'plaintext_start_byte': 17467, 'plaintext_end_byte': 17586},\n",
       "  {'plaintext_start_byte': 17587, 'plaintext_end_byte': 17679},\n",
       "  {'plaintext_start_byte': 17680, 'plaintext_end_byte': 17750},\n",
       "  {'plaintext_start_byte': 17751, 'plaintext_end_byte': 17849},\n",
       "  {'plaintext_start_byte': 17850, 'plaintext_end_byte': 17908},\n",
       "  {'plaintext_start_byte': 17909, 'plaintext_end_byte': 18048},\n",
       "  {'plaintext_start_byte': 18049, 'plaintext_end_byte': 18191}],\n",
       " 'annotations': [{'annotation_id': '953612135555563607',\n",
       "   'minimal_answer': {'plaintext_start_byte': 14343,\n",
       "    'plaintext_end_byte': 14356},\n",
       "   'passage_answer': {'candidate_index': 82},\n",
       "   'yes_no_answer': 'NONE'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "train_files = glob.glob(\"/dccstor/srosent2/primeqa/data/train/nq-full/*.jsonl.gz\")\n",
    "\n",
    "train_data_full = []\n",
    "for train_file in train_files:\n",
    "    train_data_full.extend(load_json_from_file(train_file))\n",
    "\n",
    "train_data_full[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307373"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_data_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106926\n",
      "SA\n",
      "who 38047\n",
      "where 12144\n",
      "how 5680\n",
      "when 20433\n",
      "what 15195\n",
      "name 304\n",
      "what's 401\n",
      "why 526\n",
      "which 1938\n",
      "the 2534\n",
      "first 163\n",
      "in 653\n",
      "this 78\n",
      "an 73\n",
      "if 43\n",
      "at 79\n",
      "number 99\n",
      "who's 338\n",
      "all 34\n",
      "when's 84\n",
      "a 358\n",
      "total 71\n",
      "top 53\n",
      "is 203\n",
      "where's 33\n",
      "one 69\n",
      "according 68\n",
      "whats 91\n",
      "game 35\n",
      "most 199\n",
      "during 64\n",
      "last 91\n",
      "meaning 50\n",
      "actress 54\n",
      "i 45\n",
      "on 48\n",
      "highest 58\n",
      "list 98\n",
      "real 41\n",
      "actor 67\n",
      "song 33\n",
      "movie 35\n",
      "155225\n",
      "NA\n",
      "where 13048\n",
      "what 22132\n",
      "the 7430\n",
      "1 40\n",
      "who 29623\n",
      "when 14952\n",
      "office 33\n",
      "how 9341\n",
      "this 227\n",
      "which 6362\n",
      "can 415\n",
      "in 1364\n",
      "are 223\n",
      "national 108\n",
      "little 49\n",
      "oh 48\n",
      "game 99\n",
      "meaning 185\n",
      "discuss 230\n",
      "download 81\n",
      "explain 583\n",
      "write 316\n",
      "name 537\n",
      "tell 35\n",
      "who's 327\n",
      "describe 552\n",
      "as 136\n",
      "all 412\n",
      "an 214\n",
      "most 235\n",
      "song 263\n",
      "now 95\n",
      "john 75\n",
      "history 146\n",
      "is 1109\n",
      "summary 194\n",
      "lyrics 148\n",
      "youtube 47\n",
      "show 206\n",
      "you 241\n",
      "what's 455\n",
      "why 2265\n",
      "names 78\n",
      "if 334\n",
      "black 68\n",
      "it's 118\n",
      "different 83\n",
      "list 1228\n",
      "that's 42\n",
      "first 157\n",
      "using 36\n",
      "map 147\n",
      "a 1218\n",
      "does 316\n",
      "was 93\n",
      "american 93\n",
      "blue 33\n",
      "to 97\n",
      "i 933\n",
      "on 118\n",
      "one 245\n",
      "love 77\n",
      "watch 61\n",
      "michael 62\n",
      "queen 34\n",
      "india 85\n",
      "johnny 32\n",
      "cast 245\n",
      "baby 31\n",
      "two 105\n",
      "and 64\n",
      "we 130\n",
      "give 157\n",
      "only 47\n",
      "family 45\n",
      "university 47\n",
      "types 47\n",
      "new 150\n",
      "i'm 118\n",
      "central 37\n",
      "state 129\n",
      "countries 89\n",
      "orange 72\n",
      "my 160\n",
      "according 204\n",
      "whats 138\n",
      "difference 318\n",
      "under 71\n",
      "girl 39\n",
      "role 60\n",
      "after 78\n",
      "star 174\n",
      "1. 54\n",
      "story 69\n",
      "identify 104\n",
      "old 36\n",
      "will 111\n",
      "law 91\n",
      "during 154\n",
      "did 127\n",
      "so 49\n",
      "from 50\n",
      "war 31\n",
      "top 157\n",
      "essay 32\n",
      "king 41\n",
      "factors 31\n",
      "characters 43\n",
      "do 434\n",
      "international 60\n",
      "last 100\n",
      "at 134\n",
      "journey 31\n",
      "information 49\n",
      "article 45\n",
      "rolling 41\n",
      "tom 56\n",
      "elvis 31\n",
      "harry 110\n",
      "define 104\n",
      "by 74\n",
      "find 43\n",
      "house 42\n",
      "songs 59\n",
      "main 73\n",
      "i've 46\n",
      "highest 58\n",
      "nba 35\n",
      "they 47\n",
      "high 35\n",
      "it 103\n",
      "let 54\n",
      "united 78\n",
      "red 48\n",
      "number 107\n",
      "some 33\n",
      "movies 41\n",
      "based 31\n",
      "dragon 42\n",
      "real 40\n",
      "examples 37\n",
      "for 86\n",
      "short 78\n",
      "when's 47\n",
      "briefly 48\n",
      "2 38\n",
      "don't 93\n",
      "of 54\n",
      "3 49\n",
      "st 59\n",
      "compare 49\n",
      "british 35\n",
      "world 35\n",
      "movie 59\n",
      "average 41\n",
      "hum 32\n",
      "life 39\n",
      "once 121\n",
      "paul 32\n",
      "five 39\n",
      "just 43\n",
      "south 61\n",
      "there 112\n",
      "country 32\n",
      "pictures 50\n",
      "lord 69\n",
      "largest 42\n",
      "5 46\n",
      "david 39\n",
      "dr 34\n",
      "us 72\n",
      "three 87\n",
      "man 42\n",
      "bob 54\n",
      "there's 39\n",
      "mention 51\n",
      "take 47\n",
      "george 41\n",
      "she 33\n",
      "pirates 59\n",
      "hey 32\n",
      "words 82\n",
      "he 94\n",
      "have 33\n",
      "total 70\n",
      "pink 47\n",
      "indian 73\n",
      "best 53\n",
      "four 33\n",
      "has 53\n",
      "season 69\n",
      "god 41\n",
      "ok 39\n",
      "no 47\n",
      "every 36\n",
      "make 45\n",
      "major 51\n",
      "with 50\n",
      "advantages 37\n",
      "english 31\n",
      "can't 36\n",
      "big 50\n",
      "character 37\n",
      "you're 34\n",
      "fear 37\n",
      "full 40\n",
      "call 40\n",
      "8 32\n",
      "155225\n",
      "307373\n",
      "{'la': 41424, 'bool': 3798, 'sa': 106926, 'na': 155225}\n"
     ]
    }
   ],
   "source": [
    "def get_type(annotation):\n",
    "    if annotation['passage_answer']['candidate_index'] == -1:\n",
    "        return 'na'\n",
    "    if annotation['minimal_answer']['plaintext_start_byte'] > -1:\n",
    "        return 'sa'\n",
    "    if annotation['yes_no_answer'] != 'NONE':\n",
    "        return 'bool'\n",
    "    else:\n",
    "        return 'la'\n",
    "    \n",
    "\n",
    "sa_train_data = {}\n",
    "count_sa = 0\n",
    "na_train_data = {}\n",
    "count_na = 0\n",
    "example_ids = set()\n",
    "counts = {'la':0,'bool':0,'sa':0,'na':0}\n",
    "\n",
    "for d in train_data_full:\n",
    "    if d['example_id'] in example_ids:\n",
    "        print(f\"duplicate {d['example_id']}\")\n",
    "        continue\n",
    "    example_ids.add(d['example_id'])\n",
    "    first_word = d['question_text'].split()[0]\n",
    "    answer_type = get_type(d['annotations'][0])\n",
    "    counts[answer_type] += 1\n",
    "    if answer_type == 'sa':\n",
    "        if first_word not in sa_train_data:\n",
    "            sa_train_data[first_word] = 1\n",
    "        else:\n",
    "            sa_train_data[first_word] += 1\n",
    "        count_sa += 1\n",
    "    elif answer_type == 'na':\n",
    "        if first_word not in na_train_data:\n",
    "            na_train_data[first_word] = 1\n",
    "        else:\n",
    "            na_train_data[first_word] += 1\n",
    "        count_na += 1\n",
    "    \n",
    "\n",
    "print(count_sa)\n",
    "print(\"SA\")\n",
    "for word in sa_train_data:\n",
    "    if sa_train_data[word] > 30:\n",
    "        print(f'{word} {sa_train_data[word]}')\n",
    "print(count_na)\n",
    "print(\"NA\")\n",
    "for word in na_train_data:\n",
    "    if na_train_data[word] > 30:\n",
    "        print(f'{word} {na_train_data[word]}')\n",
    "print(count_na)\n",
    "print(len(example_ids))\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "# spacy.cli.download('en_core_web_sm')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_plaintext': \"Criminal justice - wikipedia Criminal justice Jump to : navigation , search For the 1990 film , see Criminal Justice ( film ) . For the 2008 television series , see Criminal Justice ( TV series ) . The examples and perspective in this article may not represent a worldwide view of the subject . You may improve this article , discuss the issue on the talk page , or create a new article , as appropriate . ( December 2010 ) ( Learn how and when to remove this template message ) Criminology and penology Theory ( show ) Anomie Biosocial criminology Broken windows Collective efficacy Crime analysis Criminalization Differential association Deviance Labeling theory Psychopathy Rational choice Social control Social disorganization Social learning Strain Subculture Symbolic interactionism Victimology Types of crime ( show ) Against humanity Blue - collar Corporate Juvenile Organized Political Public - order State State - corporate Victimless White - collar War Penology ( hide ) Deterrence Incapacitation Prison reform abolition Prisoner prisoner abuse prisoners ' rights Rehabilitation Recidivism Justice in penology Participatory Restorative Retributive Solitary confinement Schools ( show ) Chicago School Classical School Conflict Criminology Environmental Criminology Feminist School Frankfurt School Integrative Criminology Italian School Left Realism Marxist Criminology Neo-classical school Positivist School Postmodernist School Right Realism United States criminal justice system flowchart . Criminal Justice is the system of practices and institutions of governments directed at upholding social control , deterring and mitigating crime , or sanctioning those who violate laws with criminal penalties and rehabilitation efforts . Criminal justice is also a field of study . Those accused of crime have some protections against abuse of investigatory and prosecution powers . Criminal justice systems are very different around the world depending on the country . In the United States when a person or individual is charged of a crime they are given rights . In some countries when someone is charged with a crime there is no trial and they are immediately sentenced with no rights . In the United States the criminal justice system was taken from the British criminal justice system . Today a lot of modern countries also have adopted the British criminal justice system . In less developed countries and war - torn countries no justice system is in use . These countries often use military powers to enforce their laws , this is often the result of the killing of the individual that supposedly committed this crime with no trial given . In the United States , criminal justice policy has been guided by the 1967 President 's Commission on Law Enforcement and Administration of Justice , which issued a ground - breaking report `` The Challenge of Crime in a Free Society '' . This report made more than 200 recommendations as part of a comprehensive approach toward the prevention and fighting of crime . Some of those recommendations found their way into the Omnibus Crime Control and Safe Streets Act of 1968 . The Commission advocated a `` systems '' approach to criminal justice , with improved coordination among law enforcement , courts , and correctional agencies . The President 's Commission defined the criminal justice system as the means for society to `` enforce the standards of conduct necessary to protect individuals and the community . '' The United States justice system differs from other countries ' systems such as its rank among other systems in the world . The United States justice system ranks 19th according to the Rule of Law index that was assessed in 2014 . The United States leads however in the number of incarcerated citizens in the world ; there are 2.4 million people who are currently incarcerated . The top five countries according to the Rule of Law index are Denmark , Norway , Sweden , Finland and the Netherlands . All four of these countries practice criminal justice differently , for example Finland does not use the trial by jury system such as in the United States . Finland has found that system to be flawed and sometimes biased to the individual on trial . The criminal justice system in England and Wales aims to `` reduce crime by bringing more offences to justice , and to raise public confidence that the system is fair and will deliver for the law - abiding citizen . '' In Canada , the criminal justice system aims to balance the goals of crime control and prevention , and justice ( equity , fairness , protection of individual rights ) . In Sweden , the overarching goal for the criminal justice system is to reduce crime and increase the security of the people . In China , the justice system aims to keep the society functioning well and to protect every person 's rights . Overall , criminal justice plays a huge role throughout society as a whole in all of its locations . Contents ( hide ) 1 Law 2 Criminal justice system 2.1 Definition 2.2 Branches of the Criminal Justice system 2.3 Law enforcement 2.4 Courts 2.5 Corrections and Rehabilitation 3 Academic discipline 4 History 4.1 Modern police 5 See also 6 References 7 Further reading 8 External links Law ( edit ) The Law From Old English lagu ( something laid down or fixed ) ( Harper , Douglas . `` law '' . Online Etymology Dictionary . ) ; legal comes from Latin legalis , from lex `` law , '' `` statute '' ( Harper , Douglas . `` legal '' . Online Etymology Dictionary. ) is a system of rules usually enforced through a set of institutions . The purpose of law is to provide an objective set of rules for governing conduct and maintaining order in a society . The oldest known codified law is the Code of Hammurabi , dating back to about 1754 BC . The preface directly credits the laws to the code of hammurabi of Ur . In different parts of the world , law could be established by philosophers or religion . In the modern world , laws are typically created and enforced by governments . These codified laws may coexist with or contradict other forms of social control , such as religious proscriptions , professional rules and ethics , or the cultural mores and customs of a society . Within the realm of codified law , there are generally two forms of law that the courts are concerned with . Civil laws are rules and regulations which govern transactions and grievances between individual citizens . Criminal law is concerned with actions which are dangerous or harmful to society as a whole , in which prosecution is pursued not by an individual but rather by the state . The purpose of criminal law is to provide the specific definition of what constitutes a crime and to prescribe punishments for committing such a crime . No criminal law can be valid unless it includes both of these factors . The subject of criminal justice is , of course , primarily concerned with the enforcement of criminal law . Criminal justice system ( edit ) Definition ( edit ) The criminal justice system consists of three main parts : ( 1 ) Law Enforcement ( police officers , FBI , Department of Homeland Security , etc ... ) ; ( 2 ) Courts ( attorneys , judges , etc ... ) ; and ( 3 ) corrections ( jails , prisons , probation and parole ) . In the criminal justice system , these distinct agencies operate together both under the rule of law and as the principal means of maintaining the rule of law within society . This image shows the procedure in the criminal justice system For the purposes of section 8 ( 6 ) of the Criminal Appeal Act 1995 and section 194A ( 6 ) of the Criminal Procedure ( Scotland ) Act 1995 , the criminal justice system includes , in particular , the investigation of offences and the treatment of offenders . Branches of the criminal justice system ( edit ) There are three branches of the Criminal Justice system . 1 . ) The first being police / Law enforcement , the law enforcement branch enforces the laws in their state , county , or assigned jurisdiction . The main purpose for law enforcement officers is to uphold their country 's , state 's , or local laws . The Definition of Law Enforcement : Law enforcement describes the individuals and agencies responsible for enforcing laws and maintaining public order and public safety . Law enforcement includes the prevention , detection , and investigation of crime , and the apprehension and detention of individuals suspected of law violation . 2 . ) Courts uphold the law in ways to prevent them from being broken in the future . When an individual is charged by law enforcement it is the courts job to determine if the charges are justified and if so what punishments are required to make sure or help prevent the individual or individuals from proceeding to commit the crime or crimes again in the future . The definition of a court : Government entity authorized to resolve legal disputes . Judges sometimes use `` court '' to refer to themselves in the third person , as in `` the court has read the briefs . '' 3 . ) The third branch of the criminal justice system is corrections , the correctional branch duties are to make sure that the punishment or in some cases rehabilitation is seen through until the end of the determined sentence provided by the judge ( Courts ) . Definition of corrections : Institutional corrections refers to those persons housed in secure correctional facilities . There are many different types of correctional facilities , operated by different government entities . Local jails are operated by county or municipal authorities , and typically hold offenders for short periods ranging from a single day to a year . Law enforcement ( edit ) Main article : Law enforcement The first contact a defendant has with the criminal justice system is usually with the police ( or law enforcement ) who investigate the suspected wrongdoing and make an arrest , but if the suspect is dangerous to the whole nation , a national level law enforcement agency is called in . When warranted , law enforcement agencies or police officers are empowered to use force and other forms of legal coercion and means to effect public and social order . The term is most commonly associated with police departments of a state that are authorized to exercise the police power of that state within a defined legal or territorial area of responsibility . The word comes from the Latin politia ( `` civil administration '' ) , which itself derives from the Ancient Greek πόλις , for polis ( `` city '' ) . The first police force comparable to the present - day police was established in 1667 under King Louis XIV in France , although modern police usually trace their origins to the 1800 establishment of the Marine Police in London , the Glasgow Police , and the Napoleonic police of Paris . Police are primarily concerned with keeping the peace and enforcing criminal law based on their particular mission and jurisdiction . Formed in 1908 , the Federal Bureau of Investigation began as an entity which could investigate and enforce specific federal laws as an investigative and `` law enforcement agency '' in the United States ; this , however , has constituted only a small portion of overall policing activity . Policing has included an array of activities in different contexts , but the predominant ones are concerned with order maintenance and the provision of services . During modern times , such endeavors contribute toward fulfilling a shared mission among law enforcement organizations with respect to the traditional policing mission of deterring crime and maintaining societal order . Courts ( edit ) Main article : Court A trial at the Old Bailey in London , c. 1808 The courts serve as the venue where disputes are then settled and justice is administered . With regard to criminal justice , there are a number of critical people in any court setting . These critical people are referred to as the courtroom work group and include both professional and non professional individuals . These include the judge , prosecutor , and the defense attorney . The judge , or magistrate , is a person , elected or appointed , who is knowledgeable in the law , and whose function is to objectively administer the legal proceedings and offer a final decision to dispose of a case . In the U.S. and in a growing number of nations , guilt or innocence ( although in the U.S. a jury can never find a defendant `` innocent '' but rather `` not guilty '' ) is decided through the adversarial system . In this system , two parties will both offer their version of events and argue their case before the court ( sometimes before a judge or panel of judges , sometimes before a jury ) . The case should be decided in favor of the party who offers the most sound and compelling arguments based on the law as applied to the facts of the case . The prosecutor , or district attorney , is a lawyer who brings charges against a person , persons or corporate entity . It is the prosecutor 's duty to explain to the court what crime was committed and to detail what evidence has been found which incriminates the accused . The prosecutor should not be confused with a plaintiff or plaintiff 's counsel . Although both serve the function of bringing a complaint before the court , the prosecutor is a servant of the state who makes accusations on behalf of the state in criminal proceedings , while the plaintiff is the complaining party in civil proceedings . A defense attorney counsels the accused on the legal process , likely outcomes for the accused and suggests strategies . The accused , not the lawyer , has the right to make final decisions regarding a number of fundamental points , including whether to testify , and to accept a plea offer or demand a jury trial in appropriate cases . It is the defense attorney 's duty to represent the interests of the client , raise procedural and evidentiary issues , and hold the prosecution to its burden of proving guilt beyond a reasonable doubt . Defense counsel may challenge evidence presented by the prosecution or present exculpatory evidence and argue on behalf of their client . At trial , the defense attorney may attempt to offer a rebuttal to the prosecutor 's accusations . In the U.S. , an accused person is entitled to a government - paid defense attorney if he or she is in jeopardy of losing his or her life and / or liberty . Those who can not afford a private attorney may be provided one by the state . Historically , however , the right to a defense attorney has not always been universal . For example , in Tudor England criminals accused of treason were not permitted to offer arguments in their defense . In many jurisdictions , there is no right to an appointed attorney , if the accused is not in jeopardy of losing his or her liberty . The final determination of guilt or innocence is typically made by a third party , who is supposed to be disinterested . This function may be performed by a judge , a panel of judges , or a jury panel composed of unbiased citizens . This process varies depending on the laws of the specific jurisdiction . In some places the panel ( be it judges or a jury ) is required to issue a unanimous decision , while in others only a majority vote is required . In America , this process depends on the state , level of court , and even agreements between the prosecuting and defending parties . Some nations do not use juries at all , or rely on theological or military authorities to issue verdicts . Some cases can be disposed of without the need for a trial . In fact , the vast majority are . If the accused confesses his or her guilt , a shorter process may be employed and a judgment may be rendered more quickly . Some nations , such as America , allow plea bargaining in which the accused pleads guilty , nolo contendere or not guilty , and may accept a diversion program or reduced punishment , where the prosecution 's case is weak or in exchange for the cooperation of the accused against other people . This reduced sentence is sometimes a reward for sparing the state the expense of a formal trial . Many nations do not permit the use of plea bargaining , believing that it coerces innocent people to plead guilty in an attempt to avoid a harsh punishment . The entire trial process , whatever the country , is fraught with problems and subject to criticism . Bias and discrimination form an ever - present threat to an objective decision . Any prejudice on the part of the lawyers , the judge , or jury members threatens to destroy the court 's credibility . Some people argue that the often Byzantine rules governing courtroom conduct and processes restrict a layman 's ability to participate , essentially reducing the legal process to a battle between the lawyers . In this case , the criticism is that the decision is based less on sound justice and more on the lawyer 's eloquence and charisma . This is a particular problem when the lawyer performs in a substandard manner . The jury process is another area of frequent criticism , as there are few mechanisms to guard against poor judgment or incompetence on the part of the layman jurors . Judges themselves are very subject to bias subject to things as ordinary as the length of time since their last break . Manipulations of the court system by defense and prosecution attorneys , law enforcement as well as the defendants have occurred and there have been cases where justice was denied . Corrections and rehabilitation ( edit ) The Huntsville Unit of the Texas Department of Criminal Justice in Huntsville , Texas is a prison , a component of a corrections system Main article : Corrections Offenders are then turned over to the correctional authorities , from the court system after the accused has been found guilty . Like all other aspects of criminal justice , the administration of punishment has taken many different forms throughout history . Early on , when civilizations lacked the resources necessary to construct and maintain prisons , exile and execution were the primary forms of punishment . Historically shame punishments and exile have also been used as forms of censure . The most publicly visible form of punishment in the modern era is the prison . Prisons may serve as detention centers for prisoners after trial . For containment of the accused , jails are used . Early prisons were used primarily to sequester criminals and little thought was given to living conditions within their walls . In America , the Quaker movement is commonly credited with establishing the idea that prisons should be used to reform criminals . This can also be seen as a critical moment in the debate regarding the purpose of punishment . Qur'anic education for offenders at the Central Jail Faisalabad in Faisalabad , Pakistan Punishment ( in the form of prison time ) may serve a variety of purposes . First , and most obviously , the incarceration of criminals removes them from the general population and inhibits their ability to perpetrate further crimes . A new goal of prison punishments is to offer criminals a chance to be rehabilitated . Many modern prisons offer schooling or job training to prisoners as a chance to learn a vocation and thereby earn a legitimate living when they are returned to society . Religious institutions also have a presence in many prisons , with the goal of teaching ethics and instilling a sense of morality in the prisoners . If a prisoner is released before his time is served , he is released as a parole . This means that they are released , but the restrictions are greater than that of someone on probation . There are numerous other forms of punishment which are commonly used in conjunction with or in place of prison terms . Monetary fines are one of the oldest forms of punishment still used today . These fines may be paid to the state or to the victims as a form of reparation . Probation and house arrest are also sanctions which seek to limit a person 's mobility and his or her opportunities to commit crimes without actually placing them in a prison setting . Furthermore , many jurisdictions may require some form of public or community service as a form of reparations for lesser offenses . In Corrections , the Department ensures court - ordered , pre-sentence chemical dependency assessments , related Drug Offender Sentencing Alternative specific examinations and treatment will occur for offenders sentenced to Drug Offender Sentencing Alternative in compliance with RCW 9.94 A. 660 . Execution or capital punishment is still used around the world . Its use is one of the most heavily debated aspects of the criminal justice system . Some societies are willing to use executions as a form of political control , or for relatively minor misdeeds . Other societies reserve execution for only the most sinister and brutal offenses . Others still have discontinued the practice entirely , believing the use of execution to be excessively cruel or. ( ACJS ) 1963 JUSTICE SCIENCES 2015 - 04 - 25 . 2015 - 05 - 07 ACJS HISTORY 243 - 252 CRIMINAL JUSTICE. 4 : 243 - 2546790 Academic discipline ( edit ) The functional study of criminal justice is distinct from criminology , which involves the study of crime as a social phenomenon , causes of crime , criminal behavior , and other aspects of crime . It emerged as an academic discipline in the 1920s , beginning with Berkeley police chief August Vollmer who established a criminal justice program at the University of California , Berkeley in 1916 . Vollmer 's work was carried on by his student , O.W. Wilson , who led efforts to professionalize policing and reduce corruption . Other programs were established in the United States at Indiana University , Michigan State University , San Jose State University , and the University of Washington . As of 1950 , criminal justice students were estimated to number less than 1,000 . Until the 1960s , the primary focus of criminal justice in the United States was on policing and police science . Throughout the 1960s and 1970s , crime rates soared and social issues took center stage in the public eye . A number of new laws and studies focused federal resources on researching new approaches to crime control . The Warren Court ( the Supreme Court under Chief Justice Earl Warren ) , issued a series of rulings which redefined citizen 's rights and substantially altered the powers and responsibilities of police and the courts . The Civil Rights Era offered significant legal and ethical challenges to the status quo . In the late 1960s , with the establishment of the Law Enforcement Assistance Administration ( LEAA ) and associated policy changes that resulted with the Omnibus Crime Control and Safe Streets Act of 1968 . The LEAA provided grants for criminology research , focusing on social aspects of crime . By the 1970s , there were 729 academic programs in criminology and criminal justice in the United States . Largely thanks to the Law Enforcement Education Program , criminal justice students numbered over 100,000 by 1975 . Over time , scholars of criminal justice began to include criminology , sociology , and psychology , among others , to provide a more comprehensive view of the criminal justice system and the root causes of crime . Criminal justice studies now combine the practical and technical policing skills with a study of social deviance as a whole . Criminal justice degree programs at four - year institutions typically include coursework in statistics , methods of research , criminal justice , policing , U.S court systems , criminal courts , corrections , community corrections , criminal procedure , criminal law , victimology , juvenile justice , and a variety of special topics . A number of universities offer a Bachelor of Criminal Justice . History ( edit ) Main article : History of criminal justice Prisoners at a whipping post in a Delaware prison , c. 1907 The modern criminal justice system has evolved since ancient times , with new forms of punishment , added rights for offenders and victims , and policing reforms . These developments have reflected changing customs , political ideals , and economic conditions . In ancient times through the Middle Ages , exile was a common form of punishment . During the Middle Ages , payment to the victim ( or the victim 's family ) , known as wergild , was another common punishment , including for violent crimes . For those who could not afford to buy their way out of punishment , harsh penalties included various forms of corporal punishment . These included mutilation , branding , and flogging , as well as execution . Though a prison , Le Stinche , existed as early as the 14th century in Florence , Italy , incarceration was not widely used until the 19th century . Correctional reform in the United States was first initiated by William Penn , towards the end of the 17th century . For a time , Pennsylvania 's criminal code was revised to forbid torture and other forms of cruel punishment , with jails and prisons replacing corporal punishment . These reforms were reverted , upon Penn 's death in 1718 . Under pressure from a group of Quakers , these reforms were revived in Pennsylvania toward the end of the 18th century , and led to a marked drop in Pennsylvania 's crime rate . Patrick Colquhoun , Henry Fielding and others led significant reforms during the late eighteenth and early nineteenth centuries . The first official criminal justice systems was created by the British during the American revolution , they created the system to primarily justify hangings to the citizens of their government . In each selected area or / and district there was a magistrate that in today 's time would be known as a judge . These individuals were in charge of determining if the Crown or also known as the British government had enough evidence to hang an individual for a crime . The British would not always hang an individual for committing a crime , there would also be trials for punishments that would be carried out by cleaning ships , prison ships , or be locked up on British mainland . During the American revolution the primary type of punishment was to be hanged or sent to prison ships such as the notorious HMS Jersey . After the American revolution the British - based Criminal justice system was then adopted by other developing nations ( Such as the United States ) . Modern police ( edit ) The first modern police force is commonly said to be the Metropolitan Police in London , established in 1829 by Sir Robert Peel . Based on the Peelian principles , it promoted the preventive role of police as a deterrent to urban crime and disorder . In the United States , police departments were first established in Boston in 1838 , and New York City in 1844 . Early on , police were not respected by the community , as corruption was rampant . In the 1920s , led by Berkeley , California police chief , August Vollmer and O.W. Wilson , police began to professionalize , adopt new technologies , and place emphasis on training and professional qualifications of new hires . Despite such reforms , police agencies were led by highly autocratic leaders , and there remained a lack of respect between police and the community . Following urban unrest in the 1960s , police placed more emphasis on community relations , enacted reforms such as increased diversity in hiring , and many police agencies adopted community policing strategies . In the 1990s , CompStat was developed by the New York Police Department as an information - based system for tracking and mapping crime patterns and trends , and holding police accountable for dealing with crime problems . CompStat has since been replicated in police departments across the United States and around the world , with problem - oriented policing , intelligence - led policing , and other information - led policing strategies also adopted . See also ( edit ) Outline of criminal justice -- structured list of topics related to criminal justice , organized by subject area Criminal justice ethics Criminal justice reform Academy of Criminal Justice Sciences Criminal responsibility in French law References ( edit ) Jump up ^ Walker , Samuel ( 1992 ) . `` Origins of the Contemporary Criminal Justice Paradigm : The American Bar Foundation Survey , 1953 - 1969 '' . Justice Quarterly . 9 ( 1 ) : 47 -- 76 . doi : 10.1080 / 07418829200091251 . Jump up ^ President 's Commission on Law Enforcement and Administration of Justice ( 1967 ) . The Challenge of Crime in a Free Society . U.S. Government Printing Office . ISBN 0 - 306 - 70124 - 3 . ^ Jump up to : `` Criminal Justice - Aims and Objectives '' . Scottish Executive Consultations . Archived from the original on 2006 - 10 - 13 . Jump up ^ Schmolka , Vicki . `` Principles to Guide Criminal Law Reform '' . Department of Justice , Government of Canada . Jump up ^ http://www.correctionalofficer.org/us-criminal-justice-system Jump up ^ The Criminal Appeal Act 1995 , section 8 ( 6 ) ; The Criminal Procedure ( Scotland ) Act 1995 , section 194A ( 6 ) Jump up ^ Harper , Douglas . `` police '' . Online Etymology Dictionary . Retrieved 2007 - 02 - 08 . Jump up ^ Dinsmor , Alastair ( Winter 2003 ) . `` Glasgow Police Pioneers '' . The Scotia News . Archived from the original on 2009 - 07 - 16 . Retrieved 2007 - 01 - 10 . Jump up ^ `` History '' . Marine Support Unit . Metropolitan Police . Archived from the original on 2007 - 07 - 16 . Retrieved 2007 - 02 - 10 . Jump up ^ `` La Lieutenance Générale de Police '' . La Préfecture de Police fête ses 200 ans Juillet 1800 - Juillet 2000 . La Préfecture de Police au service des Parisiens . Jump up ^ FBI ( 2009 ) . THE FBI : A Centennial History , 1908 - 2008 . Washington , D.C. : FBI . p. 138 . ISBN 978 - 0 - 16 - 080954 - 5 . Jump up ^ Walker , Samuel ( 1977 ) . A Critical History of Police Reform : The Emergence of Professionalism . Lexington , MT : Lexington Books . p. 143 . ISBN 0 - 669 - 01292 - 0 . Jump up ^ Neocleous , Mark ( 2004 ) . Fabricating Social Order : A Critical History of Police Power . London : Pluto Press . pp. 93 -- 94 . ISBN . Jump up ^ McElreath , David ; Doss , Daniel ; Jensen , Carl ; Wigginton , Michael ; Kennedy , Ralph ; Winter , Kenneth ; Mongue , Robert ; Bounds , Janice ; Estis - Sumerel , J. Michelle ( 2013 ) . Introduction to Law Enforcement ( 1 ed . ) . Boca Raton , Florida : CRC Press . p. 87 . ISBN 978 - 1466556232 . Jump up ^ `` We find that the percentage of favorable rulings drops gradually from ≈ 65 % to nearly zero within each decision session and returns abruptly to ≈ 65 % after a break . '' Shai Danzigera ; Jonathan Levav ; Liora Avnaim - Pessoa ( 11 April 2011 ) . `` Extraneous factors in judicial decisions '' . Proceedings of the National Academy of Sciences of the United States of America . 108 ( 17 ) : 6889 -- 92 . Bibcode : 2011PNAS ... 108.6889 D . doi : 10.1073 / pnas. 1018033108 . PMC 3084045 . PMID 21482790 . Retrieved 15 November 2011 . Jump up ^ Perri , Frank S. ; Lichtenwald , Terrance G. ( 2009 ) . `` When Worlds Collide : Criminal Investigative Analysis , Forensic Psychology And the Timothy Masters Case '' ( PDF ) . Forensic Examiner. 18 ( 2 ) : 226972 . Jump up ^ Perri , Frank S. ; Lichtenwald , Terrance G. ( 2010 ) . `` The Last Frontier : Myths & The Female Psychopathic Killer '' ( PDF ) . Forensic Examiner. 19 ( 2 ) : 50 -- 67 . Jump up ^ `` Finest of the Finest '' . TIME Magazine . February 18 , 1966 . Archived from the original on 2008 - 10 - 14 . ^ Jump up to : Savelsberg , Joachim J. , Lara L. Cleveland , Ryan D. King ; Cleveland ; King ( June 2004 ) . `` Institutional Environments and Scholarly Work : American Criminology , 1951 - 1993 '' . Social Forces . 82 ( 4 ) : 1275 -- 1302 . doi : 10.1353 / sof. 2004.0093 . CS1 maint : Multiple names : authors list ( link ) Jump up ^ Wolfgang , Marvin ( 1990 ) . `` Crime and Punishment in Renaissance Florence '' . Journal of Criminal Law and Criminology . Northwestern University . 81 ( 3 ) : 567 -- 84 . doi : 10.2307 / 1143848 . JSTOR 1143848 . Jump up ^ Garland , David ( 2002 ) . `` Of Crimes and Criminals '' . In Maguire , Mike ; Rod Morgan ; Robert Reiner . The Oxford Handbook of Criminology , 3rd edition . Oxford University Press . p. 20 . Jump up ^ Terrill , Richard J. ( 2015 ) . World Criminal Justice Systems : A Comparative Survey ( revised ed . ) . Routledge . p. 32 . ISBN 1317228820 . Jump up ^ Dempsey , John S. ; Forst , Linda S. ( 2015 ) . An Introduction to Policing ( 8 ed . ) . Cengage Learning . pp. 6 -- 8 . ISBN 1305544684 . Jump up ^ Brodeur , Jean - Paul ; Eds. , Kevin R.E. McCormick and Livy A. Visano ( 1992 ) . `` High Policing and Low Policing : Remarks about the Policing of Political Activities , '' Understanding Policing . Toronto : Canadian Scholars ' Press . pp. 284 -- 285 , 295 . ISBN . Jump up ^ `` Policing by consent '' . UK Government . 10 December 2012 . Retrieved 29 December 2013 . Further reading ( edit ) Dale , Elizabeth . Criminal Justice in the United States , 1789 -- 1939 ( Cambridge University Press , 2011 ) 184 pp Fuller , John Randolph . Criminal Justice : Mainstream and Crosscurrents 2005 . Prentice Hall . Upper Saddle River , NJ . Serge Guinchard and Jacques Buisson . Criminal procedural law in France Lexinexis editor , 7th edition , September 2011 , 1584 pages . Hanes , Richard C. and Sharon M. Hanes . Crime and Punishment in America . Volume 1 . 2005 . Thomas Gale . Farmington Hills , MI Friedman , Lawrence M. Crime and Punishment in American History . 1993 . Basic Books . New York , NY . Sunga , Lyal S . The Emerging System of International Criminal Law : Developments in Codification and Implementation , 1997 . Kluwer Law International . The Hague , The Netherlands . Walker , Samuel Popular Justice : A History of American Criminal Justice . 1980 . Oxford University Press , Inc . New York External links ( edit ) Wikiquote has quotations related to : Criminal justice Academy of Criminal Justice Sciences The International Center for Transitional Justice 's ( ICTJ ) Criminal Justice Page Scottish Centre for Crime and Justice Research , a well - respected academic research centre focusing on crime and justice issues . Social sciences Primary Anthropology archaeology cultural linguistics social Economics microeconomics macroeconomics Geography human integrative History cultural economic military political social Law jurisprudence legal history legal systems Political science international relations psephology public administration public policy Psychology abnormal biological cognitive developmental personality social Sociology criminology demography internet rural urban Interdisciplinary Anthrozoology Area studies Business studies Cognitive science Communication studies Community studies Cultural studies Development studies Education Environmental ( social science studies ) Food studies Gender studies Global studies History of technology Human ecology Information science International studies Media studies Philosophy of science economics history psychology social science Planning land use regional urban Political ecology Political economy Public health Regional science Science and technology studies Science studies historical Social work Other categorizations Humanities Geisteswissenschaft Human science Index Journals Outline Wikiversity Types of justice In philosophy Commutative Distributive Divine Interactional Global Natural Organizational Procedural Restorative Retributive Social Transformative Victor 's Substantive areas Climate Criminal Environmental Gender Military Racial Resource Spatial Trade Other Frontier Poetic Criminal justice portal Retrieved from `` https://en.wikipedia.org/w/index.php?title=Criminal_justice&oldid=824790209 '' Categories : Criminal justice Criminal law Justice Hidden categories : CS1 maint : Multiple names : authors list Articles with limited geographic scope from December 2010 All articles with unsourced statements Articles with unsourced statements from March 2017 Articles with unsourced statements from June 2007 Talk Contents About Wikipedia Wikiquote Čeština Deutsch हिन्दी Lietuvių Русский Slovenčina Српски / srpski Svenska Tagalog Тоҷикӣ Українська Winaray Edit links This page was last edited on 9 February 2018 , at 14 : 30 . Text is available under the Creative Commons Attribution - ShareAlike License ; additional terms may apply . By using this site , you agree to the Terms of Use and Privacy Policy . Wikipedia ® is a registered trademark of the Wikimedia Foundation , Inc. , a non-profit organization . About Wikipedia \",\n",
       " 'document_title': 'Criminal justice',\n",
       " 'document_url': 'https://en.wikipedia.org//w/index.php?title=Criminal_justice&amp;oldid=824790209',\n",
       " 'example_id': -2664875860902576660,\n",
       " 'language': 'english',\n",
       " 'question_text': 'what is the purpose of the united states criminal justice system',\n",
       " 'passage_answer_candidates': [{'plaintext_start_byte': 198,\n",
       "   'plaintext_end_byte': 478},\n",
       "  {'plaintext_start_byte': 198, 'plaintext_end_byte': 478},\n",
       "  {'plaintext_start_byte': 479, 'plaintext_end_byte': 1461},\n",
       "  {'plaintext_start_byte': 479, 'plaintext_end_byte': 503},\n",
       "  {'plaintext_start_byte': 504, 'plaintext_end_byte': 800},\n",
       "  {'plaintext_start_byte': 520, 'plaintext_end_byte': 800},\n",
       "  {'plaintext_start_byte': 801, 'plaintext_end_byte': 963},\n",
       "  {'plaintext_start_byte': 825, 'plaintext_end_byte': 963},\n",
       "  {'plaintext_start_byte': 842, 'plaintext_end_byte': 855},\n",
       "  {'plaintext_start_byte': 895, 'plaintext_end_byte': 909},\n",
       "  {'plaintext_start_byte': 916, 'plaintext_end_byte': 933},\n",
       "  {'plaintext_start_byte': 945, 'plaintext_end_byte': 959},\n",
       "  {'plaintext_start_byte': 964, 'plaintext_end_byte': 1179},\n",
       "  {'plaintext_start_byte': 982, 'plaintext_end_byte': 1179},\n",
       "  {'plaintext_start_byte': 982, 'plaintext_end_byte': 1100},\n",
       "  {'plaintext_start_byte': 982, 'plaintext_end_byte': 1100},\n",
       "  {'plaintext_start_byte': 1008, 'plaintext_end_byte': 1031},\n",
       "  {'plaintext_start_byte': 1015, 'plaintext_end_byte': 1031},\n",
       "  {'plaintext_start_byte': 1032, 'plaintext_end_byte': 1074},\n",
       "  {'plaintext_start_byte': 1041, 'plaintext_end_byte': 1074},\n",
       "  {'plaintext_start_byte': 1056, 'plaintext_end_byte': 1074},\n",
       "  {'plaintext_start_byte': 1101, 'plaintext_end_byte': 1120},\n",
       "  {'plaintext_start_byte': 1121, 'plaintext_end_byte': 1179},\n",
       "  {'plaintext_start_byte': 1121, 'plaintext_end_byte': 1179},\n",
       "  {'plaintext_start_byte': 1180, 'plaintext_end_byte': 1454},\n",
       "  {'plaintext_start_byte': 1197, 'plaintext_end_byte': 1454},\n",
       "  {'plaintext_start_byte': 1505, 'plaintext_end_byte': 2652},\n",
       "  {'plaintext_start_byte': 2653, 'plaintext_end_byte': 3472},\n",
       "  {'plaintext_start_byte': 3473, 'plaintext_end_byte': 4221},\n",
       "  {'plaintext_start_byte': 4222, 'plaintext_end_byte': 4949},\n",
       "  {'plaintext_start_byte': 5247, 'plaintext_end_byte': 5698},\n",
       "  {'plaintext_start_byte': 5699, 'plaintext_end_byte': 6223},\n",
       "  {'plaintext_start_byte': 6224, 'plaintext_end_byte': 6946},\n",
       "  {'plaintext_start_byte': 7000, 'plaintext_end_byte': 7448},\n",
       "  {'plaintext_start_byte': 7506, 'plaintext_end_byte': 7764},\n",
       "  {'plaintext_start_byte': 7814, 'plaintext_end_byte': 7871},\n",
       "  {'plaintext_start_byte': 7872, 'plaintext_end_byte': 8456},\n",
       "  {'plaintext_start_byte': 8457, 'plaintext_end_byte': 9028},\n",
       "  {'plaintext_start_byte': 9029, 'plaintext_end_byte': 9663},\n",
       "  {'plaintext_start_byte': 9720, 'plaintext_end_byte': 10815},\n",
       "  {'plaintext_start_byte': 10816, 'plaintext_end_byte': 11623},\n",
       "  {'plaintext_start_byte': 11707, 'plaintext_end_byte': 12309},\n",
       "  {'plaintext_start_byte': 12310, 'plaintext_end_byte': 12861},\n",
       "  {'plaintext_start_byte': 12862, 'plaintext_end_byte': 13472},\n",
       "  {'plaintext_start_byte': 13473, 'plaintext_end_byte': 14250},\n",
       "  {'plaintext_start_byte': 14251, 'plaintext_end_byte': 14826},\n",
       "  {'plaintext_start_byte': 14827, 'plaintext_end_byte': 15520},\n",
       "  {'plaintext_start_byte': 15521, 'plaintext_end_byte': 16289},\n",
       "  {'plaintext_start_byte': 16290, 'plaintext_end_byte': 17300},\n",
       "  {'plaintext_start_byte': 17301, 'plaintext_end_byte': 17482},\n",
       "  {'plaintext_start_byte': 17686, 'plaintext_end_byte': 18183},\n",
       "  {'plaintext_start_byte': 18184, 'plaintext_end_byte': 18742},\n",
       "  {'plaintext_start_byte': 18823, 'plaintext_end_byte': 19650},\n",
       "  {'plaintext_start_byte': 19651, 'plaintext_end_byte': 20542},\n",
       "  {'plaintext_start_byte': 20543, 'plaintext_end_byte': 21123},\n",
       "  {'plaintext_start_byte': 21153, 'plaintext_end_byte': 22044},\n",
       "  {'plaintext_start_byte': 22045, 'plaintext_end_byte': 22569},\n",
       "  {'plaintext_start_byte': 22570, 'plaintext_end_byte': 23430},\n",
       "  {'plaintext_start_byte': 23431, 'plaintext_end_byte': 23831},\n",
       "  {'plaintext_start_byte': 23952, 'plaintext_end_byte': 24664},\n",
       "  {'plaintext_start_byte': 24665, 'plaintext_end_byte': 25463},\n",
       "  {'plaintext_start_byte': 25464, 'plaintext_end_byte': 26433},\n",
       "  {'plaintext_start_byte': 26457, 'plaintext_end_byte': 26904},\n",
       "  {'plaintext_start_byte': 26905, 'plaintext_end_byte': 27496},\n",
       "  {'plaintext_start_byte': 27497, 'plaintext_end_byte': 27952}],\n",
       " 'annotations': [{'annotation_id': 3021990374539598574,\n",
       "   'minimal_answer': {'plaintext_start_byte': 3356,\n",
       "    'plaintext_end_byte': 3472},\n",
       "   'passage_answer': {'candidate_index': 27},\n",
       "   'yes_no_answer': 'NONE'}],\n",
       " 'type': ['la']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "train_files = glob.glob(\"/dccstor/srosent2/primeqa/data/nq-lfqa-train/*.jsonl\")\n",
    "train_data_long = []\n",
    "for train_file in train_files:\n",
    "    train_data_long.extend(load_json_from_file(train_file))\n",
    "\n",
    "train_data_long[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_plaintext': \"Agriculture in the United States - wikipedia Agriculture in the United States Jump to : navigation , search A wheat harvest in Idaho This photo from a 1921 encyclopedia shows a tractor plowing a crop field . Agriculture is a major industry in the United States , which is a net exporter of food . As of the 2007 census of agriculture , there were 2.2 million farms , covering an area of 922 million acres ( 3,730,000 km ) , an average of 418 acres ( 169 hectares ) per farm . Although agricultural activity occurs in all states , it is particularly concentrated in the Great Plains , a vast expanse of flat , arable land in the center of the United States and in the region around the Great Lakes known as the Corn Belt . The United States was a leader in seed improvement i.e. hybridization and in expanding uses for crops from the work of George Washington Carver to the development of bioplastics and biofuels . The mechanization of farming and intensive farming have been major themes in U.S. history , including John Deere 's steel plow , Cyrus McCormick 's mechanical reaper , Eli Whitney 's cotton gin to the widespread success of the Fordson tractor and the combine harvesters first made from them . Modern agriculture in the U.S. ranges from the common hobby farms , small - scale producers to large commercial farming covering thousands of acres of cropland or rangeland . Contents ( hide ) 1 History 2 Major agricultural products 2.1 Crops 2.1. 1 Value of production 2.1. 2 Yield 2.2 Livestock 3 Farm type or majority enterprise type 4 Governance 5 Employment 6 Occupational safety and health 6.1 Research centers 7 Women in agriculture 7.1 Pesticide exposure in relationship to female agricultural workers 7.2 Health effects 7.3 Epigenetic effects 7.4 Scientific limitations 7.5 Challenges and means of exposure 7.6 Occupational Safety 7.7 Home Safety 7.8 Social Determinants of Health 7.9 Socioeconomic challenges 7.10 Policy implications 8 See also 9 Additional reading 10 References 11 External links History ( edit ) Main article : History of agriculture in the United States Cotton farming on a Southern plantation in 1921 Corn , turkeys , tomatoes , potatoes , peanuts , and sunflower seeds constitute some of the major holdovers from the agricultural endowment of the Americas . European agricultural practices greatly affected the New England landscape . Colonists brought livestock over from Europe which caused many changes to the land . Grazing animals required a lot of land and food and the act of grazing itself destroyed native grasses , which were being replaced by European species . New species of weeds were introduced and began to thrive as they were capable of withstanding the grazing of animals , whereas native species could not . The practices associated with keeping livestock also contributed to the deterioration of the forests and fields . Colonists would cut down the trees and then allow their cattle and livestock to graze freely in the forest and never plant more trees . The animals trampled and tore up the ground so much as to cause long - term destruction and damage . Soil exhaustion was a huge problem in New England agriculture . Farming with oxen did allow the colonist to farm more land but it increased erosion and decreased soil fertility . This was due to deeper plow cuts in the soil that allowed the soil more contact with oxygen causing nutrient depletion . In grazing fields , the large number of cattle in the New England , the soil was being compacted by the cattle and this did not give the soil enough oxygen to sustain life . In the United States , farms spread from the colonies westward along with the settlers . In cooler regions , wheat was often the crop of choice when lands were newly settled , leading to a `` wheat frontier '' that moved westward over the course of years . Also very common in the antebellum Midwest was farming corn while raising hogs , complementing each other especially since it was difficult to get grain to market before the canals and railroads . After the `` wheat frontier '' had passed through an area , more diversified farms including dairy cattle generally took its place . Warmer regions saw plantings of cotton and herds of beef cattle . In the early colonial south , raising tobacco and cotton was common , especially through the use of slave labor until the Civil War . In the northeast , slaves were used in agriculture until the early 19th century . In the Midwest , slavery was prohibited by the Freedom Ordinance of 1787 . The introduction and broad adoption of scientific agriculture since the mid-19th century contributed to economic growth in the United States . This development was facilitated by the Morrill Act and the Hatch Act of 1887 which established in each state a land - grant university ( with a mission to teach and study agriculture ) and a federally funded system of agricultural experiment stations and cooperative extension networks which place extension agents in each state . Soybeans were not widely cultivated in the United States until the early 1930s , and by 1942 it became the world 's largest soybean producer , due in part to World War II and the `` need for domestic sources of fats , oils , and meal '' . Between 1930 and 1942 , the United States ' share of world soybean production skyrocketed from 3 % to 46.5 % , and by 1969 it had risen to 76 % . By 1973 soybeans were the United States ' `` number one cash crop , and leading export commodity , ahead of both wheat and corn '' . Significant areas of farmland were abandoned during the Great Depression and incorporated into nascent national forests . Later , `` Sodbuster '' and `` Swampbuster '' restrictions written into federal farm programs starting in the 1970s reversed a decades - long trend of habitat destruction that began in 1942 when farmers were encouraged to plant all possible land in support of the war effort . In the United States , federal programs administered through local Soil and Water Conservation Districts provide technical assistance and partial funding to farmers who wish to implement management practices to conserve soil and limit erosion and floods . Major agricultural products ( edit ) Satellite image of circular crop fields characteristic of center pivot irrigation in Kansas ( June 2001 ) . Tonnes of United States agriculture production , as reported by the FAO in 2003 and 2013 ( ranked roughly in order of value ) : Millions of Tonnes in 2003 2013 Corn 256.0 354.0 Cattle meat 12.0 11.7 Cow 's milk , whole , fresh 77.0 91.0 Chicken meat 14.7 17.4 Soybeans 67.0 89.0 Pig meat 9.1 10.5 Wheat 64.0 58.0 Cotton lint 4.0 2.8 Hen eggs 5.2 5.6 Turkey meat 2.5 2.6 Tomatoes 11.4 12.6 Potatoes 20.8 19.8 Grapes 5.9 7.7 Oranges 10.4 7.6 Rice , paddy 9.1 8.6 Apples 3.9 4.1 Sorghum 10.4 9.9 Lettuce 4.7 3.6 Cottonseed 6.0 5.6 Sugar beets 30.7 29.8 The only other crops to ever appear in the top 20 in the last 40 years were , commonly : tobacco , barley , and oats , and , rarely : peanuts , almonds , and sunflower seeds . Alfalfa and hay would both be in the top ten in 2003 if they were tracked by FAO . Crops ( edit ) Value of production ( edit ) Rice paddy , California Major Crops in the USA 1997 ( in US $ billions ) 2014 ( in US $ billions ) Corn $24.4 $52.4 Soybeans $17.7 $40.3 Wheat $8.6 $11.9 Alfalfa $8.3 $10.8 Cotton $6.1 $5.1 Hay , ( non-Alfalfa ) $5.1 $8.4 Tobacco $3.0 $1.8 Rice $1.7 $3.1 Sorghum $1.4 $1.7 Barley $. 9 $. 9 Source 1997 USDA - NASS reports , 2015 USDA - NASS reports , Note alfalfa and hay are not tracked by the FAO and the production of tobacco in the United States has fallen 60 % between 1997 and 2003 . Yield ( edit ) Heavily mechanized , U.S. agriculture has a high yield relative to other countries . As of 2004 : Corn for grain , average of 160.4 bushels harvested per acre ( 10.07 t / ha ) Soybean for beans , average of 42.5 bushels harvested per acre ( 2.86 t / ha ) Wheat , average of 43.2 bushels harvested per acre ( 2.91 t / ha , was 44.2 bu / ac or 2.97 t / ha in 2003 ) Livestock ( edit ) Density of cattle and calves by county in 2007 . The major livestock industries in the United States : Dairy cattle Beef cattle Pig Poultry Sheep U.S. livestock and poultry inventory Type 1997 2002 2007 2012 Cattle and calves 99,907,017 95,497,994 96,347,858 89,994,614 Hogs and pigs 61,188,149 60,405,103 67,786,318 66,026,785 Sheep and lambs 8,083,457 6,341,799 5,819,162 5,364,844 Broilers & other meat chickens 1,214,446,356 1,389,279,047 1,602,574,592 1,506,276,846 Laying hens 314,144,304 334,435,155 349,772,558 350,715,978 Goats , horses , turkeys and bees are also raised , though in lesser quantities . Inventory data is not as readily available as for the major industries . For the three major goat - producing states -- Arizona , New Mexico , and Texas -- there were 1.2 million goats at the end of 2002 . There were 5.3 million horses in the United States at the end of 1998 . There were 2.5 million colonies of bees at the end of 2002 . Farm type or majority enterprise type ( edit ) Farm type is based on which commodities are the majority crops grown on a farm . Nine common types include : Cash grains includes corn , soybeans and other grains ( wheat , oats , barley , sorghum ) , dry edible beans , peas , and rice . Tobacco Cotton Other field crops includes peanuts , potatoes , sunflowers , sweet potatoes , sugarcane , broomcorn , popcorn , sugar beets , mint , hops , seed crops , hay , silage , forage , etc . Tobacco and cotton can be included here if not in their own separate category . High - value crops includes fruits , vegetables , melons , tree nuts , greenhouse , nursery crops , and horticultural specialties . Cattle Hogs Dairy Poultry and eggs Governance ( edit ) Agriculture subsidy , from a Congressional Budget Office report . Note : chart does not show sugar subsidies . Main articles : Agricultural policy in the United States and Agricultural subsidy Agriculture in the United States is primarily governed by periodically renewed U.S. farm bills . Governance is both a federal and a local responsibility with the United States Department of Agriculture being the federal department responsible . Government aid includes research into crop types and regional suitability as well as many kinds of subsidies , some price supports and loan programs . U.S. farmers are not subject to production quotas and some laws are different for farms compared to other workplaces . Labor laws prohibiting children in other workplaces provide some exemptions for children working on farms with complete exemptions for children working on their family 's farm . Children can also gain permits from vocational training schools or the 4 - H club which allow them to do jobs they would otherwise not be permitted to do . A large part of the U.S. farm workforce is made up of migrant and seasonal workers , many of them recent immigrants from Latin America . Additional laws apply to these workers and their housing which is often provided by the farmer . Employment ( edit ) In 1870 , almost 50 percent of the US population was employed in agriculture . As of 2008 , less than 2 percent of the population is directly employed in agriculture . In 2012 , there were 3.2 million farmers , ranchers and other agricultural managers and an estimated 757,900 agricultural workers were legally employed in the US . Animal breeders accounted for 11,500 of those workers with the rest categorized as miscellaneous agricultural workers . According to a study the farm laborers declined by 20 % between 2002 and 2014 . The median pay was $9.12 per hour or $18,970 per year . In 2009 , about 519,000 people under age 20 worked on farms owned by their family . In addition to the youth who lived on family farms , an additional 230,000 youth were employed in agriculture . In 2004 , women made up approximately 24 % of farmers ; that year , there were 580,000 women employed in agriculture , forestry , and fishing . From 1999 - 2009 , roughly 50 % of hired crop farmworkers in the US were noncitizens working without legal authorization . Occupational Safety and Health ( edit ) Main article : Agricultural safety and health Agriculture ranks among the most hazardous industries due to the use of chemicals and risk of injury . Farmers are at high risk for fatal and nonfatal injuries ( general traumatic injury and musculoskeletal injury ) , work - related lung diseases , noise - induced hearing loss , skin diseases , chemical - related illnesses , and certain cancers associated with chemical use and prolonged sun exposure . In an average year , 516 workers die doing farm work in the U.S. ( 1992 -- 2005 ) . Every day , about 243 agricultural workers suffer lost - work - time injuries , and about 5 % of these result in permanent impairment . Tractor overturns are the leading cause of agriculture - related fatal injuries , and account for over 90 deaths every year . The National Institute for Occupational Safety and Health recommends the use of roll over protection structures on tractors to reduce the risk of overturn - related fatal injuries . Farming is one of the few industries in which families ( who often share the work and live on the premises ) are also at risk for injuries , illness , and death . Agriculture is the most dangerous industry for young workers , accounting for 42 % of all work - related fatalities of young workers in the U.S. between 1992 and 2000 . In 2011 , 108 youth , less than 20 years of age , died from farm - related injuries . Unlike other industries , half the young victims in agriculture were under age 15 . For young agricultural workers aged 15 -- 17 , the risk of fatal injury is four times the risk for young workers in other workplaces Agricultural work exposes young workers to safety hazards such as machinery , confined spaces , work at elevations , and work around livestock . The most common causes of fatal farm - related youth injuries involve machinery , motor vehicles , or drowning . Together these three causes comprise more than half of all fatal injuries to youth on U.S. farms . Women in agriculture ( including the related industries of forestry and fishing ) numbered 556,000 in 2011 . Agriculture in the US makes up approximately 75 % of the country 's pesticide use . Agricultural workers are at high risk for being exposed to dangerous levels of pesticides , whether or not they are directly working with the chemicals . Research centers ( edit ) Some US research centers are focused on the topic of health and safety in agricultural practices . These centers not only conduct research on the subject of occupational disease and injury prevention , but also promote agricultural health and safety through educational outreach programs . Most of these groups are funded by the National Institute for Occupational Safety and Health , the US Department of Agriculture , or other state agencies . Centers include : Central States Center for Agricultural Safety and Health , University of Nebraska Medical Center , Omaha , NE Great Plains Center for Agricultural Health , University of Iowa , Iowa City , IA High Plains Intermountain Center for Agricultural Health and Safety , Colorado State University , Fort Collins , CO National Children 's Center for Rural and Agricultural Health and Safety , Marshfield , WI Northeast Center for Agricultural and Occupational Health , New York Center for Agricultural Medicine and Health , Cooperstown , NY Pacific Northwest Agricultural Safety and Health Center , University of Washington , Seattle , WA Southeast Center for Agricultural Health and Injury Prevention , University of Kentucky , Lexington , KY Southwest Center for Agricultural Health , Injury Prevention and Education , University of Texas , Tyler , TX Upper Midwest Agricultural Safety and Health Center , a collaboration between the University of Minnesota School of Public Health , Minneapolis , MN , University of Minnesota College of Veterinary Medicine , St. Paul , MN , Minnesota Department of Health , St. Paul , MN and the National Farm Medicine Center , Marshfield , WI with Migrant Clinicians Network , Salisbury , MD Western Center for Agricultural Health and Safety , University of California , Davis , CA Women in agriculture ( edit ) It has been suggested that this section be split out into another article titled Women In Agriculture - United States . ( Discuss ) ( November 2016 ) Women who work in agriculture face different occupational hazards than men . Women in agriculture are poisoned by pesticides at twice the rate of their male counterparts . Exposure to pesticides can also affect fertility ; women exposed to pesticides take longer to conceive ( men are unaffected ) . Women are also at risk for bronchitis from exposure to grain , pesticides , and dust . Pesticide exposure in relationship to female agricultural workers ( edit ) In many developing countries worldwide , women make up a significant proportion of agricultural workers , accounting for between 44 - 75 % of agricultural workers , depending on which country is being examined . In developed countries , approximately 36 % of the entire agricultural workforce are women , with approximately one in five agricultural workers in the United States being women . Women agricultural workers in the United States are exposed to various categories of pesticides , which include insecticides , fungicides , disinfectants , herbicides , and fumigants . These pesticides are applied in order to protect a multitude of crops , including but not limited to , fruits , vegetables , grains , and fiber crops . The exposures can occur via application as well as residues left in the soil and on the crops after application has occurred ; pesticide may also be present in ambient air . Women may acquire acute pesticide poisoning , which has classified as being based on three criteria . These criteria include the strength of evidence that a pesticide exposure occurred , whether adverse health effects were observed by a healthcare professional , and if there is sufficient evidence that the known toxicology of the agent was consistent with the observed health effects . The WHO defines acute pesticide poisoning as any illness or health effect resulting from suspected or confirmed exposure to a pesticide within 48 hours . Female agricultural workers are less likely to wear Personal Protective Equipment , which is made of chemical resistance material that prevents chemicals from coming in contact with skin for a limited period of time , . Only 51 % of women pesticide handlers utilize PPE , while 26 % of women non-handlers use PPE ; this is significantly less than male workers in the agricultural field and is largely a result of ill - fitting equipment , including glasses , gloves , respirators , and protective outerwear , . Acute Pesticide Poisoning Case Definition Matrix Health effects ( edit ) Surveillance for occupational pesticide - related illnesses and injuries are tracked by the National Institute for Occupational Safety and Health ( NIOSH ) and the Environmental Protection Agency ( EPA ) through the SENSOR - Pesticides program . The EPA estimates between 10,000 - 20,000 physician related pesticide poisonings are reported among hired US agricultural workers each year . `` While poisonings comprise a relatively small portion of total agricultural worker occupational illness , this is likely underestimated due to inadequate state surveillance programs , lack of physician training to recognize poisonings , lack of health insurance among farm workers , worker reluctance to report poisonings , and the transient nature of agricultural workers '' . Female agricultural workers face the same potential acute exposure and chronic conditions as do their male counterparts . Acute Exposure Conditions dizziness ; confusion ; abnormal skin sensations ; contact dermatitis ; eye irritation ; chest tightness ; gastrointestinal problems ; vomiting ; convulsions ; and even death in cases of acute exposure . Chronic Conditions dermatological sensitivity ; respiratory disease including lung fibrosis and chronic bronchitis ; asthma - like syndromes ; cancer ; and neurological symptoms . The issue of preconceptional prenatal exposure is another factor in the health of female agricultural workers . It has been documented in the literature that pesticide exposure before or during pregnancy has been associated with increased risk of infertility , perinatal death , spontaneous abortion / stillbirth , premature birth , and congenital malformations . These health ramifications not only impact the physical and mental health of women but also future generations . Epigenetic effects ( edit ) The female agricultural workers are not the only ones that suffer damage from pesticide exposure . Husbands of the agricultural worker as well as the children and grandchildren and great - grandchildren are also affected . This is due to exposure to Organophosphorus Pesticides because they have been shown to cause damage to DNA in sperm cells . When DNA damage is done in gamete cells ( sperm and egg cells ) then the future generations will all be affected . The damage may not cause any noticeable abnormalities in the development of the child born to a father with sperm cell DNA damage . However , it could lead to such serious complications as Autism ( caused by chromosomal abnormalities ) or Leukemia . Female agricultural workers that are exposed to pesticides can expose their family members by bringing home some of the pesticides from work on their clothes , or skin . The husband 's DNA can be compromised through this exposure pathway , as well as any other children already born and living in the house . Scientific limitations ( edit ) The two most common limitations in studying the health effects of pesticide exposure in women are the small sample sizes and the lack of toxicological data , . Ensuring that the proper exposure is measured relies heavily on the study participants not moving residences throughout the study period . However , this is nearly impossible because migrant workers and seasonal employees do not typically live in the same place throughout the year . Scientific studies require consistency within the group of participants being studied so that confounders are adjusted for , and transient residents do not make for very consistent study participants . Such living arrangements also make agricultural workers difficult to get in contact with . The most common methods for scientific researchers to find a person 's contact information are not available for these populations . Health insurance information is not available and contact information left with an employer may not be correct year - round . Additionally , there is a very limited amount of quantifiable data on the pesticides the study participants are exposed to . The specific names of the pesticides may not be available . The units of pesticide applied per field may not accurately represent the units that a worker is exposed to . The number of days or hours that an agricultural worker is exposed is rarely recorded . This is due to the inconsistencies in the end of an agricultural work day practices - such as removing work clothing before going home , showering before going home , etc . Additionally , the proximity of agricultural workers ' homes to the fields they harvest results in more exposure to the pesticides , and the amount of exposure at home is even more difficult to measure . Challenges and means of exposure ( edit ) Occupational Safety ( edit ) In addition to the scientific limitations regarding pesticide exposure data , a variety of challenges exist in the industry for female farmworkers . Occupational safety measures are not always well defined and rarely enforced . This means that not all laborers are subject to safety training through their provider . Furthermore , as many as 35 % of female farmworkers do not know of any health risks associated with pesticide spraying at all . When workers are unaware of best practices in pesticide application and the subsequent health risks , they are unable to protect themselves and their families appropriately from pesticide exposure . One of the first steps of protection against exposure is through personal protective equipment ( PPEs ) . However , PPEs are not regularly used and rarely includes all the recommended protective measures such as goggles and gloves . Some women also report not having the necessary equipment to mix the pesticides and ultimately resort to using household items like broomsticks or even their hands . Home Safety ( edit ) Home safety provides its own challenges for women . It is possible for non-laborers to be exposed to pesticides through clothing contamination . In order to maintain a safe home environment , clothing from spraying pesticides should be cleaned and stored separately from other clothing in the household . Exposure can also be limited by having workers shower within 15 minutes of returning home at the end of the work day . The pesticides used in the agricultural industry in the United States often have a strong odor that helps to remind families of the presence of toxins which makes it more likely that they PPEs and equipment will be stored appropriately . Family members are also subject to contamination through food and water supplies . Many people reported reusing pesticide containers for laundry or to carry water . Social determinants of Health ( edit ) Finally , all of these factors are compounded by social determinants affecting agricultural workers . Studies have shown that as many as 97 % of female farm laborers take their children with them to work , thereby directly exposing them to pesticide contamination . Farm workers have literacy rates significantly lower than the rest of the population . This negatively impacts health outcomes because employees that have not received safety training are not able to read the warning labels and instructions on the pesticides . In one study , `` Only 85 ( 23.2 % ) of the women could read English and 69 ( 18.9 % ) reported ever reading the pesticide labels . '' . Housing is usually cramped without adequate laundry or bathroom facilities to wash and store equipment . Such dwellings are often occupied by multiple laborers thereby multiplying the overall contaminants . Lastly , women in the agricultural industry report accessing prenatal health care services at nearly half the rate of the national average , 42 % vs. 76 % , respectively . Socioeconomic challenges ( edit ) Female farm workers may often face social challenges and adverse mental health effects while working , with one of the biggest challenges being social inequality . The number of women working in agriculture has risen and the 2002 census of agriculture recorded a 40 % increase in the number of female farm workers . Inequality and respect are common issues for these workers , as many have reported that they are not being respected , listened to , or taken seriously due to traditional views of women as housewives and caretakers . Women may also face resistance when attempting to advance to higher positions . Other issues reported by female farm workers include receiving less pay than their male counterparts and a refusal or reluctance by their employers to offer their female workers the same additional benefits given to male workers such as housing . This inequality in pay can cause some women to seek off - farm jobs , which can be difficult if the women are older or have no education or related experience . The risk of injury for farm workers is high . Studies have shown that safety recautions and regulations tend to focus on the male 's work because of the traditional idea that the male farm workers work is more dangerous and risky than the females , despite women also engaging in equally risky work such as caring for farm animals or using farming machinery . Women in the farming industry are more likely than men to experience depression and women who experience higher rates of depression are more likely to have been through traumatic events such as sexual abuse and stress due to gender inequality . They are also at a disadvantage when beginning farm work due to some female workers lacking knowledge about the chemical hazards on farms , which can pose issues for pregnant farm workers who are exposed to chemicals that can harm the pregnancy . Some farm workers may also be immigrants who may not be educated on the importance of prenatal care , especially when being exposed to harmful chemicals , which can cause them to experience complications during pregnancy and have children born with birth defects . Policy Implications ( edit ) Protection of women 's reproductive health is needed for female agricultural workers . Farm work is one of three most dangerous occupations in the United States . According to the National Agricultural Workers Survey ( 1994 - 1995 ) , the proportion of women in farming declined from 25 % in the 1980s to less than 20 % in the 1990s . As a result of `` a larger portion of the farm worker population being U.S. born ( 1994 - 1995 ) which means that every third U.S. born farm worker was a woman while only one in eight foreign - born farm workers was a woman . '' Due to their occupation , women and their families are at risk to higher exposure from pesticides than the general population from direct contact and pesticide drift as result of their housing proximity to agricultural lands . To ensure the safety and health of women , they need additional surveillance and monitoring for any toxic effects caused by working and living in close proximity to commercial spraying operations , . Moreover , this is important to women 's reproductive health , because the quality of healthcare they receive in the United States during their lifespan has a direct impact on their reproductive health and well - being and that of their US - born children , . Furthermore , `` U.S. born workers , women tended to be older than their male counterparts ( 32 and 25 years old , respectively ) while among the foreign - born farm workers , there was no meaningful difference in age between men and women ( 29 and 30 years old , respectively ) . '' The key issues confronting women in agriculture 's healthcare are : access to health care ; lack of affordable health insurance ; and lack of a medical home due to the seasonality of the work which forces migrant workers to follow the crops . Increased enforcement and compliance of existing EPA 's Worker Protection Standards is needed to protect women workers from pesticide exposures as well as new policies that specifically address women 's reproductive health and to their families and unborn children . This is complicated due to the composition of the workforce which consists primarily of migrants with a mixed immigrant status and the United States government 's policies about not providing nonemergency health care to nonresidents . This includes prenatal care for undocumented workers whose child born in the United States is considered an American by the 14 Amendment of the US Constitution or the Citizenship Clause . Additional work on compliance onsite by OSHA . See also ( edit ) Agriculture and Agronomy portal 2010 United States tomato shortage Agribusiness Banana production in the United States Beekeeping in the United States Child nutrition programs Electrical energy efficiency on United States farms Fishing industry in the United States Genetic engineering in the United States History of agriculture in the United States Poultry farming in the United States Soil in the United States List of largest producing countries of agricultural commodities List of turkey meat producing companies in the United States Additional reading ( edit ) Winterbottom , Jo ; Huffstutter , P.J. ( Feb. 2015 ) . Rent walkouts point to strains in U.S. farm economy , Reuters References ( edit ) Jump up ^ `` Latest U.S. Agricultural Trade Data . '' USDA Economic Research Service . Ed . Stephen MacDonald . USDA , 4 Sept. 2013 . Web . 28 Sept. 2013 . Jump up ^ `` US Census of Agriculture , 2007 '' . Agcensus.usda.gov. 2009 - 02 - 04 . Retrieved 2014 - 04 - 01 . Jump up ^ Hatfield , J. , 2012 : Agriculture in the Midwest . In : U.S. National Climate Assessment Midwest Technical Input Report . J. Winkler , J. Andresen , J. Hatfield , D. Bidwell , and D. Brown , coordinators . Available from the Great Lakes Integrated Sciences and Assessments ( GLISA ) Center ^ Jump up to : Cronon , William . Changes in the Land : Indians , Colonists , and the Ecology of New England . New York : Hill & Wang , 2003 . Jump up ^ Shurtleff , William ; Aoyagi , Akiko ( 2004 ) . History of World Soybean Production and Trade - Part 1 . Soyfoods Center , Lafayette , California : Unpublished Manuscript , History of Soybeans and Soyfoods , 1100 B.C. to the 1980s . Jump up ^ `` FAOSTAT '' . faostat3.fao.org . Retrieved 2015 - 11 - 26 . Jump up ^ `` United States Crop Rankings - 1997 Production Year '' . Retrieved 2014 - 04 - 01 . Jump up ^ `` Crop Values - 2014 Summary '' ( PDF ) . Retrieved 2015 - 11 - 26 . Jump up ^ `` Chapter IX : Farm Resources , Income , and Expenses '' ( PDF ) . Archived from the original ( PDF ) on 2008 - 04 - 09 . Retrieved 2014 - 04 - 01 . Jump up ^ USDA. 2004 . 2002 Census of agriculture . United States summary and state data . Vol. 1 . Geographic area series . Part 51 . AC - 02 - A-51. 663 pp . Jump up ^ USDA. 2009 . 2007 Census of agriculture . United States summary and state data . Vol. 1 . Geographic area series . Part 51 . AC - 07 - A-51. 739 pp . Jump up ^ USDA. 2014 . 2012 Census of agriculture . United States summary and state data . Vol. 1 . Geographic area series . Part 51 . AC - 12 - A-51. 695 pp . Jump up ^ `` Appendix A : Glossary '' ( PDF ) . Archived from the original ( PDF ) on March 18 , 2009 . Retrieved 2014 - 04 - 01 . Jump up ^ `` ERS / USDA Briefing Room - Farm Structure : Questions and Answers '' . Wayback.archive.org . Archived from the original on February 9 , 2008 . Retrieved 2014 - 04 - 01 . Jump up ^ `` Chapter 3 : american Farms '' ( PDF ) . Archived from the original ( PDF ) on 2014 - 08 - 24 . Retrieved 2014 - 04 - 01 . Jump up ^ ( 1 ) , Retrieved May 6 , 2016 Jump up ^ `` Employment by major industry sector '' . Bls.gov. 2013 - 12 - 19 . Retrieved 2014 - 04 - 01 . Jump up ^ `` Extension '' . Csrees.usda.gov. 2014 - 03 - 28 . Retrieved 2014 - 04 - 01 . Jump up ^ `` Farm Demographics - U.S. Farmers by Gender , Age , Race , Ethnicity , and More '' . Jump up ^ `` Farming Labor Shortage : Can Computer Vision Guided Robots fill the gap ? '' . lanner-america.com . Jump up ^ `` Agricultural Workers : Occupational Outlook Handbook : U.S. Bureau of Labor Statistics '' . Bls.gov. 2014 - 01 - 08 . Retrieved 2014 - 04 - 01 . ^ Jump up to : Youth in Agriculture , OHSA , accessed January 21 , 2014 Jump up ^ `` Women 's Safety and Health Issues at Work Job Area : Agriculture '' . NIOSH . September 27 , 2013 . Jump up ^ `` Farm Labor - Background '' . USDA Economic Research Service . United States Department of Agriculture . Retrieved 26 November 2016 . Jump up ^ `` NIOSH - Agriculture '' . United States National Institute for Occupational Safety and Health . Archived from the original on 9 October 2007 . Retrieved 2007 - 10 - 10 . ^ Jump up to : Swanson , Naomi ; Tisdale - Pardi , Julie ; MacDonald , Leslie ; Tiesman , Hope M. ( 13 May 2013 ) . `` Women 's Health at Work '' . National Institute for Occupational Safety and Health . Retrieved 21 January 2015 . Jump up ^ `` NIOSH Pesticide Poisoning MOnitoring Program Protects Farmworkers '' . Cdc.gov. 2009 - 07 - 31 . Retrieved 2014 - 04 - 01 . ^ Jump up to : Calvert , Geoffrey M. ; Karnik , Jennifer ; Mehler , Louise ; Beckman , John ; Morrissey , Barbara ; Sievert , Jennifer ; Barrett , Rosanna ; Lackovic , Michelle ; Mabee , Laura ( Dec 2008 ) . `` Acute pesticide poisoning among agricultural workers in the United States , 1998 - 2005 '' . American Journal of Industrial Medicine . 51 ( 12 ) : 883 -- 898 . doi : 10.1002 / ajim. 20623 . ISSN 1097 - 0274 . PMID 18666136 . ^ Jump up to : `` NIOSH - Agriculture Injury '' . United States National Institute for Occupational Safety and Health . Archived from the original on 28 October 2007 . Retrieved 2007 - 10 - 10 . Jump up ^ NIOSH ( 2003 ) . Unpublished analyses of the 1992 -- 2000 Census of Fatal Occupational Injuries Special Research Files provided to NIOSH by the Bureau of Labor Statistics ( includes more detailed data than the research file , but excludes data from New York City ) . Morgantown , WV : U.S. Department of Health and Human Services , Public Health Service , Centers for Disease Control and Prevention , National Institute for Occupational Safety and Health , Division of Safety Research , Surveillance and Field Investigations Branch , Special Studies Section . Unpublished database . Jump up ^ BLS ( 2000 ) . Report on the youth labor force . Washington , DC : U.S. Department of Labor , Bureau of Labor Statistics , pp. 58 -- 67 . Jump up ^ `` Guidelines for Children 's Agricultural Tasks Demonstrate Effectiveness '' . Cdc.gov. 2009 - 07 - 31 . Retrieved 2014 - 04 - 01 . Jump up ^ `` CDC - NIOSH Grants and Funding - Extramural Research and Training Programs - Training and Research - Agricultural Centers '' . Centers for Disease Control and Prevention . 2016 - 03 - 03 . Retrieved 2016 - 03 - 03 . Jump up ^ `` Home CS - CASH University of Nebraska Medical Center '' . www.unmc.edu . Retrieved 2016 - 03 - 04 . Jump up ^ `` Great Plains Center for Agricultural Health Protecting and improve the health and safety of agricultural workers '' . www.public-health.uiowa.edu . Retrieved 2016 - 03 - 04 . Jump up ^ `` High Plains Intermountain Center for Agricultural Health & Safety '' . csu-cvmbs.colostate.edu . Retrieved 2016 - 03 - 04 . Jump up ^ `` Marshfield Clinic Research Foundation - National Children 's Center for Rural Agricultural Health & Safety '' . Marshfield Clinic Research Foundation . 2016 - 03 - 03 . Retrieved 2016 - 03 - 03 . Jump up ^ http://www.nycamh.com/northeastcenter/ Jump up ^ `` Pacific Northwest Agricultural Safety and Health Center '' . deohs.washington.edu . Retrieved 2016 - 03 - 04 . Jump up ^ `` Southeast Center for Agricultural Health and Injury Prevention University of Kentucky College of Public Health '' . www.uky.edu . Retrieved 2016 - 03 - 04 . Jump up ^ Day , Steven . `` Southwest Center for Agricultural Health , Injury Prevention , and Education : : Main '' . www.swagcenter.org . Retrieved 2016 - 03 - 04 . Jump up ^ `` Upper Midwest Agricultural Safety and Health Center - UMASH '' . Upper Midwest Agricultural Safety and Health . University of Minnesota . 2016 - 03 - 03 . Retrieved 2016 - 03 - 03 . Jump up ^ Sciences , Department of Public Health . `` Western Center for Agricultural Health and Safety '' . agcenter.ucdavis.edu . Retrieved 2016 - 03 - 04 . ^ Jump up to : Garcia , A.M. ( 1999 ) . `` Parental agricultural work and selected congenital malformations '' . American Journal of Epidemiology. 149 ( 64 ) . Jump up ^ Calvert , G.M. ; Karnik , J. ; Mehler , L. ( 2008 ) . `` Acute pesticide poisoning among agricultural workers in the United States '' . American journal of industrial medicine . 51 ( 12 ) : 883 -- 898 . doi : 10.1002 / ajim. 20623 . PMID 18666136 . Jump up ^ Calvert , G.M. ; Karnik , J. ( 2008 ) . `` Acute pesticide poisoning among agricultural workers in the United States '' . American journal of industrial medicine . 51 ( 12 ) : 883 -- 898 . doi : 10.1002 / ajim. 20623 . PMID 18666136 . Jump up ^ Thundiyil , J.G. ; Stober , J. ; Besbelli , N. ; Pronczuk , J. `` Acute pesticide poisoning : a proposed classification tool '' . World Health Organization . Jump up ^ Calvert , G.M. ; Karnik , J. ( 2008 ) . `` Acute pesticide poisoning among agricultural workers in the United States , 1998 - 2005 '' . American journal of industrial medicine . 51 ( 12 ) : 883 -- 898 . doi : 10.1002 / ajim. 20623 . PMID 18666136 . Jump up ^ Young , P. `` Pesticide use and your personal protective equipment ( PPE ) '' ( PDF ) . Oregon Occupational Safety and Health Division . Jump up ^ Calvert , G.M. ; Karnik , J. ( 2008 ) . `` Acute pesticide poisoning among agricultural workers in the United States , 1998 -- 2005 '' . American journal of industrial medicine . 51 ( 12 ) : 883 -- 898 . doi : 10.1002 / ajim. 20623 . PMID 18666136 . Jump up ^ Walker , J.L. `` PPE for women : we 've come a long way , ' rosie ' , but we still have a long ways to go '' ( PDF ) . International Safety Equipment Association . ^ Jump up to : `` National Institute for Occupational Safety and Health ( 2016 ) Pesticides illness and injury surveillance '' . Retrieved 17 March 2016 . Jump up ^ Das , R ; Steege , A ; Beckman , J ; Harrison , R ( 2001 ) . `` Pesticide - related illness among migrant farm workers in the United States '' . Int J Occup Environ Health . 7 : 303 -- 312 . doi : 10.1179 / oeh. 2001.7. 4.303 . Jump up ^ Costa , L.G. ; Giordano , G ; Guizzetti , M ; Vitalone , A ( 2008 ) . `` Neurotoxicity of pesticides : a brief review '' . Front Biosci. 13 : 1240 -- 1249 . doi : 10.2741 / 2758 . Jump up ^ Quandt , S.A. ( 2013 ) . `` Occupational Health Outcomes for Workers in the Agriculture , Forestry and Fishing Sector : Implications for Immigrant Workers in the Southeastern US '' . American Journal of Industrial Medicine . 56 : 940 -- 959 . doi : 10.1002 / ajim. 22170 . Jump up ^ Greenlee , A.R. ; Arbuckle , T.E. ; Chyou , P.H. ( 2003 ) . `` Risk Factors for Female Infertility in an Agricultural Region '' . Epidemiology. 14 ( 4 ) : 429 -- 436 . doi : 10.1097 / 01. ede. 0000071407.15670. aa . Jump up ^ Bell , EM ( 2001 ) . `` A case - control study of pesticides and fetal death due to congenital anomalies '' . Epidemiology. 12 : 148 . doi : 10.1097 / 00001648 - 200103000 - 00005 . Jump up ^ Nurminen , T ( 1995 ) . `` Maternal pesticide exposure and pregnancy outcome '' . J Occup Environ Med. 37 : 935 . doi : 10.1097 / 00043764 - 199508000 - 00008 . Jump up ^ Eskenazi , B ( 2004 ) . `` Association of in utero organophosphate pesticide exposure and fetal growth and length of gestation in an agricultural population '' . Environmental Health Perspectives. 112 ( 10 ) : 1116 -- 1124 . doi : 10.1289 / ehp. 6789 . Jump up ^ Garcia , AM ( 1999 ) . `` Parental agricultural work and selected congenital malformations '' . American Journal of Epidemiology. 149 : 64 . doi : 10.1093 / oxfordjournals. aje. a009729 . Jump up ^ Sanchez - Pena , L.C. ; Reyes , B.E. ; Lopez - Carrillo , L. ; Recio , R. ; Moran - Martinez , J ( 2004 ) . `` Organophosphorous pesticide exposure alters sperm chromatin structure in Mexican agricultural workers '' . Toxicology and Applied Pharmacology . 196 ( 1 ) : 108 -- 113 . doi : 10.1016 / j. taap. 2003.11. 023 . Jump up ^ Ward , M.H. ; Colt , J.S. ; Metayer , C. ; Gunier , R.B. ( 2009 ) . `` Residential exposure to polychlorinated biphenyls and organochlorine pesticides and risk of childhood leukemia '' . Environmental Health Perspectives. 117 ( 6 ) : 1007 . doi : 10.1289 / ehp. 0900583 . PMC 2702395 . PMID 19590698 . Jump up ^ El - Baz , M.A. ; El - Deek , S.E. ; Nsar , A.Y. ( 2015 ) . `` Prenatal Pesticide Exposure : Meconium as a Biomarker and Impact on Fetal Weight '' . Journal of Environmental & Analytical Toxicology . Jump up ^ Ward , M.H. ; Colt , J.S. ; Metayer , C. ; Gunier , R.B. ( 2009 ) . `` Residential exposure to polychlorinated biphenyls and organochlorine pesticides and risk of childhood leukemia '' . Environmental Health Perspectives. 117 ( 6 ) : 1007 . doi : 10.1289 / ehp. 0900583 . PMC 2702395 . PMID 19590698 . Jump up ^ Calvert , G.M. ; Karnik , J. ; Mehler , L. ; Mitchell , Y. ( 2008 ) . `` Acute pesticide poisoning among agricultural workers in the United States , 1998 -- 2005 '' . American journal of industrial medicine . 51 ( 12 ) : 883 -- 898 . doi : 10.1002 / ajim. 20623 . PMID 18666136 . Jump up ^ Ward , M.H. ; Colt , J.S. ; Metayer , C. ( 2009 ) . `` Residential exposure to polychlorinated biphenyls and organochlorine pesticides and risk of childhood leukemia '' . Environmental Health Perspectives. 117 ( 6 ) : 1007 . doi : 10.1289 / ehp. 0900583 . PMC 2702395 . PMID 19590698 . Jump up ^ Habib , R.R. ; Fathallah , F.A. ( 2012 ) . `` Migrant women farm workers in the occupational health literature '' . Work . 41 ( 1 ) : 4356 -- 4362 . Jump up ^ Calvert , G.M. ; Karnik , J. ; Mitchell , Y. ( 2008 ) . `` Acute pesticide poisoning among agricultural workers in the United States , 1998 -- 2005 '' . American journal of industrial medicine . 51 ( 12 ) : 883 -- 898 . doi : 10.1002 / ajim. 20623 . PMID 18666136 . Jump up ^ Andersen , H.R. ; Grandjean , P. ( 2015 ) . `` Occupational pesticide exposure in early pregnancy associated with sex - specific neurobehavioral deficits in the children at school age '' . Neurotoxicology and teratology. 47 : 1 -- 9 . doi : 10.1016 / j. ntt. 2014.10. 006 . Jump up ^ Shelton , J.F. ; Geraghty , E.M. ; Hertz - Picciotto , I. ( 2014 ) . `` Neurodevelopmental disorders and prenatal residential proximity to agricultural pesticides : the CHARGE study '' . Environmental Health Perspectives ( Online ) . 122 ( 10 ) : 1103 . ^ Jump up to : Garcia , Ana M. ( 2003 ) . `` Pesticide Exposure and Women 's Health '' . American Journal of Industrial Medicine . 44 ( 6 ) : 584 -- 594 . doi : 10.1002 / ajim. 10256 . ^ Jump up to : Naidoo , S. ; et . al. ( 2010 ) . `` Pesticide Safety Training and Practices in Women Working in Small - Scale Agriculture in South Africa '' . Occupational and Environmental Medicine . 67 ( 12 ) : 823 -- 828 . doi : 10.1136 / oem. 2010.055863 . Jump up ^ Rao , Pamela ; et . al. ( 2006 ) . `` Pesticide Safety Behaviors in Latino Farmworker Family Households '' . American Journal of Industrial Medicine . 49 ( 4 ) : 271 -- 280 . doi : 10.1002 / ajim. 20277 . Jump up ^ Rao , Pamela ; et . al. ( 2006 ) . `` Pesticide Safety Behaviors in Latino Farmworker Family Households '' . American Journal of Industrial Medicine . 49 ( 4 ) : 271 -- 280 . doi : 10.1002 / ajim. 20277 . Jump up ^ National Center for Farmworker Health , Inc. ( 2009 ) . `` Maternal and Child Health Fact Sheet '' : 1 -- 5 . Jump up ^ Rao , Pamela ; et . al. ( 2006 ) . `` Pesticide Safety Behaviors in Latino Farmworker Family Households '' . American Journal of Industrial Medicine . 49 ( 4 ) : 271 -- 280 . doi : 10.1002 / ajim. 20277 . Jump up ^ National Center for Farmworker Health , Inc. ( 2009 ) . `` Maternal and Child Health Fact Sheet '' : 1 -- 5 . ^ Jump up to : Albright , Carmen ( 2006 ) . `` Who 's Running The Farm ? : Changes and characteristics of Arkansas women in Agriculture '' . American Agricultural Economics Association : 1315 -- 1322 -- via JSTOR . Jump up ^ Jones , L. ( 2015 ) . `` North Carolina 's Farm Women : Plowing around Obstacles '' . University of Georgia Press . -- via JSTOR . Jump up ^ Golichenko , M. ; Sarang , A. ( 2013 ) . `` Farm labor , reproductive justice : Migrant women farmworkers in the US '' . Health and Human Rights -- via JSTOR . Jump up ^ Dimich - Ward , H. , Guernsey , J. , Pickett , W. , Rennie , D. , Hartling , L. , & Brison , R. ( 2004 ) . Gender Differences in the Occurrence of Farm Related Injuries . Occupational and Environmental Medicine , 61 ( 1 ) , 52 - 56 . Retrieved from http://www.jstor.org/stable/27732153 Jump up ^ Pulgar , C.A. , Trejo , G. , Suerken , C. , Ip , E.H. , Arcury , T.A. , & Quandt , S.A. ( 2016 ) . Economic hardship and depression among women in latino farmworker families. Journal of Immigrant and Minority Health , 18 ( 3 ) , 497 - 504 . doi : http://dx.doi.org.proxyhu.wrlc.org/10.1007/s10903-015-0229-6 ^ Jump up to : Larson , K. ( 1993 ) . Migrant Farmworkers ' Health Issues . In Defense of the Alien , 16 , 100 - 106 . Retrieved from http://www.jstor.org/stable/23140866 Jump up ^ Calvert , G. , Walter A. Alarcon , Ann Chelminski , Mark S. Crowley , Rosanna Barrett , Correa , A. , ... Evans , E. ( 2007 ) . Case Report : Three Farmworkers Who Gave Birth to Infants with Birth Defects Closely Grouped in Time and Place . Florida and North Carolina , 2004 - 2005 . Environmental Health Perspectives , 115 ( 5 ) , 787 - 791 . Retrieved from http://www.jstor.org/stable/4489029 Jump up ^ `` United States Farmworker Factsheet '' . Student Action with Farmworkers . Jump up ^ `` National Agricultural Workers Survey ( 1994 - 1995 ) '' . Jump up ^ `` National Agricultural Workers Survey ( 1994 - 1995 ) '' . ^ Jump up to : `` WPS Standards '' . Jump up ^ `` The Hastings Center : Undocumented Immigrants in the United States : U.S. Health Policy and Access to Care '' . ^ Jump up to : `` Undocumented Immigrants in the United States : Access to Prenatal Care '' . Jump up ^ `` Hidden Danger : Environmental Threats to Latino Community '' ( PDF ) . 2004 . Jump up ^ `` Farm Labor , Reproductive Justice : Migrant Women Farmworkers in the US '' ( PDF ) . Jump up ^ `` Farmworker Justice : Pesticide Safety '' . Jump up ^ `` National Agricultural Workers Survey ( 1994 - 1995 ) '' . Jump up ^ `` Neurodevelopmental Disorders and Prenatal Residential Proximity to Agricultural Pesticides : The CHARGE Study '' . ^ Jump up to : `` Women living near pesticide - treated fields have smaller babies '' . Jump up ^ `` Acute Pesticide Poisoning Among Agricultural Workers in the United States , 1998 -- 2005 '' ( PDF ) . Jump up ^ Sanchez - Pena , L.C. ; Reyes , B.E. ; Lopez - Carillo , L. ( 2004 ) . `` Organophosphorous pesticide exposure alters sperm chromatin structure in Mexican agricultural workers '' . Toxicology and Applied Pharmacology . 196 ( 1 ) : 108 -- 113 . doi : 10.1016 / j. taap. 2003.11. 023 . External links ( edit ) Wikimedia Commons has media related to Agriculture in the United States . United States Department of Agriculture National Ag Safety Database North American Guidelines for Children 's Agricultural Tasks Agriculture in the United States History History African - American history Industries Almond Apple Banana Blueberry Cherry Christmas tree Citrus Corn Cotton Maple syrup Onion Pepper Rice Spinach Strawberry Tea Tomato Wheat Wine State - specific Idaho New York State - specific by type Aquaculture in Alaska Aquaculture in Hawaii Aquaculture in Maine Coffee in Hawaii Garlic in California Pistachios in California Walnuts in California Law and politics Agricultural policy Packers and Stockyards Act Capper - Volstead Act Grain Futures Act 1929 Agricultural Marketing Act 1938 Agricultural Adjustment Act National School Lunch Act of 1946 Agricultural Trade Development and Assistance Act of 1954 1956 Soil Bank Act Food and Agricultural Act of 1962 1964 Food Stamp Act Food Security Act of 1985 Food , Agriculture , Conservation , and Trade Act of 1990 1990 Wetlands Reserve Program Federal Agriculture Improvement and Reform Act Agricultural Risk Protection Act of 2000 2002 Grassland Reserve Program Agriculture in North America Sovereign states Antigua and Barbuda Bahamas Barbados Belize Canada Costa Rica Cuba Dominica Dominican Republic El Salvador Grenada Guatemala Haiti Honduras Jamaica Mexico Nicaragua Panama Saint Kitts and Nevis Saint Lucia Saint Vincent and the Grenadines Trinidad and Tobago United States Dependencies and other territories Anguilla Aruba Bermuda Bonaire British Virgin Islands Cayman Islands Curaçao Greenland Guadeloupe Martinique Montserrat Puerto Rico Saint Barthélemy Saint Martin Saint Pierre and Miquelon Saba Sint Eustatius Sint Maarten Turks and Caicos Islands United States Virgin Islands United States articles History By event Timeline of U.S. history Pre-Columbian era Colonial era Thirteen Colonies military history Continental Congress American Revolution War American frontier America 's Critical Period Drafting and ratification of Constitution Federalist Era War of 1812 Territorial acquisitions Territorial evolution Mexican -- American War Civil War Reconstruction Era Indian Wars Gilded Age Progressive Era African - American civil rights movement 1865 -- 1896 / 1896 -- 1954 / 1954 -- 1968 Spanish -- American War Imperialism World War I Roaring Twenties Great Depression World War II home front Nazism in the United States American Century Cold War Korean War Space Race Feminist Movement Vietnam War Post-Cold War ( 1991 -- 2008 ) War on Terror War in Afghanistan Iraq War Recent events ( 2008 -- present ) By topic Outline of U.S. history Demographic Discoveries Economic debt ceiling Inventions before 1890 1890 -- 1945 1946 -- 91 after 1991 Military Postal Technological and industrial Geography Territory counties federal district federal enclaves Indian reservations insular zones minor outlying islands populated places states Earthquakes Extreme points Islands Mountains peaks ranges Appalachian Rocky National Park Service National Parks Regions East Coast West Coast Great Plains Gulf Mid-Atlantic Midwestern New England Pacific Central Eastern Northern Northeastern Northwestern Southern Southeastern Southwestern Western Rivers Colorado Columbia Mississippi Missouri Ohio Rio Grande Yukon Time Water supply and sanitation Politics Federal Executive Cabinet Civil service Executive departments Executive Office Independent agencies Law enforcement President of the United States Public policy Legislative House of Representatives current members Speaker Senate current members President pro tempore Vice President Judicial Courts of appeals District courts Supreme Court Law Bill of Rights civil liberties Code of Federal Regulations Constitution federalism preemption separation of powers Federal Reporter United States Code United States Reports Intelligence Central Intelligence Agency Defense Intelligence Agency Federal Bureau of Investigation National Geospatial - Intelligence Agency National Reconnaissance Office National Security Agency Office of the Director of National Intelligence Uniformed Armed Forces Army Marine Corps Navy Air Force Coast Guard National Guard NOAA Corps Public Health Service Corps 51st state political status of Puerto Rico District of Columbia statehood movement Elections Electoral College Foreign relations Foreign policy Hawaiian sovereignty movement Ideologies anti-Americanism exceptionalism nationalism Local government Parties Democratic Republican Third parties Red states and blue states Purple America Scandals State government governor state legislature state court Uncle Sam Economy By sector Agriculture Banking Communications Energy Insurance Manufacturing Mining Tourism Trade Transportation Companies by state Currency Exports Federal budget Federal Reserve System Financial position Labor unions Public debt Social welfare programs Taxation Unemployment Wall Street Society Culture Americana Architecture Cinema Cuisine Dance Demography Education Family structure Fashion Flag Folklore Languages American English Indigenous languages ASL Black American Sign Language HSL Plains Sign Talk Arabic Chinese French German Italian Russian Spanish Literature Media Journalism Internet Newspapers Radio Television Music Names People Philosophy Public holidays Religion Sexuality Sports Theater Visual art Social class Affluence American Dream Educational attainment Homelessness Home - ownership Household income Income inequality Middle class Personal income Poverty Professional and working class conflict Standard of living Wealth Issues Ages of consent Capital punishment Crime incarceration Criticism of government Discrimination affirmative action antisemitism intersex rights islamophobia LGBT rights racism same - sex marriage Drug policy Energy policy Environmental movement Gun politics Health care abortion health insurance hunger obesity smoking Human rights Immigration illegal International rankings National security Mass surveillance Terrorism Separation of church and state Outline Index Book Portal Retrieved from `` https://en.wikipedia.org/w/index.php?title=Agriculture_in_the_United_States&oldid=820613422 '' Categories : Agriculture in the United States Hidden categories : All articles with unsourced statements Articles with unsourced statements from September 2011 Articles containing potentially dated statements from 2008 All articles containing potentially dated statements Articles to be split from November 2016 All articles to be split Talk Contents About Wikipedia Languages Català Español Esperanto فارسی Français Magyar Tiếng Việt Edit links This page was last edited on 15 January 2018 , at 16 : 51 . Text is available under the Creative Commons Attribution - ShareAlike License ; additional terms may apply . By using this site , you agree to the Terms of Use and Privacy Policy . Wikipedia ® is a registered trademark of the Wikimedia Foundation , Inc. , a non-profit organization . About Wikipedia \",\n",
       " 'document_title': 'Agriculture in the United States',\n",
       " 'document_url': 'https://en.wikipedia.org//w/index.php?title=Agriculture_in_the_United_States&amp;oldid=820613422',\n",
       " 'example_id': -6570496346595660652,\n",
       " 'language': 'english',\n",
       " 'question_text': 'what are the main crops grown in the united states',\n",
       " 'passage_answer_candidates': [{'plaintext_start_byte': 208,\n",
       "   'plaintext_end_byte': 721},\n",
       "  {'plaintext_start_byte': 722, 'plaintext_end_byte': 1382},\n",
       "  {'plaintext_start_byte': 2140, 'plaintext_end_byte': 2297},\n",
       "  {'plaintext_start_byte': 2298, 'plaintext_end_byte': 2766},\n",
       "  {'plaintext_start_byte': 2767, 'plaintext_end_byte': 3117},\n",
       "  {'plaintext_start_byte': 3118, 'plaintext_end_byte': 3591},\n",
       "  {'plaintext_start_byte': 3592, 'plaintext_end_byte': 4535},\n",
       "  {'plaintext_start_byte': 4536, 'plaintext_end_byte': 5010},\n",
       "  {'plaintext_start_byte': 5011, 'plaintext_end_byte': 5528},\n",
       "  {'plaintext_start_byte': 5529, 'plaintext_end_byte': 6183},\n",
       "  {'plaintext_start_byte': 6329, 'plaintext_end_byte': 6456},\n",
       "  {'plaintext_start_byte': 6457, 'plaintext_end_byte': 6878},\n",
       "  {'plaintext_start_byte': 6457, 'plaintext_end_byte': 6488},\n",
       "  {'plaintext_start_byte': 6489, 'plaintext_end_byte': 6505},\n",
       "  {'plaintext_start_byte': 6506, 'plaintext_end_byte': 6527},\n",
       "  {'plaintext_start_byte': 6528, 'plaintext_end_byte': 6565},\n",
       "  {'plaintext_start_byte': 6566, 'plaintext_end_byte': 6588},\n",
       "  {'plaintext_start_byte': 6589, 'plaintext_end_byte': 6607},\n",
       "  {'plaintext_start_byte': 6608, 'plaintext_end_byte': 6625},\n",
       "  {'plaintext_start_byte': 6626, 'plaintext_end_byte': 6641},\n",
       "  {'plaintext_start_byte': 6642, 'plaintext_end_byte': 6661},\n",
       "  {'plaintext_start_byte': 6662, 'plaintext_end_byte': 6678},\n",
       "  {'plaintext_start_byte': 6679, 'plaintext_end_byte': 6698},\n",
       "  {'plaintext_start_byte': 6699, 'plaintext_end_byte': 6717},\n",
       "  {'plaintext_start_byte': 6718, 'plaintext_end_byte': 6736},\n",
       "  {'plaintext_start_byte': 6737, 'plaintext_end_byte': 6751},\n",
       "  {'plaintext_start_byte': 6752, 'plaintext_end_byte': 6768},\n",
       "  {'plaintext_start_byte': 6769, 'plaintext_end_byte': 6789},\n",
       "  {'plaintext_start_byte': 6790, 'plaintext_end_byte': 6804},\n",
       "  {'plaintext_start_byte': 6805, 'plaintext_end_byte': 6821},\n",
       "  {'plaintext_start_byte': 6822, 'plaintext_end_byte': 6837},\n",
       "  {'plaintext_start_byte': 6838, 'plaintext_end_byte': 6856},\n",
       "  {'plaintext_start_byte': 6857, 'plaintext_end_byte': 6878},\n",
       "  {'plaintext_start_byte': 6879, 'plaintext_end_byte': 7137},\n",
       "  {'plaintext_start_byte': 7206, 'plaintext_end_byte': 7532},\n",
       "  {'plaintext_start_byte': 7206, 'plaintext_end_byte': 7280},\n",
       "  {'plaintext_start_byte': 7281, 'plaintext_end_byte': 7297},\n",
       "  {'plaintext_start_byte': 7298, 'plaintext_end_byte': 7318},\n",
       "  {'plaintext_start_byte': 7319, 'plaintext_end_byte': 7335},\n",
       "  {'plaintext_start_byte': 7336, 'plaintext_end_byte': 7354},\n",
       "  {'plaintext_start_byte': 7355, 'plaintext_end_byte': 7371},\n",
       "  {'plaintext_start_byte': 7372, 'plaintext_end_byte': 7403},\n",
       "  {'plaintext_start_byte': 7404, 'plaintext_end_byte': 7421},\n",
       "  {'plaintext_start_byte': 7422, 'plaintext_end_byte': 7436},\n",
       "  {'plaintext_start_byte': 7437, 'plaintext_end_byte': 7454},\n",
       "  {'plaintext_start_byte': 7455, 'plaintext_end_byte': 7471},\n",
       "  {'plaintext_start_byte': 7472, 'plaintext_end_byte': 7532},\n",
       "  {'plaintext_start_byte': 7533, 'plaintext_end_byte': 7677},\n",
       "  {'plaintext_start_byte': 7687, 'plaintext_end_byte': 7784},\n",
       "  {'plaintext_start_byte': 7785, 'plaintext_end_byte': 8050},\n",
       "  {'plaintext_start_byte': 7785, 'plaintext_end_byte': 7862},\n",
       "  {'plaintext_start_byte': 7863, 'plaintext_end_byte': 7941},\n",
       "  {'plaintext_start_byte': 7942, 'plaintext_end_byte': 8050},\n",
       "  {'plaintext_start_byte': 8119, 'plaintext_end_byte': 8172},\n",
       "  {'plaintext_start_byte': 8173, 'plaintext_end_byte': 8215},\n",
       "  {'plaintext_start_byte': 8216, 'plaintext_end_byte': 8600},\n",
       "  {'plaintext_start_byte': 8253, 'plaintext_end_byte': 8277},\n",
       "  {'plaintext_start_byte': 8278, 'plaintext_end_byte': 8339},\n",
       "  {'plaintext_start_byte': 8340, 'plaintext_end_byte': 8397},\n",
       "  {'plaintext_start_byte': 8398, 'plaintext_end_byte': 8453},\n",
       "  {'plaintext_start_byte': 8454, 'plaintext_end_byte': 8540},\n",
       "  {'plaintext_start_byte': 8541, 'plaintext_end_byte': 8600},\n",
       "  {'plaintext_start_byte': 8601, 'plaintext_end_byte': 9021},\n",
       "  {'plaintext_start_byte': 9069, 'plaintext_end_byte': 9177},\n",
       "  {'plaintext_start_byte': 9178, 'plaintext_end_byte': 9751},\n",
       "  {'plaintext_start_byte': 9178, 'plaintext_end_byte': 9306},\n",
       "  {'plaintext_start_byte': 9322, 'plaintext_end_byte': 9584},\n",
       "  {'plaintext_start_byte': 9585, 'plaintext_end_byte': 9716},\n",
       "  {'plaintext_start_byte': 9735, 'plaintext_end_byte': 9751},\n",
       "  {'plaintext_start_byte': 9965, 'plaintext_end_byte': 10479},\n",
       "  {'plaintext_start_byte': 10480, 'plaintext_end_byte': 10813},\n",
       "  {'plaintext_start_byte': 10814, 'plaintext_end_byte': 11047},\n",
       "  {'plaintext_start_byte': 11068, 'plaintext_end_byte': 11235},\n",
       "  {'plaintext_start_byte': 11236, 'plaintext_end_byte': 11995},\n",
       "  {'plaintext_start_byte': 11996, 'plaintext_end_byte': 12118},\n",
       "  {'plaintext_start_byte': 12205, 'plaintext_end_byte': 13137},\n",
       "  {'plaintext_start_byte': 13138, 'plaintext_end_byte': 14238},\n",
       "  {'plaintext_start_byte': 14239, 'plaintext_end_byte': 14476},\n",
       "  {'plaintext_start_byte': 14503, 'plaintext_end_byte': 14966},\n",
       "  {'plaintext_start_byte': 14967, 'plaintext_end_byte': 16276},\n",
       "  {'plaintext_start_byte': 14967, 'plaintext_end_byte': 15076},\n",
       "  {'plaintext_start_byte': 15077, 'plaintext_end_byte': 15158},\n",
       "  {'plaintext_start_byte': 15159, 'plaintext_end_byte': 15274},\n",
       "  {'plaintext_start_byte': 15275, 'plaintext_end_byte': 15365},\n",
       "  {'plaintext_start_byte': 15366, 'plaintext_end_byte': 15497},\n",
       "  {'plaintext_start_byte': 15498, 'plaintext_end_byte': 15595},\n",
       "  {'plaintext_start_byte': 15596, 'plaintext_end_byte': 15700},\n",
       "  {'plaintext_start_byte': 15701, 'plaintext_end_byte': 15810},\n",
       "  {'plaintext_start_byte': 15811, 'plaintext_end_byte': 16186},\n",
       "  {'plaintext_start_byte': 16187, 'plaintext_end_byte': 16276},\n",
       "  {'plaintext_start_byte': 16307, 'plaintext_end_byte': 16456},\n",
       "  {'plaintext_start_byte': 16307, 'plaintext_end_byte': 16456},\n",
       "  {'plaintext_start_byte': 16457, 'plaintext_end_byte': 16843},\n",
       "  {'plaintext_start_byte': 16919, 'plaintext_end_byte': 18874},\n",
       "  {'plaintext_start_byte': 18875, 'plaintext_end_byte': 18923},\n",
       "  {'plaintext_start_byte': 18948, 'plaintext_end_byte': 19837},\n",
       "  {'plaintext_start_byte': 19838, 'plaintext_end_byte': 20067},\n",
       "  {'plaintext_start_byte': 20068, 'plaintext_end_byte': 20247},\n",
       "  {'plaintext_start_byte': 20248, 'plaintext_end_byte': 20724},\n",
       "  {'plaintext_start_byte': 20753, 'plaintext_end_byte': 21773},\n",
       "  {'plaintext_start_byte': 21806, 'plaintext_end_byte': 23561},\n",
       "  {'plaintext_start_byte': 23633, 'plaintext_end_byte': 24675},\n",
       "  {'plaintext_start_byte': 24697, 'plaintext_end_byte': 25523},\n",
       "  {'plaintext_start_byte': 25563, 'plaintext_end_byte': 26605},\n",
       "  {'plaintext_start_byte': 26640, 'plaintext_end_byte': 27172},\n",
       "  {'plaintext_start_byte': 27173, 'plaintext_end_byte': 28020},\n",
       "  {'plaintext_start_byte': 28021, 'plaintext_end_byte': 28777},\n",
       "  {'plaintext_start_byte': 28807, 'plaintext_end_byte': 30584},\n",
       "  {'plaintext_start_byte': 30585, 'plaintext_end_byte': 31321}],\n",
       " 'annotations': [{'annotation_id': 2703952710185985039,\n",
       "   'minimal_answer': {'plaintext_start_byte': 7281,\n",
       "    'plaintext_end_byte': 7461},\n",
       "   'passage_answer': {'candidate_index': 34},\n",
       "   'yes_no_answer': 'NONE'},\n",
       "  {'annotation_id': 18167812781706571942,\n",
       "   'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1},\n",
       "   'passage_answer': {'candidate_index': 11},\n",
       "   'yes_no_answer': 'NONE'},\n",
       "  {'annotation_id': 2621982195373552579,\n",
       "   'minimal_answer': {'plaintext_start_byte': 7281,\n",
       "    'plaintext_end_byte': 7461},\n",
       "   'passage_answer': {'candidate_index': 34},\n",
       "   'yes_no_answer': 'NONE'},\n",
       "  {'annotation_id': 6241216130406106851,\n",
       "   'minimal_answer': {'plaintext_start_byte': -1, 'plaintext_end_byte': -1},\n",
       "   'passage_answer': {'candidate_index': 11},\n",
       "   'yes_no_answer': 'NONE'},\n",
       "  {'annotation_id': 2778447470309494845,\n",
       "   'minimal_answer': {'plaintext_start_byte': 7281,\n",
       "    'plaintext_end_byte': 7461},\n",
       "   'passage_answer': {'candidate_index': 34},\n",
       "   'yes_no_answer': 'NONE'}],\n",
       " 'type': ['table', 'table', 'table', 'table', 'table']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "dev_files = glob.glob(\"/dccstor/srosent2/primeqa/data/dev/nq-lfqa/*.jsonl\")\n",
    "dev_data_long = []\n",
    "for dev_file in dev_files:\n",
    "    dev_data_long.extend(load_json_from_file(dev_file))\n",
    "\n",
    "dev_data_long[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/353\n",
      "200/736\n",
      "300/1116\n",
      "400/1455\n",
      "500/1793\n",
      "600/2156\n",
      "700/2519\n",
      "800/2869\n",
      "900/3197\n",
      "1000/3551\n",
      "1100/3887\n",
      "1200/4225\n",
      "1300/4585\n",
      "1400/4947\n",
      "1500/5299\n",
      "1600/5656\n",
      "1700/6042\n",
      "1800/6400\n",
      "1900/6728\n",
      "2000/7088\n",
      "2100/7450\n",
      "2200/7759\n",
      "2300/8113\n",
      "2400/8516\n",
      "2500/8854\n",
      "2600/9223\n",
      "2700/9578\n",
      "2800/9931\n",
      "2900/10294\n",
      "3000/10647\n",
      "3100/10962\n",
      "3200/11306\n",
      "3300/11616\n",
      "3400/11997\n",
      "3500/12334\n",
      "3600/12636\n",
      "3700/12981\n",
      "3800/13348\n",
      "3900/13729\n",
      "4000/14082\n",
      "4100/14382\n",
      "4200/14750\n",
      "4300/15084\n",
      "4400/15448\n",
      "4500/15823\n",
      "4600/16143\n",
      "4700/16513\n",
      "4800/16840\n",
      "4900/17216\n",
      "5000/17619\n",
      "5100/18047\n",
      "5200/18403\n",
      "5300/18785\n",
      "5400/19159\n",
      "5500/19553\n",
      "5600/19881\n",
      "5700/20209\n",
      "5800/20563\n",
      "5900/20889\n",
      "6000/21230\n",
      "6100/21580\n",
      "6200/21908\n",
      "6300/22277\n",
      "6400/22648\n",
      "6500/22989\n",
      "6600/23361\n",
      "6700/23697\n",
      "6800/24072\n",
      "6900/24442\n",
      "7000/24805\n",
      "7100/25130\n",
      "7200/25487\n",
      "7300/25834\n",
      "7400/26195\n",
      "7500/26588\n",
      "7600/26947\n",
      "7700/27301\n",
      "7800/27693\n",
      "7900/28066\n",
      "8000/28386\n",
      "8100/28732\n",
      "8200/29083\n",
      "8300/29399\n",
      "8400/29753\n",
      "8500/30118\n",
      "8600/30428\n",
      "8700/30790\n",
      "8800/31208\n",
      "8900/31606\n",
      "9000/31894\n",
      "9100/32244\n",
      "9200/32587\n",
      "9300/32988\n",
      "9400/33339\n",
      "9500/33665\n",
      "9600/33988\n",
      "9700/34295\n",
      "9800/34727\n",
      "9900/35085\n",
      "10000/35434\n",
      "10100/35760\n",
      "10200/36117\n",
      "10300/36489\n",
      "10400/36878\n",
      "10500/37200\n",
      "10600/37548\n",
      "10700/37904\n",
      "10800/38283\n",
      "10900/38652\n",
      "11000/39024\n",
      "11100/39403\n",
      "11200/39803\n",
      "11300/40234\n",
      "11400/40550\n",
      "11500/40892\n",
      "11600/41264\n",
      "11700/41601\n",
      "11800/41998\n",
      "11900/42356\n",
      "12000/42668\n",
      "12100/43024\n",
      "12200/43361\n",
      "12300/43731\n",
      "12400/44093\n",
      "12500/44436\n",
      "12600/44769\n",
      "12700/45116\n",
      "12800/45474\n",
      "12900/45859\n",
      "13000/46225\n",
      "13100/46571\n",
      "13200/46901\n",
      "13300/47267\n",
      "13400/47638\n",
      "13500/48026\n",
      "13600/48343\n",
      "13700/48685\n",
      "13800/49001\n",
      "13900/49341\n",
      "14000/49743\n",
      "14100/50037\n",
      "14200/50407\n",
      "14300/50805\n",
      "14400/51136\n",
      "14500/51447\n",
      "14600/51811\n",
      "14700/52174\n",
      "14800/52518\n",
      "14900/52878\n",
      "15000/53239\n",
      "15100/53559\n",
      "15200/53870\n",
      "15300/54244\n",
      "15400/54572\n",
      "15500/54937\n",
      "15600/55282\n",
      "15700/55627\n",
      "15800/55933\n",
      "15900/56243\n",
      "16000/56591\n",
      "16100/56965\n",
      "16200/57310\n",
      "16300/57672\n",
      "16400/58032\n",
      "16500/58386\n",
      "16600/58735\n",
      "16700/59135\n",
      "16800/59544\n",
      "16900/59919\n",
      "17000/60266\n",
      "17100/60601\n",
      "17200/60916\n",
      "17300/61247\n",
      "17365/61499\n",
      "{'la': 27027, 'boolean': 3798, 'sa': 0, 'none': 0, 'table': 11778, 'list': 2619, 'null': 0}\n",
      "100/769\n",
      "200/1418\n",
      "300/2164\n",
      "400/2864\n",
      "472/3393\n",
      "{'la': 763, 'boolean': 98, 'sa': 465, 'none': 0, 'table': 281, 'list': 65, 'null': 867}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# for training data only\n",
    "\n",
    "def get_type(annotation):\n",
    "    if annotation['passage_answer']['candidate_index'] == -1:\n",
    "        return 'na'\n",
    "    if annotation['minimal_answer']['plaintext_start_byte'] > -1:\n",
    "        return 'sa'\n",
    "    if annotation['yes_no_answer'] != 'NONE':\n",
    "        return 'bool'\n",
    "    else:\n",
    "        return 'la'\n",
    "  \n",
    "def verify_annotation_count(data, answer_type):\n",
    "    \n",
    "    counts = {'la':0,'boolean':0,'sa':0,'none':0, 'table':0, 'list':0, 'null':0}\n",
    "\n",
    "    count = 0\n",
    "    index = 0\n",
    "    for example in data:\n",
    "        index += 1\n",
    "       \n",
    "        annotation = example['annotations'][0]\n",
    "\n",
    "        if annotation == None:\n",
    "            continue\n",
    "\n",
    "        if annotation['minimal_answer']['plaintext_start_byte'] != -1:\n",
    "            continue\n",
    "        counts[example['type'][0]] += 1\n",
    "        if example['type'][0] != answer_type:\n",
    "            continue\n",
    "               \n",
    "        passage_offsets = example['passage_answer_candidates'][annotation['passage_answer']['candidate_index']]\n",
    "        passage_text = example['document_plaintext'].encode('utf-8')[passage_offsets['plaintext_start_byte']:passage_offsets['plaintext_end_byte']].decode('utf-8')\n",
    "        \n",
    "        num_sentences = len(passage_text.split(\".\"))\n",
    "        \n",
    "        # num_sentences = 0\n",
    "        # for sentence in sentences.sents:\n",
    "        #     num_sentences += 1\n",
    "\n",
    "        if num_sentences < 5:\n",
    "            continue\n",
    "\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(f\"{count}/{index}\")\n",
    "    print(f\"{count}/{index}\")\n",
    "    print(counts)\n",
    "\n",
    "verify_annotation_count(train_data_long, 'la') \n",
    "verify_annotation_count(dev_data_long,'la')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307373\n",
      "61499\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_full))\n",
    "print(len(train_data_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>long_answer</th>\n",
       "      <th>minimal_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1065148654910669702</td>\n",
       "      <td>who were the code talkers and what did they do</td>\n",
       "      <td>Code talker</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Co...</td>\n",
       "      <td>Code talkers are people in the 20th century wh...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6161336059403722646</td>\n",
       "      <td>who is responsible for redrawing congressional...</td>\n",
       "      <td>Redistricting</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Re...</td>\n",
       "      <td>In 28 states , the state legislature has prima...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1009972407158508256</td>\n",
       "      <td>do you put the euro symbol before or after the...</td>\n",
       "      <td>Euro sign</td>\n",
       "      <td>https://en.wikipedia.org//w/index.php?title=Eu...</td>\n",
       "      <td>The euro sign ( € ) is the currency sign used ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            question_id                                           question  \\\n",
       "0  -1065148654910669702     who were the code talkers and what did they do   \n",
       "1  -6161336059403722646  who is responsible for redrawing congressional...   \n",
       "2  -1009972407158508256  do you put the euro symbol before or after the...   \n",
       "\n",
       "           title                                                url  \\\n",
       "0    Code talker  https://en.wikipedia.org//w/index.php?title=Co...   \n",
       "1  Redistricting  https://en.wikipedia.org//w/index.php?title=Re...   \n",
       "2      Euro sign  https://en.wikipedia.org//w/index.php?title=Eu...   \n",
       "\n",
       "                                         long_answer minimal_text  \n",
       "0  Code talkers are people in the 20th century wh...          NaN  \n",
       "1  In 28 states , the state legislature has prima...          NaN  \n",
       "2  The euro sign ( € ) is the currency sign used ...          NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load files to see what has been annotated for dev (and if anything should still be)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#tydi_data = pd.read_json(\"/dccstor/srosent2/generative/appen/final/original_tydi/test/longNQ_test_answerable_tydi.jsonl\",lines=True,orient=\"records\")\n",
    "original_dev_data = pd.read_csv(\"/dccstor/srosent2/generative/data_for_appen/full_nq_task_nomin_dev_notfirst.tsv\", delimiter=\"\\t\", dtype=str)\n",
    "annotated_dev_data = pd.read_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_single-9.15.23_dev.json\", lines=True, orient='records', dtype=str)\n",
    "\n",
    "original_dev_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -1065148654910669702\n",
       "1      -6161336059403722646\n",
       "2      -1009972407158508256\n",
       "3      -4950811927075917485\n",
       "4       8126650568596797201\n",
       "               ...         \n",
       "239     9183769728515813177\n",
       "240    -6130542731927880581\n",
       "241    -5562718362522355071\n",
       "242     6067744271603788282\n",
       "243     1314014560118147785\n",
       "Name: question_id, Length: 244, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dev_data['question_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input</th>\n",
       "      <th>passages</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8597348749484412075</td>\n",
       "      <td>what kind of animal does princess jasmine have...</td>\n",
       "      <td>[{'title': \"List of Disney's Aladdin character...</td>\n",
       "      <td>[{'answer': \"Rajah is Princess Jasmine's pet t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4579239791023850339</td>\n",
       "      <td>who played the orc in lord of the rings</td>\n",
       "      <td>[{'title': 'Lawrence Makoare', 'text': 'Makoar...</td>\n",
       "      <td>[{'answer': 'In The Return of the Ring, he por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3067931010063966525</td>\n",
       "      <td>what is the population of sydney in 2017</td>\n",
       "      <td>[{'title': 'Sydney', 'text': \"Sydney ( / ˈsɪdn...</td>\n",
       "      <td>[{'answer': \"As of June 2017, Sydney's estimat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                              input  \\\n",
       "0   8597348749484412075  what kind of animal does princess jasmine have...   \n",
       "1  -4579239791023850339            who played the orc in lord of the rings   \n",
       "2  -3067931010063966525           what is the population of sydney in 2017   \n",
       "\n",
       "                                            passages  \\\n",
       "0  [{'title': \"List of Disney's Aladdin character...   \n",
       "1  [{'title': 'Lawrence Makoare', 'text': 'Makoar...   \n",
       "2  [{'title': 'Sydney', 'text': \"Sydney ( / ˈsɪdn...   \n",
       "\n",
       "                                              output  \n",
       "0  [{'answer': \"Rajah is Princess Jasmine's pet t...  \n",
       "1  [{'answer': 'In The Return of the Ring, he por...  \n",
       "2  [{'answer': \"As of June 2017, Sydney's estimat...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_dev_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "completed in appen: 384\n",
      "dev set to be annotated: 244\n",
      "{'5092896004240326569', '-7424780667593320090', '-4547742096922519098', '8573011053503667493', '-6959456828837530300', '8825151679647483660', '7205105695796652667', '8201377518358719355', '-2062431639562008643', '5014034923974543089', '-2288554954984872130', '-6761261320447397619', '-8526428323250273438', '-2717750449825978712', '-2538897953919294229', '-453840009279473504', '-6873324306955804871', '3998737477138282236', '1055956944049390471'}\n",
      "{'-5646056836091194880', '-112600240844905447', '6907427372936166627', '9084604251611519852', '-6831117546976231492', '-2930493607495363881', '7078825330678600085', '-3405454990106767111', '-5935683210985272192', '-480770051139847590', '-5130985228372725056', '-4595785795645617006', '55168494140189683', '-1109521761207576670', '4046851836203380467', '-6394021642305140986', '-5276717549584332512', '-2163433583494748797', '8593098226775358914', '-5199162398326752157', '2247250807557083996', '5783164682986114581', '-7146348936280379162', '-7524567160561800616', '9079628211873443319', '3331521999074486282', '-6857185698372403357', '4353796127200895834', '-6820572455772765065', '-1733599216028389486', '103695536222146008', '-6187451959008390485', '-3697600391347486989', '-5777361948264487802', '-1636103814308578967', '-8458859943785727179', '-3946622065085295485', '-1747884962039056100', '-1915051281495968844', '-1446394904764739888', '2266455383924644726', '7152569300818483186', '6839178547474228192', '-7741098467845091640', '4629920912618978409', '810772972080024175', '464806290971548552', '1602216890709254118', '-5715486737703688206', '7483656096034094185', '-5957270386941120779', '495186108393848476', '-113853178908722264', '-3772952199709196386', '8439391267868315000', '1180829738254891996', '-7619703070047018245', '3623329036707397391', '6922281948445554994', '-437208222092000137', '-1769528362781268772', '-2299952073699939803', '8663125622899433567', '5308421567711743018', '2567803341516865697', '-2137922245074894812', '-8391680223788694572', '297857577311545840', '-6867022576468538792', '-6910541884247739685', '-1100776571922066473', '4232795933460718553', '4012917101190794967', '9188359206780164872', '2545607965679456162', '7323495208033851133', '-667585536233219997', '7075559602853408649', '3259945285535844180', '-7778233237890403173', '2577140274301537828', '-6261786306662914709', '-8353097987973046480', '8153175567512322762', '-5345341689626036799', '7988342159023966553', '-3987615030635779915', '4398904483546889087', '8533079479108336590', '-6105123000722847801', '7688531429933381708', '-4815412956812959567', '-8366545547296627039', '700604097171850168', '-4859429630659533610', '7753793359500605772', '-4296931100877367527', '4323871331649279373', '5480436824826220839', '-8473146838282712240', '6471679536081978392', '-3278537129884135433', '-7041492222442041722', '-864239359964960011', '2146143093796977535', '1059245342091045794', '-4950472843406558062', '5518515944351776633', '2079625003362967146', '-3712648842797144882', '9050098303086371705', '2236521535238054703', '7756227667165778451', '-4843437099290518220', '7281701387754006749', '-9022769667581203573', '-3672139806378353884', '6067202541314094683', '-3719623571078658627', '5039379954253353144', '3063199819637642694', '-5187723577508700915', '7647339054759303922', '4440911260005876349', '3935460856147254218', '-6592930185579555872', '6277987745161874494', '7074367758797858357', '-4613603971460615511', '587999005951345244', '2021564516056105015', '-3677675061277118953', '-8498955431733322253', '206259850951848123', '-4159010968122813872', '4764100575661627990', '-3098183913232160451', '453096709814985147', '-5434619514071340448', '8172034568090428011', '8660243868576307033', '7447169337758219958', '-4295890134982682500', '-3344403727454433038', '-5559443388832069073', '-6651255565624706987', '8494342737238168262', '-3632972835558527833', '1988662011276832086', '-8061211071687487091', '8971771098313710059', '4168225793730595982', '2358325362897837240', '2758477882950225590', '-7491187190913609813', '-7254388745571129306', '-2557047790386805329', '5449262060389880454', '-2418032234376469176'}\n"
     ]
    }
   ],
   "source": [
    "print(len(set(annotated_dev_data['id']) & set(original_dev_data['question_id'])))\n",
    "print(f\"completed in appen: {len(set(annotated_dev_data['id']))}\")\n",
    "print(f\"dev set to be annotated: {len(set(original_dev_data['question_id']))}\")\n",
    "print(set(original_dev_data['question_id'])-set(annotated_dev_data['id']))\n",
    "print(set(annotated_dev_data['id'])-set(original_dev_data['question_id']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('primeqaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "229bd894a0cdb05b7ee80ea2bc43559a301775857073a25e64e4f441f37822ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d58979d",
   "metadata": {},
   "source": [
    "# TydiQA - support for boolean questions\n",
    "\n",
    "Here we assume that you have used `run_mrc.py` with the `--do_boolean` option to decode the TydiQA dataset with full support for boolean questions.  See top-level README.md. There are four stages in the process:\n",
    "\n",
    "1. MRC (**M**achine **R**eading **C**omprehension) - given a question and and answer, find a representative span that may contain a short answer.  This is analyzed in detail in the `tydiqa.ipynb`\n",
    "2. QTC (**Q**uestion **T**ype **C**lassification) - given the question, decide if it is `boolean` or `short_answer`\n",
    "3. EVC (**Ev**idence **C**lassifier) - given a question and a short answer span, decide the short answer span supports `yes` or `no`.  This is analyzed in more detail in `evc.ipynb`.\n",
    "4. SN (**S**core **N**ormalization) - span scores may have different dynamic ranges according as whether the question is `boolean` or `short_anwer`.  Normalize them uniformally to $[0,1]$\n",
    "\n",
    "In this notebook, we will show what happened internally in each step of the operation by looking at intermediate files from the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e2ffcf",
   "metadata": {},
   "source": [
    "# Intermediate files\n",
    "\n",
    "We will load some output/intermediate files from a recent command-line experiment with command\n",
    "```\n",
    "python examples/mrc/run_mrc.py --model_name_or_path ibm/tydiqa-primary-task-xlm-roberta-large \\\n",
    "       --output_dir ${OUTPUT_DIR} --fp16 --do_eval \\\n",
    "       --per_device_eval_batch_size 128 --overwrite_output_dir \\\n",
    "       --postprocessor primeqa.boolqa.processors.postprocessors.extractive.ExtractivePipelinePostProcessor \\\n",
    "       --do_boolean --boolean_config ${BOOLEAN_CONFIG_FILE}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b166b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrc_file=f'{base}/eval_predictions.json'\n",
    "qtc_file=f'{base}/qtc/eval_predictions.json'\n",
    "evc_file=f'{base}/evc/eval_predictions.json'\n",
    "out_file=f'{base}/sn/eval_predictions_processed.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2d1ef5",
   "metadata": {},
   "source": [
    "# Display helper\n",
    "\n",
    "Our intermediate files have many fields - to display them better we use a helper routine to convert to dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75834e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeqa.boolqa.processors.dataset.mrc2dataset  import create_dataset_from_run_mrc_output\n",
    "\n",
    "from datasets import ClassLabel, Sequence\n",
    "from numpy.random import permutation\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Based on https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb\n",
    "def show_balanced_examples(dataset, perm, groups, nrows, maxchars, cols):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    dfp = df.iloc[perm] # shuffle\n",
    "    dfg = dfp.groupby(groups)\n",
    "    df_todisplay = dfg.head(nrows)[cols]\n",
    "    if 'passage_answer_text' in cols:\n",
    "        df_todisplay['passage_answer_text'] = df_todisplay['passage_answer_text'].str.slice(0,maxchars) + '...'\n",
    "    display(HTML(df_todisplay.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550c7d6",
   "metadata": {},
   "source": [
    "# Samples of MRC output\n",
    "\n",
    "Here we show `question`'s and the predicted answer `span_answer_text` for the random examples (one from each language.)  This is at the initial stage of question answering - a purely extractive system.  The confidence in the span answer is given by `span_answer_score`, which is a function of various other logits available in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ecb031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question</th>\n",
       "      <th>span_answer_text</th>\n",
       "      <th>language</th>\n",
       "      <th>span_answer_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>40d6b689-2367-400b-8696-7b4699319250</td>\n",
       "      <td>Onko seminoleilla oma kieli?</td>\n",
       "      <td>Kieltä puhuvat creekit ja seminolit Oklahomassa ja Floridassa</td>\n",
       "      <td>finnish</td>\n",
       "      <td>-9.770508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>51b64c30-b88b-4df2-a031-4aea7767cc2b</td>\n",
       "      <td>2018년 한해동안 가장 많은 강수량을 기록한 나라는 어디인가?</td>\n",
       "      <td>대한민국</td>\n",
       "      <td>korean</td>\n",
       "      <td>0.393555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13250</th>\n",
       "      <td>b8ba1fe6-4151-48c6-b01e-9601745f47cd</td>\n",
       "      <td>mata uang apakah yang digunakan di brazil?</td>\n",
       "      <td>Real Brasil</td>\n",
       "      <td>indonesian</td>\n",
       "      <td>6.929688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>63da4d5b-c749-4ea4-983b-66175aa4fffd</td>\n",
       "      <td>পশ্চিমবঙ্গের মুর্শিদাবাদ জেলার সদর শহর কোনটি ?</td>\n",
       "      <td>বহরমপুর</td>\n",
       "      <td>bengali</td>\n",
       "      <td>6.760742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>d492809f-ee82-499a-83c5-47978f4f2384</td>\n",
       "      <td>2014 వరకి విజయవాడలో అతిపెద్ద కట్టడం ఏది?</td>\n",
       "      <td>నల్లూరి వెంకటేశ్వర్లు</td>\n",
       "      <td>telugu</td>\n",
       "      <td>-7.500366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>ef360d58-694c-49b3-b54a-a8751e4caa8d</td>\n",
       "      <td>ローリング・ストーンズはいつ結成した？</td>\n",
       "      <td>1962年4月の</td>\n",
       "      <td>japanese</td>\n",
       "      <td>9.826660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16352</th>\n",
       "      <td>a407bfdb-4209-472f-9023-1d2bde833319</td>\n",
       "      <td>Где разворачивается действие игры Dreamfall Chapters?</td>\n",
       "      <td>двух параллельных мирах — Старке, антиутопичном будущем Земли, и Аркадии, его магическом мире-двойнике</td>\n",
       "      <td>russian</td>\n",
       "      <td>7.372070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8929</th>\n",
       "      <td>db464794-b7c0-4659-a898-6c3b26b70caa</td>\n",
       "      <td>อีดี อามิน มีภรรยาชื่อว่าอะไร?</td>\n",
       "      <td>มาดินา อามิน</td>\n",
       "      <td>thai</td>\n",
       "      <td>4.783203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>9136366d-4825-42bd-bd49-c4cd3f75d673</td>\n",
       "      <td>في أي عام تولى عبد الفتاح السيسي الحكم في مصر؟</td>\n",
       "      <td>2014</td>\n",
       "      <td>arabic</td>\n",
       "      <td>6.965820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14054</th>\n",
       "      <td>2cc55a29-83a6-4224-bfe6-2cde22c5c2ee</td>\n",
       "      <td>Kisiwa cha Pemba kina mitaa mingapi?</td>\n",
       "      <td>980 km².</td>\n",
       "      <td>swahili</td>\n",
       "      <td>0.041016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>69f73e21-05c9-40c9-8988-9fb06f5d6e87</td>\n",
       "      <td>Is there a championship for stock car racing?</td>\n",
       "      <td>Bobby Isaac</td>\n",
       "      <td>english</td>\n",
       "      <td>-7.368580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_examples=create_dataset_from_run_mrc_output(mrc_file, unpack=False)\n",
    "random_idxs = permutation(len(eval_examples))\n",
    "\n",
    "cols=['example_id','question','span_answer_text','language', 'span_answer_score']\n",
    "show_balanced_examples(eval_examples, random_idxs, 'language', 1, 100, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a891b",
   "metadata": {},
   "source": [
    "# Samples of QTC output\n",
    "\n",
    "At this stage, two fields have been added: `question_type_pred` which is `boolean` if the question is a boolean question, and `short_answer` if the question is not boolean - typically factoid in this dataset.\n",
    "The other field `question_type_scores` contains the classifier scores (logits) for each class. \n",
    "By far the majority of questions in TydiQA are `short_answer`: we present random examples chosen equally from those predicted `boolean` and those predicted `short_answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c748f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9812600e358b45a4a6bad439fbd3fdd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_type_pred</th>\n",
       "      <th>question_type_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>4fb782e6-fc06-41f0-a511-2f67ed428ff3</td>\n",
       "      <td>How large is the German military today?</td>\n",
       "      <td>short_answer</td>\n",
       "      <td>{'boolean': -2.996520519256592, 'short_answer': 3.7801873683929443}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>e1b05e1b-de67-46af-8393-f996ebcecf4e</td>\n",
       "      <td>What is the largest rail yard in the New York City Subway system?</td>\n",
       "      <td>short_answer</td>\n",
       "      <td>{'boolean': -2.9972739219665527, 'short_answer': 3.7812328338623047}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1478b75c-7f5f-411d-9bc5-99c009ae15a4</td>\n",
       "      <td>On what network did Space: 1999 originally air?</td>\n",
       "      <td>short_answer</td>\n",
       "      <td>{'boolean': -2.997262477874756, 'short_answer': 3.7814853191375732}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>548f4820-75a8-4909-93b8-5c88c3f97795</td>\n",
       "      <td>What is the most watched show on Oklahoma?</td>\n",
       "      <td>short_answer</td>\n",
       "      <td>{'boolean': -2.9975571632385254, 'short_answer': 3.7821381092071533}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0d928e95-3286-47ff-8c2c-9018f84a86ce</td>\n",
       "      <td>How many countries are in Africa?</td>\n",
       "      <td>short_answer</td>\n",
       "      <td>{'boolean': -2.9956188201904297, 'short_answer': 3.778301477432251}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>78ef1304-b481-4de9-966a-5635f3c6dd10</td>\n",
       "      <td>Is Windex poisonous?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.414430618286133, 'short_answer': -4.332897186279297}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>bbb56373-e84e-4fde-8858-be612b8f5d2c</td>\n",
       "      <td>Is Cantonese written the same as Mandarin?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.4161205291748047, 'short_answer': -4.3320770263671875}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>398f7acb-3508-4b19-8440-8a685799eade</td>\n",
       "      <td>Did Dilophosaurus have feathers?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.4151928424835205, 'short_answer': -4.333571910858154}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>24970674-4111-4cef-97b4-9de085794256</td>\n",
       "      <td>Is there a term limit to the Russian presidency?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.417029619216919, 'short_answer': -4.33302640914917}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2c73eb36-c0e2-4c1c-8ebe-27d61d0ae713</td>\n",
       "      <td>Was Slovenia ever under Roman rule?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>{'boolean': 3.417308807373047, 'short_answer': -4.332035541534424}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_examples=create_dataset_from_run_mrc_output(qtc_file, unpack=False)\n",
    "english_eval_examples = eval_examples.filter(lambda x:x['language']=='english')\n",
    "random_idxs = permutation(len(english_eval_examples))\n",
    "cols=['example_id','question','question_type_pred', 'question_type_scores']\n",
    "show_balanced_examples(english_eval_examples, random_idxs, 'question_type_pred', 5, 100, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49dbb3",
   "metadata": {},
   "source": [
    "# Samples of EVC output \n",
    "As above this classifier adds two new fields.  `boolean_answer_pred` is `yes` if the predicted answer to a boolean question is positive/true/yes, `no` if the answer is negative/false/no, and `no_answer` if there is no support for either answer in the context.  The field `boolean_answer_scores` provides the scores (logits) of each class.\n",
    "For the TydiQA evaluation, we discard the `no_answer` prediction and always predict `yes` or `no`.  Other application may choose a different behavior.\n",
    "\n",
    "For presentation purposes, we select the English questions from the dev set (they are not scored by tydi_eval.py), which have a higher fraction of boolean questions.  The boolean questions in the tydi dataset are overwhelmingly biased towards having a `yes` rather than a `no`  as the answer.  We suspect that the question writers were attempting to confirm existing knowledge.\n",
    "Note that the answer classifier runs on all questions, even on the short answer questions, for simplicity.  A real deployed system would run the answer classifier only on questions that are predicted to be boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbfa3a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74430cff8be46efb1ea094358967caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>question</th>\n",
       "      <th>passage_answer_text</th>\n",
       "      <th>boolean_answer_pred</th>\n",
       "      <th>boolean_answer_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9cd50fd0-eeb1-4146-935b-438caceccb19</td>\n",
       "      <td>Is oiliness of the skin considered a disease?</td>\n",
       "      <td>Sebaceous glands are microscopic exocrine glands in the skin that secrete an oily or waxy matter, called sebum, to lubricate and waterproof the skin and hair of mammals. In humans, they occur in the greatest number on the face and scalp, but also on all parts of the skin except the palms of the hand...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -5.162100791931152, 'no_answer': 6.438989162445068, 'yes': -0.6098946928977966}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>c463b465-d068-4fa1-80b9-819683217594</td>\n",
       "      <td>Does Kenshin take place during the Meiji era?</td>\n",
       "      <td>Rurouni Kenshin: Meiji Swordsman Romantic Story(Japanese:るろうに剣心 -明治剣客浪漫譚-,Hepburn:Rurōni Kenshin -Meiji Kenkaku Romantan-),[lower-alpha 1] also known as Samurai X, is a Japanese manga series written and illustrated by Nobuhiro Watsuki. The story begins during the 11th year of the Meiji period in Jap...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -4.352438449859619, 'no_answer': -2.97670578956604, 'yes': 6.797365665435791}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0ed01f94-b8c7-43ad-bf68-d861da8bbb11</td>\n",
       "      <td>Does Bob Jones University do any research?</td>\n",
       "      <td>The school offers undergraduate majors in biology (zoo and wildlife, and cell biology[48]), premed/predent, chemistry, engineering, and physics and also offers courses in astronomy. Between 80% and 100% of the pre-med graduates are accepted to medical school every year.[49] The Department of Biology...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -6.790474891662598, 'no_answer': 2.862802743911743, 'yes': 3.7170300483703613}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>14e03c4b-effd-459f-aea9-8da1cf936cbd</td>\n",
       "      <td>Did American Epic play in theaters?</td>\n",
       "      <td>The film was previewed as a work in progress at film festivals around the world throughout 2016, including a Special Event at Sundance hosted by Robert Redford,[55] SXSW,[56] International Documentary Film Festival Amsterdam,[57] Denver International Film Festival,[58] Sydney Film Festival,[59] and ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -5.135706901550293, 'no_answer': 1.3839850425720215, 'yes': 3.9040300846099854}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2254035a-f43d-48e9-9eae-ef1c1e626f96</td>\n",
       "      <td>Can salt marsh die-off be fixed?</td>\n",
       "      <td>Research on the salt marsh snail Littoraria irrorata and its effects on marsh plant productivity, have provided strong evidence of consumer control in marshes triggered by overexploitation. This snail is capable of turning strands of cordgrass (Spartina alterniflora) (&gt;2.5m tall) into mudflats withi...</td>\n",
       "      <td>yes</td>\n",
       "      <td>{'no': -5.444829940795898, 'no_answer': 6.888958930969238, 'yes': -1.1627817153930664}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>e215f384-0afa-4477-b34a-d5f75ac8a467</td>\n",
       "      <td>Is the Mauser C96 produced today?</td>\n",
       "      <td>The Spanish gunmaker Astra-Unceta y Cia began producing a copy of the Mauser C.96 in 1927 that was externally similar to the C96 (including the presence of a detachable shoulder stock/holster) but with non-interlocking internal parts. It was produced until 1941, with a production hiatus in 1937 and ...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 3.608994245529175, 'no_answer': 0.8599523901939392, 'yes': -4.0795159339904785}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bbb56373-e84e-4fde-8858-be612b8f5d2c</td>\n",
       "      <td>Is Cantonese written the same as Mandarin?</td>\n",
       "      <td>General estimates of vocabulary differences between Cantonese and Mandarin range from 30 to 50 percent. Donald B. Snow, the author of Cantonese as Written Language: The Growth of a Written Chinese Vernacular, wrote that \"It is difficult to quantify precisely how different\" the two vocabularies are.[...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 6.1006059646606445, 'no_answer': -1.4011447429656982, 'yes': -4.083403587341309}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1a47aa43-2afb-4d16-a472-d2a9e71f3195</td>\n",
       "      <td>Does the KGB still exist?</td>\n",
       "      <td>The KGB (Russian:Комите́т Госуда́рственной Безопа́сности (КГБ), tr.Komitet Gosudarstvennoy Bezopasnosti,IPA:[kəmʲɪˈtʲet ɡəsʊˈdarstvʲɪnːəj bʲɪzɐˈpasnəsʲtʲɪ](listen)), translated in English as Committee for State Security, was the main security agency for the Soviet Union from 1954 until its break-up ...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 6.468663692474365, 'no_answer': -2.3071203231811523, 'yes': -3.554609775543213}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>64caf47e-c348-4b2c-a90a-45aae4930784</td>\n",
       "      <td>Were there ever any WMD in Iraq?</td>\n",
       "      <td>In January 2003, United Nations weapons inspectors reported that they had found no indication that Iraq possessed nuclear weapons or an active program. Some former UNSCOM inspectors disagree about whether the United States could know for certain whether or not Iraq had renewed production of weapons ...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': -1.4815336465835571, 'no_answer': 4.486413478851318, 'yes': -2.3255317211151123}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>8de36edd-c6fe-4d29-90e5-c0b3cd605a30</td>\n",
       "      <td>Are any U.S. battleships still active?</td>\n",
       "      <td>When the last Iowa-class ship was finally stricken from the Naval Vessel Registry, no battleships remained in service or in reserve with any navy worldwide. A number are preserved as museum ships, either afloat or in drydock. The U.S. has eight battleships on display: Massachusetts, North Carolina, ...</td>\n",
       "      <td>no</td>\n",
       "      <td>{'no': 6.306628227233887, 'no_answer': -1.8138644695281982, 'yes': -3.84908127784729}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_examples=create_dataset_from_run_mrc_output(evc_file, unpack=False)\n",
    "english_boolean_eval_examples = eval_examples.filter(lambda x:x['language']=='english' and x['question_type_pred']=='boolean')\n",
    "random_idxs = permutation(len(english_boolean_eval_examples))\n",
    "cols=['example_id','question','passage_answer_text', 'boolean_answer_pred', 'boolean_answer_scores']\n",
    "show_balanced_examples(english_boolean_eval_examples, random_idxs, 'boolean_answer_pred', 5, 300, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a2201",
   "metadata": {},
   "source": [
    "# Final output\n",
    "\n",
    "The final output file is in a format suitable for the tydi evalutation script and contains no textual information.  The `confidence_score` is normalized to `[0,1]` by the score normalizer based the confidence score of the original mrc output, and the prediction of the question type classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "362efbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>start_position</th>\n",
       "      <th>end_position</th>\n",
       "      <th>passage_index</th>\n",
       "      <th>yes_no_answer</th>\n",
       "      <th>confidence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>740c33ae-78b9-40e5-8444-b6c8d2776776</td>\n",
       "      <td>986</td>\n",
       "      <td>1020</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e7541e40-46ec-494c-b0d6-a9c435568f2b</td>\n",
       "      <td>385</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>869198a8-fc4d-43b4-bed7-24a61c17d8ab</td>\n",
       "      <td>14805</td>\n",
       "      <td>14807</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.099508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308f64d3-2794-410c-b2d5-10472b7e6661</td>\n",
       "      <td>6703</td>\n",
       "      <td>6715</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87ade38f-9ae7-4a98-8558-335772c33843</td>\n",
       "      <td>2539</td>\n",
       "      <td>2544</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18665</th>\n",
       "      <td>6504cb42-77d4-4a7d-a8bd-00d7f2df8994</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18666</th>\n",
       "      <td>704baa32-153b-45fb-9ef2-ca9f2e7265fd</td>\n",
       "      <td>5770</td>\n",
       "      <td>5777</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18667</th>\n",
       "      <td>5383daad-3b82-4e34-ad04-0c08a3ff86f7</td>\n",
       "      <td>1483</td>\n",
       "      <td>1541</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18668</th>\n",
       "      <td>a737ab02-a0a0-4b09-9ea8-ea348d19e212</td>\n",
       "      <td>61</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18669</th>\n",
       "      <td>f2346e03-0710-4841-b28c-e3caaec4c1ed</td>\n",
       "      <td>1455</td>\n",
       "      <td>1461</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.067554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18670 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 example_id  start_position  end_position  \\\n",
       "0      740c33ae-78b9-40e5-8444-b6c8d2776776             986          1020   \n",
       "1      e7541e40-46ec-494c-b0d6-a9c435568f2b             385           388   \n",
       "2      869198a8-fc4d-43b4-bed7-24a61c17d8ab           14805         14807   \n",
       "3      308f64d3-2794-410c-b2d5-10472b7e6661            6703          6715   \n",
       "4      87ade38f-9ae7-4a98-8558-335772c33843            2539          2544   \n",
       "...                                     ...             ...           ...   \n",
       "18665  6504cb42-77d4-4a7d-a8bd-00d7f2df8994               1            12   \n",
       "18666  704baa32-153b-45fb-9ef2-ca9f2e7265fd            5770          5777   \n",
       "18667  5383daad-3b82-4e34-ad04-0c08a3ff86f7            1483          1541   \n",
       "18668  a737ab02-a0a0-4b09-9ea8-ea348d19e212              61            69   \n",
       "18669  f2346e03-0710-4841-b28c-e3caaec4c1ed            1455          1461   \n",
       "\n",
       "       passage_index  yes_no_answer  confidence_score  \n",
       "0                  2              0          0.697498  \n",
       "1                  1              0          0.044546  \n",
       "2                 27              0          0.099508  \n",
       "3                 13              0          0.083534  \n",
       "4                  6              0          0.081707  \n",
       "...              ...            ...               ...  \n",
       "18665              0              0          0.213102  \n",
       "18666             16              0          0.034656  \n",
       "18667              4              0          0.172497  \n",
       "18668              0              0          0.120389  \n",
       "18669              3              0          0.067554  \n",
       "\n",
       "[18670 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

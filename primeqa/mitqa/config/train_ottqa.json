{
    "per_device_train_batch_size_rr":8,
    "per_device_eval_batch_size_rr":8,
    "rr_model_name":"bert-base-uncased",
    "row_retriever_model_name_path":"bert-base-uncased",
    "pos_frac_per_epoch":[0.3, 0.3, 0.1, 0.0001, 0.0001],
    "group_frac_per_epoch":[0.0, 0.0, 0.0, 0.0, 0.0],
    "num_train_epochs_rr":2,
    "save_every_niter_rr":100,
    "save_model_path_rr":"data/ottqa/models/row_retriever/rr.bin",
    "max_seq_length":512,
    "per_gpu_train_batch_size":8,
    "train_batch_size":8,
    "per_gpu_eval_batch_size":8,
    "eval_batch_size":4,
    "max_query_length":64,
    "threads":1,
    "null_score_diff_threshold":0.0,
    "n_best_size":20,
    "do_lower_case":true,
    "do_train_ae":true,
    "do_eval_ae":true,
    "n_gpu":1,
    "max_answer_length":30,
    "model_name_or_path_ae":"bert-base-uncased",
    "output_dir":"data/ottqa/models/answer_extractor/",
    "model_type":"bert",
    "doc_stride":128,
    "train_file":"data/ottqa/ae_input_train.json",
    "eval_file":"data/ottqa/ae_input_dev.json",
    "pred_ans_file":"data/ottqa/predictions/answer_extractor_output_test.json",
    "model":"gpt2",
    "top_k":0,
    "top_p":0.9,
    "seed_lg":42,
    "batch_size_lg":2,
    "linker_model":"data/ottqa/models/link_generator/model-ep9.pt",
    "max_source_len":32,
    "max_target_len":16,
    "do_train_lg":false,
    "do_all_lg":true,
    "learning_rate_lg":5e-6,
    "data_path_root":"data/ottqa/",
    "dataset_name":"ottqa",
    "train_data_path":"data/ottqa/released_data/train.json",
    "dev_data_path":"data/ottqa/released_data/dev.json",
    "collections_file":"linearized_tables.tsv"

}

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Machine Reading Comprehension (MRC) &#8212; PrimeQA  documentation</title>
<link rel="stylesheet" href="../../_static/plex.css" type="text/css">

<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="icon" sizes="16x16" type="image/png" href="../../_static/primeqa_logo.png" />
    <link rel="icon" sizes="32x32" type="image/png" href="../../_static/primeqa_logo.png" />
    <link rel="apple-touch-icon" sizes="180x180" type="image/png" href="../../_static/primeqa_logo.png" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
<script async
    src="https://api.countapi.xyz/hit/mnlp-qa-dev-2.sl.cloud9.ibm.com/visits?callback=callbackCounter"></script>
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="light">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">PrimeQA: The Prime Repository for QA</p>
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../development.html">
  Development
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../testing.html">
  Testing
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../index.html">
  API
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../tutorials/index.html">
  Tutorials
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/primeqa/primeqa/" rel="noopener" target="_blank" title="GitHub"><img src="https://badgen.net/github/stars/primeqa/primeqa?icon=github" class="icon-link-image" alt="GitHub"/></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://join.slack.com/t/primeqaworkspace/shared_invite/zt-1edc4fn7n-6aUO0CCvDOMOLb0drROwSw" rel="noopener" target="_blank" title="Slack"><img src="https://cdn.bfldr.com/5H442O3W/at/pl546j-7le8zk-6gwiyo/Slack_Mark.svg?auto=webp&format=png" class="icon-link-image" alt="Slack"/></a>
        </li>
      </ul>
      </div>
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><div class="custom-left-section-api-pkg" style="padding: 0 1.5rem">


        <h4 style="color: #c9d1d9">API</h4>
        <p style="color: #c9d1d9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="width: 1em; height: 1em;">
                        <path style="fill: #c9d1d9"
                                d="M232.5 5.171C247.4-1.718 264.6-1.718 279.5 5.171L498.1 106.2C506.6 110.1 512 118.6 512 127.1C512 137.3 506.6 145.8 498.1 149.8L279.5 250.8C264.6 257.7 247.4 257.7 232.5 250.8L13.93 149.8C5.438 145.8 0 137.3 0 127.1C0 118.6 5.437 110.1 13.93 106.2L232.5 5.171zM498.1 234.2C506.6 238.1 512 246.6 512 255.1C512 265.3 506.6 273.8 498.1 277.8L279.5 378.8C264.6 385.7 247.4 385.7 232.5 378.8L13.93 277.8C5.438 273.8 0 265.3 0 255.1C0 246.6 5.437 238.1 13.93 234.2L67.13 209.6L219.1 279.8C242.5 290.7 269.5 290.7 292.9 279.8L444.9 209.6L498.1 234.2zM292.9 407.8L444.9 337.6L498.1 362.2C506.6 366.1 512 374.6 512 383.1C512 393.3 506.6 401.8 498.1 405.8L279.5 506.8C264.6 513.7 247.4 513.7 232.5 506.8L13.93 405.8C5.438 401.8 0 393.3 0 383.1C0 374.6 5.437 366.1 13.93 362.2L67.13 337.6L219.1 407.8C242.5 418.7 269.5 418.7 292.9 407.8V407.8z" />
                </svg>
                <strong><a href="../boolqa/index.html">Boolean Question Answer</a></strong>
        </p>
        <p style="color: #c9d1d9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="width: 1em; height: 1em;">
                        <path style="fill: #c9d1d9"
                                d="M232.5 5.171C247.4-1.718 264.6-1.718 279.5 5.171L498.1 106.2C506.6 110.1 512 118.6 512 127.1C512 137.3 506.6 145.8 498.1 149.8L279.5 250.8C264.6 257.7 247.4 257.7 232.5 250.8L13.93 149.8C5.438 145.8 0 137.3 0 127.1C0 118.6 5.437 110.1 13.93 106.2L232.5 5.171zM498.1 234.2C506.6 238.1 512 246.6 512 255.1C512 265.3 506.6 273.8 498.1 277.8L279.5 378.8C264.6 385.7 247.4 385.7 232.5 378.8L13.93 277.8C5.438 273.8 0 265.3 0 255.1C0 246.6 5.437 238.1 13.93 234.2L67.13 209.6L219.1 279.8C242.5 290.7 269.5 290.7 292.9 279.8L444.9 209.6L498.1 234.2zM292.9 407.8L444.9 337.6L498.1 362.2C506.6 366.1 512 374.6 512 383.1C512 393.3 506.6 401.8 498.1 405.8L279.5 506.8C264.6 513.7 247.4 513.7 232.5 506.8L13.93 405.8C5.438 401.8 0 393.3 0 383.1C0 374.6 5.437 366.1 13.93 362.2L67.13 337.6L219.1 407.8C242.5 418.7 269.5 418.7 292.9 407.8V407.8z" />
                </svg>
                <strong><a href="../calibration/index.html">Calibration</a></strong>
        </p>
        <p style="color: #c9d1d9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="width: 1em; height: 1em;">
                        <path style="fill: #c9d1d9"
                                d="M232.5 5.171C247.4-1.718 264.6-1.718 279.5 5.171L498.1 106.2C506.6 110.1 512 118.6 512 127.1C512 137.3 506.6 145.8 498.1 149.8L279.5 250.8C264.6 257.7 247.4 257.7 232.5 250.8L13.93 149.8C5.438 145.8 0 137.3 0 127.1C0 118.6 5.437 110.1 13.93 106.2L232.5 5.171zM498.1 234.2C506.6 238.1 512 246.6 512 255.1C512 265.3 506.6 273.8 498.1 277.8L279.5 378.8C264.6 385.7 247.4 385.7 232.5 378.8L13.93 277.8C5.438 273.8 0 265.3 0 255.1C0 246.6 5.437 238.1 13.93 234.2L67.13 209.6L219.1 279.8C242.5 290.7 269.5 290.7 292.9 279.8L444.9 209.6L498.1 234.2zM292.9 407.8L444.9 337.6L498.1 362.2C506.6 366.1 512 374.6 512 383.1C512 393.3 506.6 401.8 498.1 405.8L279.5 506.8C264.6 513.7 247.4 513.7 232.5 506.8L13.93 405.8C5.438 401.8 0 393.3 0 383.1C0 374.6 5.437 366.1 13.93 362.2L67.13 337.6L219.1 407.8C242.5 418.7 269.5 418.7 292.9 407.8V407.8z" />
                </svg>
                <strong><a href="../distillation/index.html">Distillation</a></strong>
        </p>
        <p style="color: #c9d1d9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="width: 1em; height: 1em;">
                        <path style="fill: #c9d1d9"
                                d="M232.5 5.171C247.4-1.718 264.6-1.718 279.5 5.171L498.1 106.2C506.6 110.1 512 118.6 512 127.1C512 137.3 506.6 145.8 498.1 149.8L279.5 250.8C264.6 257.7 247.4 257.7 232.5 250.8L13.93 149.8C5.438 145.8 0 137.3 0 127.1C0 118.6 5.437 110.1 13.93 106.2L232.5 5.171zM498.1 234.2C506.6 238.1 512 246.6 512 255.1C512 265.3 506.6 273.8 498.1 277.8L279.5 378.8C264.6 385.7 247.4 385.7 232.5 378.8L13.93 277.8C5.438 273.8 0 265.3 0 255.1C0 246.6 5.437 238.1 13.93 234.2L67.13 209.6L219.1 279.8C242.5 290.7 269.5 290.7 292.9 279.8L444.9 209.6L498.1 234.2zM292.9 407.8L444.9 337.6L498.1 362.2C506.6 366.1 512 374.6 512 383.1C512 393.3 506.6 401.8 498.1 405.8L279.5 506.8C264.6 513.7 247.4 513.7 232.5 506.8L13.93 405.8C5.438 401.8 0 393.3 0 383.1C0 374.6 5.437 366.1 13.93 362.2L67.13 337.6L219.1 407.8C242.5 418.7 269.5 418.7 292.9 407.8V407.8z" />
                </svg>
                <strong><a href="../ir/index.html">Information Retrieval</a></strong>
        </p>
        <p style="color: #c9d1d9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="width: 1em; height: 1em;">
                        <path style="fill: #c9d1d9"
                                d="M232.5 5.171C247.4-1.718 264.6-1.718 279.5 5.171L498.1 106.2C506.6 110.1 512 118.6 512 127.1C512 137.3 506.6 145.8 498.1 149.8L279.5 250.8C264.6 257.7 247.4 257.7 232.5 250.8L13.93 149.8C5.438 145.8 0 137.3 0 127.1C0 118.6 5.437 110.1 13.93 106.2L232.5 5.171zM498.1 234.2C506.6 238.1 512 246.6 512 255.1C512 265.3 506.6 273.8 498.1 277.8L279.5 378.8C264.6 385.7 247.4 385.7 232.5 378.8L13.93 277.8C5.438 273.8 0 265.3 0 255.1C0 246.6 5.437 238.1 13.93 234.2L67.13 209.6L219.1 279.8C242.5 290.7 269.5 290.7 292.9 279.8L444.9 209.6L498.1 234.2zM292.9 407.8L444.9 337.6L498.1 362.2C506.6 366.1 512 374.6 512 383.1C512 393.3 506.6 401.8 498.1 405.8L279.5 506.8C264.6 513.7 247.4 513.7 232.5 506.8L13.93 405.8C5.438 401.8 0 393.3 0 383.1C0 374.6 5.437 366.1 13.93 362.2L67.13 337.6L219.1 407.8C242.5 418.7 269.5 418.7 292.9 407.8V407.8z" />
                </svg>
                <strong><a href="../mrc/index.html">Machine Reading Comprehension</a></strong>
        </p>
        <p style="color: #c9d1d9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="width: 1em; height: 1em;">
                        <path style="fill: #c9d1d9"
                                d="M232.5 5.171C247.4-1.718 264.6-1.718 279.5 5.171L498.1 106.2C506.6 110.1 512 118.6 512 127.1C512 137.3 506.6 145.8 498.1 149.8L279.5 250.8C264.6 257.7 247.4 257.7 232.5 250.8L13.93 149.8C5.438 145.8 0 137.3 0 127.1C0 118.6 5.437 110.1 13.93 106.2L232.5 5.171zM498.1 234.2C506.6 238.1 512 246.6 512 255.1C512 265.3 506.6 273.8 498.1 277.8L279.5 378.8C264.6 385.7 247.4 385.7 232.5 378.8L13.93 277.8C5.438 273.8 0 265.3 0 255.1C0 246.6 5.437 238.1 13.93 234.2L67.13 209.6L219.1 279.8C242.5 290.7 269.5 290.7 292.9 279.8L444.9 209.6L498.1 234.2zM292.9 407.8L444.9 337.6L498.1 362.2C506.6 366.1 512 374.6 512 383.1C512 393.3 506.6 401.8 498.1 405.8L279.5 506.8C264.6 513.7 247.4 513.7 232.5 506.8L13.93 405.8C5.438 401.8 0 393.3 0 383.1C0 374.6 5.437 366.1 13.93 362.2L67.13 337.6L219.1 407.8C242.5 418.7 269.5 418.7 292.9 407.8V407.8z" />
                </svg>
                <strong><a href="../pipelines/index.html">Pipelines</a></strong>
        </p>
        <p style="color: #c9d1d9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="width: 1em; height: 1em;">
                        <path style="fill: #c9d1d9"
                                d="M232.5 5.171C247.4-1.718 264.6-1.718 279.5 5.171L498.1 106.2C506.6 110.1 512 118.6 512 127.1C512 137.3 506.6 145.8 498.1 149.8L279.5 250.8C264.6 257.7 247.4 257.7 232.5 250.8L13.93 149.8C5.438 145.8 0 137.3 0 127.1C0 118.6 5.437 110.1 13.93 106.2L232.5 5.171zM498.1 234.2C506.6 238.1 512 246.6 512 255.1C512 265.3 506.6 273.8 498.1 277.8L279.5 378.8C264.6 385.7 247.4 385.7 232.5 378.8L13.93 277.8C5.438 273.8 0 265.3 0 255.1C0 246.6 5.437 238.1 13.93 234.2L67.13 209.6L219.1 279.8C242.5 290.7 269.5 290.7 292.9 279.8L444.9 209.6L498.1 234.2zM292.9 407.8L444.9 337.6L498.1 362.2C506.6 366.1 512 374.6 512 383.1C512 393.3 506.6 401.8 498.1 405.8L279.5 506.8C264.6 513.7 247.4 513.7 232.5 506.8L13.93 405.8C5.438 401.8 0 393.3 0 383.1C0 374.6 5.437 366.1 13.93 362.2L67.13 337.6L219.1 407.8C242.5 418.7 269.5 418.7 292.9 407.8V407.8z" />
                </svg>
                <strong><a href="../qg/index.html">Question Generation</a></strong>
        </p>
        <p style="color: #c9d1d9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="width: 1em; height: 1em;">
                        <path style="fill: #c9d1d9"
                                d="M232.5 5.171C247.4-1.718 264.6-1.718 279.5 5.171L498.1 106.2C506.6 110.1 512 118.6 512 127.1C512 137.3 506.6 145.8 498.1 149.8L279.5 250.8C264.6 257.7 247.4 257.7 232.5 250.8L13.93 149.8C5.438 145.8 0 137.3 0 127.1C0 118.6 5.437 110.1 13.93 106.2L232.5 5.171zM498.1 234.2C506.6 238.1 512 246.6 512 255.1C512 265.3 506.6 273.8 498.1 277.8L279.5 378.8C264.6 385.7 247.4 385.7 232.5 378.8L13.93 277.8C5.438 273.8 0 265.3 0 255.1C0 246.6 5.437 238.1 13.93 234.2L67.13 209.6L219.1 279.8C242.5 290.7 269.5 290.7 292.9 279.8L444.9 209.6L498.1 234.2zM292.9 407.8L444.9 337.6L498.1 362.2C506.6 366.1 512 374.6 512 383.1C512 393.3 506.6 401.8 498.1 405.8L279.5 506.8C264.6 513.7 247.4 513.7 232.5 506.8L13.93 405.8C5.438 401.8 0 393.3 0 383.1C0 374.6 5.437 366.1 13.93 362.2L67.13 337.6L219.1 407.8C242.5 418.7 269.5 418.7 292.9 407.8V407.8z" />
                </svg>
                <strong><a href="../tableqa/index.html">Table QA</a></strong>
        </p>
        <p style="color: #c9d1d9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" style="width: 1em; height: 1em;">
                        <path style="fill: #c9d1d9"
                                d="M232.5 5.171C247.4-1.718 264.6-1.718 279.5 5.171L498.1 106.2C506.6 110.1 512 118.6 512 127.1C512 137.3 506.6 145.8 498.1 149.8L279.5 250.8C264.6 257.7 247.4 257.7 232.5 250.8L13.93 149.8C5.438 145.8 0 137.3 0 127.1C0 118.6 5.437 110.1 13.93 106.2L232.5 5.171zM498.1 234.2C506.6 238.1 512 246.6 512 255.1C512 265.3 506.6 273.8 498.1 277.8L279.5 378.8C264.6 385.7 247.4 385.7 232.5 378.8L13.93 277.8C5.438 273.8 0 265.3 0 255.1C0 246.6 5.437 238.1 13.93 234.2L67.13 209.6L219.1 279.8C242.5 290.7 269.5 290.7 292.9 279.8L444.9 209.6L498.1 234.2zM292.9 407.8L444.9 337.6L498.1 362.2C506.6 366.1 512 374.6 512 383.1C512 393.3 506.6 401.8 498.1 405.8L279.5 506.8C264.6 513.7 247.4 513.7 232.5 506.8L13.93 405.8C5.438 401.8 0 393.3 0 383.1C0 374.6 5.437 366.1 13.93 362.2L67.13 337.6L219.1 407.8C242.5 418.7 269.5 418.7 292.9 407.8V407.8z" />
                </svg>
                <strong><a href="../util/index.html">Util</a></strong>
        </p>
</div>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      <div class="custom-right-section" style="padding: 2rem 0 0 0">
        <button onclick="window.open('https://github.com/primeqa/primeqa/discussions','_blank')" class="bootstrap-btn">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" style="width: 1em; height: 1em;">
                        <!-- Font Awesome Pro 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) -->
                        <path style="fill: #459db9"
                                d="M96 224c35.3 0 64-28.7 64-64s-28.7-64-64-64-64 28.7-64 64 28.7 64 64 64zm448 0c35.3 0 64-28.7 64-64s-28.7-64-64-64-64 28.7-64 64 28.7 64 64 64zm32 32h-64c-17.6 0-33.5 7.1-45.1 18.6 40.3 22.1 68.9 62 75.1 109.4h66c17.7 0 32-14.3 32-32v-32c0-35.3-28.7-64-64-64zm-256 0c61.9 0 112-50.1 112-112S381.9 32 320 32 208 82.1 208 144s50.1 112 112 112zm76.8 32h-8.3c-20.8 10-43.9 16-68.5 16s-47.6-6-68.5-16h-8.3C179.6 288 128 339.6 128 403.2V432c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48v-28.8c0-63.6-51.6-115.2-115.2-115.2zm-223.7-13.4C161.5 263.1 145.6 256 128 256H64c-35.3 0-64 28.7-64 64v32c0 17.7 14.3 32 32 32h65.9c6.3-47.4 34.9-87.3 75.2-109.4z" />
                </svg>&nbsp;Start a Discussion!</button>
        <button onclick="showSource()" class="bootstrap-btn"><svg xmlns="http://www.w3.org/2000/svg"
                        viewBox="0 0 640 512" style="width: 1em; height: 1em;">
                        <!--! Font Awesome Pro 6.1.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc. -->
                        <path style="fill: #459db9"
                                d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z" />
                </svg>&nbsp;Show Source</button>
        <button onclick="hRefGitHub()" class="bootstrap-btn"><svg xmlns="http://www.w3.org/2000/svg"
                        viewBox="0 0 576 512" style="width: 1em; height: 1em;">
                        <path style="fill: #459db9"
                                d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1 0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7 0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174L402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7l-43.2-43.2c-4.1-4.1-10.8-4.1-14.8 0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z" />
                </svg>&nbsp;Edit on GitHub</button>
        <!-- <p style="color: #459db9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" style="width: 1em; height: 1em;">
                        <path style="fill: #459db9"
                                d="M96 224c35.3 0 64-28.7 64-64s-28.7-64-64-64-64 28.7-64 64 28.7 64 64 64zm448 0c35.3 0 64-28.7 64-64s-28.7-64-64-64-64 28.7-64 64 28.7 64 64 64zm32 32h-64c-17.6 0-33.5 7.1-45.1 18.6 40.3 22.1 68.9 62 75.1 109.4h66c17.7 0 32-14.3 32-32v-32c0-35.3-28.7-64-64-64zm-256 0c61.9 0 112-50.1 112-112S381.9 32 320 32 208 82.1 208 144s50.1 112 112 112zm76.8 32h-8.3c-20.8 10-43.9 16-68.5 16s-47.6-6-68.5-16h-8.3C179.6 288 128 339.6 128 403.2V432c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48v-28.8c0-63.6-51.6-115.2-115.2-115.2zm-223.7-13.4C161.5 263.1 145.6 256 128 256H64c-35.3 0-64 28.7-64 64v32c0 17.7 14.3 32 32 32h65.9c6.3-47.4 34.9-87.3 75.2-109.4z" />
                </svg>&nbsp;<span id="visits"></span>
        </p> -->
        <img src="_static/img/PrimeQA.png" alt="primeqa" width="100"
                style="display: block;margin-left: auto;margin-right: auto;" />
</div>

<script>
        function showSource() {
                window.open("../../_sources/api/mrc/index.md.txt", '_blank');
        }

        function hRefGitHub() {
                window.open('https://github.com/primeqa/primeqa/edit/main/primeqa/mrc/README.md', '_blank');
        }
        // function callbackCounter(response) {
        //         document.getElementById('visits').innerText = response.value;
        // }
</script>
    </div>
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inference-example-usage">
   Inference Example Usage
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-and-evaluate">
   Train and Evaluate
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#supported-datasets">
     Supported Datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example-usage">
     Example Usage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tydiqa">
       TyDiQA
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#squad">
       SQuAD
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#xquad">
       XQuAD
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mlqa">
       MLQA
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#natural-questions">
       Natural Questions
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mrqa">
       MRQA
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#custom-data">
     Custom Data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-with-multiple-datasets">
     Training with Multiple Datasets
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#special-mrc-features">
   Special MRC Features:
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#boolean-questions">
     Boolean Questions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confidence-calibration">
     Confidence Calibration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#list-answers">
     List Answers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#table-qa">
     Table QA
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <!-- START sphinx doc instructions - DO NOT MODIFY next code, please -->
<details>
<summary>API Reference</summary>    
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="_autosummary/primeqa.mrc.html#module-primeqa.mrc" title="primeqa.mrc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">primeqa.mrc</span></code></a></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</details>          
<br>
<!-- END sphinx doc instructions - DO NOT MODIFY above code, please --> 
<section id="machine-reading-comprehension-mrc">
<h1>Machine Reading Comprehension (MRC)<a class="headerlink" href="#machine-reading-comprehension-mrc" title="Permalink to this headline">#</a></h1>
<p>Before continuing below make sure you have PrimeQA <a class="reference external" href="https://primeqa.github.io/primeqa/installation.html">installed</a>.</p>
<section id="inference-example-usage">
<h2>Inference Example Usage<a class="headerlink" href="#inference-example-usage" title="Permalink to this headline">#</a></h2>
<p>The following shows how to use the MRC component within PrimeQA to extract an answer given a question and a context:</p>
<ul class="simple">
<li><p>Step 1:  Initialize the reader. You can choose any of the MRC models we currently have <a class="reference external" href="https://huggingface.co/PrimeQA">here</a>.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">primeqa.components.reader.extractive</span> <span class="kn">import</span> <span class="n">ExtractiveReader</span>
<span class="n">reader</span> <span class="o">=</span> <span class="n">ExtractiveReader</span><span class="p">(</span><span class="s2">&quot;PrimeQA/nq_tydi_sq1-reader-xlmr_large-20221110&quot;</span><span class="p">)</span>
<span class="n">reader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Step 2: Execute the reader in inference mode:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">question</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Which country is Canberra located in?&quot;</span><span class="p">]</span>
<span class="n">context</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;&quot;&quot;Canberra is the capital city of Australia. </span>
<span class="s2">Founded following the federation of the colonies of Australia </span>
<span class="s2">as the seat of government for the new nation, it is Australia&#39;s </span>
<span class="s2">largest inland city&quot;&quot;&quot;</span><span class="p">]]</span>
<span class="n">answers</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">question</span><span class="p">,</span><span class="n">context</span><span class="p">)</span>  
<span class="nb">print</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>  
</pre></div>
</div>
<p>The above statements will generate an output in the form of a dictionary:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;0&quot;</span>:<span class="w"> </span><span class="o">[</span>
<span class="w">        </span><span class="o">{</span>
<span class="w">            </span><span class="s2">&quot;example_id&quot;</span>:<span class="w"> </span><span class="s2">&quot;0&quot;</span>,
<span class="w">            </span><span class="s2">&quot;passage_index&quot;</span>:<span class="w"> </span><span class="m">0</span>,
<span class="w">            </span><span class="s2">&quot;span_answer_text&quot;</span>:<span class="w"> </span><span class="s2">&quot;Australia&quot;</span>,
<span class="w">            </span><span class="s2">&quot;span_answer&quot;</span>:<span class="w"> </span><span class="o">{</span>
<span class="w">                </span><span class="s2">&quot;start_position&quot;</span>:<span class="w"> </span><span class="m">32</span>,
<span class="w">                </span><span class="s2">&quot;end_position&quot;</span>:<span class="w"> </span><span class="m">41</span>
<span class="w">            </span><span class="o">}</span>,
<span class="w">            </span><span class="s2">&quot;span_answer_score&quot;</span>:<span class="w"> </span><span class="m">14</span>.109326839447021,
<span class="w">            </span><span class="s2">&quot;confidence_score&quot;</span>:<span class="w"> </span><span class="m">0</span>.6732346778531001
<span class="w">        </span><span class="o">}</span>,
<span class="w">        </span><span class="o">{</span>
<span class="w">            </span><span class="s2">&quot;example_id&quot;</span>:<span class="w"> </span><span class="s2">&quot;0&quot;</span>,
<span class="w">            </span><span class="s2">&quot;passage_index&quot;</span>:<span class="w"> </span><span class="m">0</span>,
<span class="w">            </span><span class="s2">&quot;span_answer_text&quot;</span>:<span class="w"> </span><span class="s2">&quot;Australia. \nFounded following the federation of the colonies of Australia&quot;</span>,
<span class="w">            </span><span class="s2">&quot;span_answer&quot;</span>:<span class="w"> </span><span class="o">{</span>
<span class="w">                </span><span class="s2">&quot;start_position&quot;</span>:<span class="w"> </span><span class="m">32</span>,
<span class="w">                </span><span class="s2">&quot;end_position&quot;</span>:<span class="w"> </span><span class="m">105</span>
<span class="w">            </span><span class="o">}</span>,
<span class="w">            </span><span class="s2">&quot;span_answer_score&quot;</span>:<span class="w"> </span><span class="m">12</span>.882871329784393,
<span class="w">            </span><span class="s2">&quot;confidence_score&quot;</span>:<span class="w"> </span><span class="m">0</span>.1974802270822016
<span class="w">        </span><span class="o">}</span>,
<span class="w">        </span><span class="o">{</span>
<span class="w">            </span><span class="s2">&quot;example_id&quot;</span>:<span class="w"> </span><span class="s2">&quot;0&quot;</span>,
<span class="w">            </span><span class="s2">&quot;passage_index&quot;</span>:<span class="w"> </span><span class="m">0</span>,
<span class="w">            </span><span class="s2">&quot;span_answer_text&quot;</span>:<span class="w"> </span><span class="s2">&quot;Australia. \nFounded following the federation of the colonies of Australia \nas the seat of government for the new nation, it is Australia&quot;</span>,
<span class="w">            </span><span class="s2">&quot;span_answer&quot;</span>:<span class="w"> </span><span class="o">{</span>
<span class="w">                </span><span class="s2">&quot;start_position&quot;</span>:<span class="w"> </span><span class="m">32</span>,
<span class="w">                </span><span class="s2">&quot;end_position&quot;</span>:<span class="w"> </span><span class="m">168</span>
<span class="w">            </span><span class="o">}</span>,
<span class="w">            </span><span class="s2">&quot;span_answer_score&quot;</span>:<span class="w"> </span><span class="m">12</span>.459252871572971,
<span class="w">            </span><span class="s2">&quot;confidence_score&quot;</span>:<span class="w"> </span><span class="m">0</span>.12928509506469837
<span class="w">        </span><span class="o">}</span>
<span class="w">    </span><span class="o">]</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Additional inference examples can be found in the python <span class="xref myst">notebook</span>.</p>
</section>
<section id="train-and-evaluate">
<h2>Train and Evaluate<a class="headerlink" href="#train-and-evaluate" title="Permalink to this headline">#</a></h2>
<p>If you want to perform a fully functional train and inference procedure for the MRC components, then the primary script to use is <a class="reference external" href="https://github.com/primeqa/primeqa/blob/main/primeqa/mrc/run_mrc.py">run_mrc.py</a>.  This runs a transformer-based MRC pipeline.</p>
<section id="supported-datasets">
<h3>Supported Datasets<a class="headerlink" href="#supported-datasets" title="Permalink to this headline">#</a></h3>
<p>Currently supported MRC datasets include:</p>
<ul class="simple">
<li><p>TyDiQA</p></li>
<li><p>SQuAD 1.1</p></li>
<li><p>XQuAD</p></li>
<li><p>MLQA</p></li>
<li><p>Natural Questions(NQ)</p></li>
<li><p>Custom Data</p></li>
<li><p>MRQA</p></li>
</ul>
<p>Currently supported TableQA datasets :</p>
<ul class="simple">
<li><p>WikiSQL</p></li>
<li><p>SQA</p></li>
</ul>
<p>User’s can also provide their own <span class="xref myst">custom data</span></p>
</section>
<section id="example-usage">
<h3>Example Usage<a class="headerlink" href="#example-usage" title="Permalink to this headline">#</a></h3>
<section id="tydiqa">
<h4><a class="reference external" href="https://ai.google.com/research/tydiqa">TyDiQA</a><a class="headerlink" href="#tydiqa" title="Permalink to this headline">#</a></h4>
<p>An example usage for train + eval command on the TyDiQA dataset (default) is:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>primeqa/mrc/run_mrc.py<span class="w"> </span>--model_name_or_path<span class="w"> </span>xlm-roberta-large<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--output_dir<span class="w"> </span><span class="si">${</span><span class="nv">OUTPUT_DIR</span><span class="si">}</span><span class="w"> </span>--fp16<span class="w"> </span>--learning_rate<span class="w"> </span>4e-5<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--do_train<span class="w"> </span>--do_eval<span class="w"> </span>--per_device_train_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">128</span><span class="w"> </span>--gradient_accumulation_steps<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span>--weight_decay<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span>--save_steps<span class="w"> </span><span class="m">50000</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--overwrite_output_dir<span class="w"> </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span>
<span class="w">       </span>--evaluation_strategy<span class="w"> </span>no<span class="w"> </span>--overwrite_cache
</pre></div>
</div>
<p>This will detect a GPU if present as well as multiple CPU cores for accelerating preprocessing.
Some hyperparameters (e.g. fp16, batch size, gradient accumulation steps) may need to be changed
depending on your hardware configuration.</p>
<p>The trained model is available <a class="reference external" href="https://huggingface.co/ibm/tydiqa-primary-task-xlm-roberta-large">here</a>.</p>
<p>This yields the following results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">*****</span> <span class="nb">eval</span> <span class="n">metrics</span> <span class="o">*****</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">eval_avg_minimal_f1</span> <span class="o">=</span> <span class="mf">0.6745</span>
<span class="n">eval_avg_minimal_precision</span> <span class="o">=</span> <span class="mf">0.7331</span>
<span class="n">eval_avg_minimal_recall</span> <span class="o">=</span> <span class="mf">0.628</span>
<span class="n">eval_avg_passage_f1</span> <span class="o">=</span> <span class="mf">0.7215</span>
<span class="n">eval_avg_passage_precision</span> <span class="o">=</span> <span class="mf">0.7403</span>
<span class="n">eval_avg_passage_recall</span> <span class="o">=</span> <span class="mf">0.7061</span>
<span class="n">eval_samples</span> <span class="o">=</span> <span class="mi">18670</span>
</pre></div>
</div>
<p>For just training:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>primeqa/mrc/run_mrc.py<span class="w"> </span>--model_name_or_path<span class="w"> </span>xlm-roberta-large<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--output_dir<span class="w"> </span><span class="si">${</span><span class="nv">TRAINING_OUTPUT_DIR</span><span class="si">}</span><span class="w"> </span>--fp16<span class="w"> </span>--learning_rate<span class="w"> </span>4e-5<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--do_train<span class="w"> </span>--per_device_train_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span>--gradient_accumulation_steps<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span>--weight_decay<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span>--save_steps<span class="w"> </span><span class="m">50000</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--overwrite_output_dir<span class="w"> </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span>
<span class="w">       </span>--evaluation_strategy<span class="w"> </span>no<span class="w"> </span>--overwrite_cache
</pre></div>
</div>
<p>For just eval:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>primeqa/mrc/run_mrc.py<span class="w"> </span>--model_name_or_path<span class="w"> </span><span class="si">${</span><span class="nv">TRAINING_OUTPUT_DIR</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--output_dir<span class="w"> </span><span class="si">${</span><span class="nv">OUTPUT_DIR</span><span class="si">}</span><span class="w"> </span>--fp16<span class="w"> </span>--do_eval<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">128</span><span class="w"> </span>--overwrite_output_dir<span class="w"> </span>--overwrite_cache
</pre></div>
</div>
</section>
<section id="squad">
<h4><a class="reference external" href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a><a class="headerlink" href="#squad" title="Permalink to this headline">#</a></h4>
<p>For the SQUAD 1.1 dataset from Huggingface use the folowing additional command line arguments for train + eval :</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="w">       </span>--dataset_name<span class="w"> </span>squad<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--dataset_config_name<span class="w"> </span>plain_text<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--preprocessor<span class="w"> </span>primeqa.mrc.processors.preprocessors.squad.SQUADPreprocessor<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--postprocessor<span class="w"> </span>primeqa.mrc.processors.postprocessors.squad.SQUADPostProcessor<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--eval_metrics<span class="w"> </span>SQUAD<span class="w"> </span>
</pre></div>
</div>
<p>For the SQUAD 1.1 dataset in the original Stanford format, first download the train and dev files from here:</p>
<ul class="simple">
<li><p>https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json</p></li>
<li><p>https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json</p></li>
</ul>
<p>Use the following additional command line arguments for train and eval:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>       <span class="o">--</span><span class="n">train_file</span> <span class="o">&lt;</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">train</span><span class="o">-</span><span class="n">v1</span><span class="mf">.1</span><span class="o">.</span><span class="n">json</span><span class="o">&gt;</span> \
       <span class="o">--</span><span class="n">eval_file</span> <span class="o">&lt;</span><span class="n">path</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">dev</span><span class="o">-</span><span class="n">v1</span><span class="mf">.1</span><span class="o">.</span><span class="n">json</span><span class="o">&gt;</span> \
       <span class="o">--</span><span class="n">preprocessor</span> <span class="n">primeqa</span><span class="o">.</span><span class="n">mrc</span><span class="o">.</span><span class="n">processors</span><span class="o">.</span><span class="n">preprocessors</span><span class="o">.</span><span class="n">squad</span><span class="o">.</span><span class="n">SQUADPreprocessor</span> \
       <span class="o">--</span><span class="n">postprocessor</span> <span class="n">primeqa</span><span class="o">.</span><span class="n">mrc</span><span class="o">.</span><span class="n">processors</span><span class="o">.</span><span class="n">postprocessors</span><span class="o">.</span><span class="n">squad</span><span class="o">.</span><span class="n">SQUADPostProcessor</span> \
       <span class="o">--</span><span class="n">eval_metrics</span> <span class="n">SQUAD</span> 
</pre></div>
</div>
<p>This yields the following results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">*****</span> <span class="nb">eval</span> <span class="n">metrics</span> <span class="o">*****</span> 
<span class="n">eval_exact_match</span> <span class="o">=</span> <span class="mf">88.7133</span>
<span class="n">eval_f1</span>          <span class="o">=</span> <span class="mf">94.3525</span>
</pre></div>
</div>
</section>
<section id="xquad">
<h4><a class="reference external" href="https://arxiv.org/pdf/1910.11856v3.pdf">XQuAD</a><a class="headerlink" href="#xquad" title="Permalink to this headline">#</a></h4>
<p>For the XQuAD dataset run the evaluation script after the model has been trained on SQuAD 1.1.
The dataset configurations for all languages are supported.
For the XQuAD in ZH use the following command line arguments for eval:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="w">       </span>--dataset_name<span class="w"> </span>xquad<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--dataset_config_name<span class="w"> </span>xquad.zh<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--preprocessor<span class="w"> </span>primeqa.mrc.processors.preprocessors.squad.SQUADPreprocessor<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--postprocessor<span class="w"> </span>primeqa.mrc.processors.postprocessors.squad.SQUADPostProcessor<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--eval_metrics<span class="w"> </span>SQUAD<span class="w"> </span>
</pre></div>
</div>
<p>This yields the following results:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>en</p></th>
<th class="head"><p>es</p></th>
<th class="head"><p>de</p></th>
<th class="head"><p>el</p></th>
<th class="head"><p>ru</p></th>
<th class="head"><p>tr</p></th>
<th class="head"><p>ar</p></th>
<th class="head"><p>vi</p></th>
<th class="head"><p>th</p></th>
<th class="head"><p>zh</p></th>
<th class="head"><p>hi</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>F1</p></td>
<td><p>87.5</p></td>
<td><p>82.1</p></td>
<td><p>80.7</p></td>
<td><p>81.5</p></td>
<td><p>80.0</p></td>
<td><p>75.0</p></td>
<td><p>75.1</p></td>
<td><p>80.0</p></td>
<td><p>75.3</p></td>
<td><p>70.3</p></td>
<td><p>77.2</p></td>
</tr>
<tr class="row-odd"><td><p>EM</p></td>
<td><p>76.7</p></td>
<td><p>63.4</p></td>
<td><p>65.4</p></td>
<td><p>64.2</p></td>
<td><p>63.6</p></td>
<td><p>59.3</p></td>
<td><p>59.1</p></td>
<td><p>61.3</p></td>
<td><p>65.5</p></td>
<td><p>62.2</p></td>
<td><p>61.8</p></td>
</tr>
</tbody>
</table>
</section>
<section id="mlqa">
<h4><a class="reference external" href="https://github.com/facebookresearch/MLQA">MLQA</a><a class="headerlink" href="#mlqa" title="Permalink to this headline">#</a></h4>
<p>For the MLQA dataset run the evaluation script after the model has been trained on SQuAD 1.1.
The dataset configurations for all language combinations are supported.
For the MLQA configuration with context language EN and question language DE use the following command line arguments for eval:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="w">       </span>--dataset_name<span class="w"> </span>mlqa<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--dataset_config_name<span class="w"> </span>mlqa.en.de<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--preprocessor<span class="w"> </span>primeqa.mrc.processors.preprocessors.squad.SQUADPreprocessor<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--postprocessor<span class="w"> </span>primeqa.mrc.processors.postprocessors.squad.SQUADPostProcessor<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--eval_metrics<span class="w"> </span>MLQA<span class="w"> </span>
</pre></div>
</div>
<p>This yields the following results:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>en</p></th>
<th class="head"><p>es</p></th>
<th class="head"><p>de</p></th>
<th class="head"><p>ar</p></th>
<th class="head"><p>hi</p></th>
<th class="head"><p>vi</p></th>
<th class="head"><p>zh</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>F1</p></td>
<td><p>84.8</p></td>
<td><p>75.9</p></td>
<td><p>68.8</p></td>
<td><p>67.7</p></td>
<td><p>72.1</p></td>
<td><p>71.8</p></td>
<td><p>69.8</p></td>
</tr>
<tr class="row-odd"><td><p>EM</p></td>
<td><p>72.9</p></td>
<td><p>57.2</p></td>
<td><p>52.7</p></td>
<td><p>46.6</p></td>
<td><p>55.6</p></td>
<td><p>52.1</p></td>
<td><p>50.0</p></td>
</tr>
</tbody>
</table>
</section>
<section id="natural-questions">
<h4><a class="reference external" href="https://ai.google.com/research/NaturalQuestions">Natural Questions</a><a class="headerlink" href="#natural-questions" title="Permalink to this headline">#</a></h4>
<p>For the NQ dataset use the following additional command line arguments for train + eval :</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="w">       </span>--dataset_name<span class="w"> </span>natural_questions<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--dataset_config_name<span class="w"> </span>default<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--postprocessor<span class="w"> </span>primeqa.mrc.processors.postprocessors.natural_questions.NaturalQuestionsPostProcessor<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--preprocessor<span class="w"> </span>primeqa.mrc.processors.preprocessors.natural_questions.NaturalQuestionsPreProcessor<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--beam_runner<span class="w"> </span>DirectRunner<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--learning_rate<span class="w"> </span>3e-5<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--eval_metrics<span class="w"> </span>NQF1
</pre></div>
</div>
<p>This yields the following results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">LONG</span> <span class="n">ANSWER</span> <span class="n">R</span><span class="nd">@P</span> <span class="n">TABLE</span><span class="p">:</span>
<span class="n">Optimal</span> <span class="n">threshold</span><span class="p">:</span> <span class="mf">4.0808</span>
<span class="n">F1</span> <span class="o">/</span> <span class="n">P</span> <span class="o">/</span> <span class="n">R</span>
<span class="mf">65.09</span><span class="o">%</span> <span class="o">/</span> <span class="mf">64.54</span><span class="o">%</span> <span class="o">/</span> <span class="mf">65.65</span><span class="o">%</span>
<span class="n">R</span><span class="nd">@P</span><span class="o">=</span><span class="mf">0.5</span><span class="p">:</span> <span class="mf">77.76</span><span class="o">%</span> <span class="p">(</span><span class="n">actual</span> <span class="n">p</span><span class="o">=</span><span class="mf">50.12</span><span class="o">%</span><span class="p">,</span> <span class="n">score</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">1.979</span><span class="p">)</span>
<span class="n">R</span><span class="nd">@P</span><span class="o">=</span><span class="mf">0.75</span><span class="p">:</span> <span class="mf">41.85</span><span class="o">%</span> <span class="p">(</span><span class="n">actual</span> <span class="n">p</span><span class="o">=</span><span class="mf">75.01</span><span class="o">%</span><span class="p">,</span> <span class="n">score</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">5.523</span><span class="p">)</span>
<span class="n">R</span><span class="nd">@P</span><span class="o">=</span><span class="mf">0.9</span><span class="p">:</span> <span class="mf">4.20</span><span class="o">%</span> <span class="p">(</span><span class="n">actual</span> <span class="n">p</span><span class="o">=</span><span class="mf">90.32</span><span class="o">%</span><span class="p">,</span> <span class="n">score</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">8.189</span><span class="p">)</span>

<span class="n">SHORT</span> <span class="n">ANSWER</span> <span class="n">R</span><span class="nd">@P</span> <span class="n">TABLE</span><span class="p">:</span>
<span class="n">Optimal</span> <span class="n">threshold</span><span class="p">:</span> <span class="mf">4.0822</span>
<span class="n">F1</span> <span class="o">/</span> <span class="n">P</span> <span class="o">/</span> <span class="n">R</span>
<span class="mf">56.76</span><span class="o">%</span> <span class="o">/</span> <span class="mf">57.24</span><span class="o">%</span> <span class="o">/</span> <span class="mf">56.28</span><span class="o">%</span>
<span class="n">R</span><span class="nd">@P</span><span class="o">=</span><span class="mf">0.5</span><span class="p">:</span> <span class="mf">61.23</span><span class="o">%</span> <span class="p">(</span><span class="n">actual</span> <span class="n">p</span><span class="o">=</span><span class="mf">50.01</span><span class="o">%</span><span class="p">,</span> <span class="n">score</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">3.235</span><span class="p">)</span>
<span class="n">R</span><span class="nd">@P</span><span class="o">=</span><span class="mf">0.75</span><span class="p">:</span> <span class="mf">29.25</span><span class="o">%</span> <span class="p">(</span><span class="n">actual</span> <span class="n">p</span><span class="o">=</span><span class="mf">75.11</span><span class="o">%</span><span class="p">,</span> <span class="n">score</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">6.031</span><span class="p">)</span>
<span class="n">R</span><span class="nd">@P</span><span class="o">=</span><span class="mf">0.9</span><span class="p">:</span> <span class="mf">10.16</span><span class="o">%</span> <span class="p">(</span><span class="n">actual</span> <span class="n">p</span><span class="o">=</span><span class="mf">90.00</span><span class="o">%</span><span class="p">,</span> <span class="n">score</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">7.425</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="mrqa">
<h4><a class="reference external" href="https://huggingface.co/datasets/mrqa">MRQA</a><a class="headerlink" href="#mrqa" title="Permalink to this headline">#</a></h4>
<p>The dataset is a collection of 18 existing QA dataset (carefully selected subset of them) and converted to the same format (SQuAD like format)</p>
<p>For the MRQA dataset use the following additional command line arguments:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="w">      </span>--dataset_name<span class="w"> </span>mrqa<span class="w"> </span><span class="se">\</span>
<span class="w">      </span>--dataset_config_name<span class="w"> </span>plain_text<span class="w"> </span><span class="se">\</span>
<span class="w">      </span>--preprocessor<span class="w"> </span>primeqa.mrc.processors.preprocessors.mrqa.MRQAPreprocessor<span class="w"> </span><span class="se">\</span>
<span class="w">      </span>--postprocessor<span class="w"> </span>primeqa.mrc.processors.postprocessors.squad.SQUADPostProcessor<span class="w"> </span><span class="se">\</span>
<span class="w">      </span>--eval_metrics<span class="w"> </span>SQUAD<span class="w"> </span>
</pre></div>
</div>
<p>Additionally, to specify a MRQA subset e.g. <code class="docutils literal notranslate"><span class="pre">SQuAD</span></code>, <code class="docutils literal notranslate"><span class="pre">NaturalQuestionsShort</span></code>, <code class="docutils literal notranslate"><span class="pre">TriviaQA-web</span></code>, use the command line argments  <code class="docutils literal notranslate"><span class="pre">--dataset_filter_column_name</span></code> to specify a column name and <code class="docutils literal notranslate"><span class="pre">--dataset_filter_column_values</span></code> to specify a list of column values.  The example below selects <code class="docutils literal notranslate"><span class="pre">SQuAD</span></code> and <code class="docutils literal notranslate"><span class="pre">HotpotQA</span></code> examples using the column <code class="docutils literal notranslate"><span class="pre">subset</span></code> in the MRQA dataset.  The script <code class="docutils literal notranslate"><span class="pre">run_mrc.py</span></code> shuffles the train examples, eval examples are kept in the same order as read in from the source.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="w">      </span>--dataset_filter_column_values<span class="w"> </span>SQuAD<span class="w"> </span>HotpotQA
<span class="w">      </span>--dataset_filter_column_name<span class="w"> </span>subset
</pre></div>
</div>
<p>Cross domain experiments can be run by running train and eval as separate processes.</p>
</section>
</section>
<section id="custom-data">
<h3>Custom Data<a class="headerlink" href="#custom-data" title="Permalink to this headline">#</a></h3>
<p>Users can also train (fine-tune) and evaluate the MRC model on custom data by providing their own train_file and eval_file. Instructions for getting started are available <span class="xref myst">here</span>.</p>
</section>
<section id="training-with-multiple-datasets">
<h3>Training with Multiple Datasets<a class="headerlink" href="#training-with-multiple-datasets" title="Permalink to this headline">#</a></h3>
<p>PrimeQA supports the training of MRC model with combination of multiple datasets, which are specified in “–train_fof” argument. This argument points to a file of training files (fof). This fof can be in any of three supported formats: csv, jsonl, and json.</p>
<p>In the csv format, each line of train_fof consists of four columns, separated by spaces:</p>
<ul class="simple">
<li><p>HuggingFace dataset name, or path of local data file, or path of dataset processing script (in python);</p></li>
<li><p>Dataset config name or data file format;</p></li>
<li><p>Sampling rate within range 0.0 to 1.0, e.g. 0.5 means 50% of the examples are randomly selected and used in MRC training;</p></li>
<li><p>Preprocessor name.</p></li>
</ul>
<p>If column 2 to 4 are not given, default values from input arguments will be used, i.e.:</p>
<ul class="simple">
<li><p>Value of “–dataset_config_name” for HuggingFace dataset and processing script, or “–data_file_format” for local data file;</p></li>
<li><p>1.0 for sampling rate;</p></li>
<li><p>Value of “–preprocessor” for preprocessor name.</p></li>
</ul>
<p>If in jsonl format, each line is a dictionary consisting of</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;dataset&#39;</span><span class="p">:</span> <span class="n">dataset_name_or_path_of_data_file_or_processing_script</span><span class="p">,</span>
 <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="n">dataset_config_or_data_file_format</span><span class="p">,</span>
 <span class="s1">&#39;sampling_rate&#39;</span><span class="p">:</span> <span class="n">sampling_rate</span><span class="p">,</span>
 <span class="s1">&#39;preprocessor&#39;</span><span class="p">:</span> <span class="n">preprocessor_name</span><span class="p">}</span>
</pre></div>
</div>
<p>Fields ‘config’, ‘sampling_rate’, and ‘preprocessor’ are optional.</p>
<p>If in json format, a list of dictionaries same to that in jsonl is expected.</p>
<p>The following is an example of “–train_fof” in csv format which includes two HuggingFace datatsets: TyDiQA and SQuAD.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tydiqa</span> <span class="n">primary_task</span> <span class="mf">0.1</span> <span class="n">primeqa</span><span class="o">.</span><span class="n">mrc</span><span class="o">.</span><span class="n">processors</span><span class="o">.</span><span class="n">preprocessors</span><span class="o">.</span><span class="n">tydiqa</span><span class="o">.</span><span class="n">TyDiQAPreprocessor</span>
<span class="n">squad</span>  <span class="n">plain_text</span>   <span class="mf">0.1</span> <span class="n">primeqa</span><span class="o">.</span><span class="n">mrc</span><span class="o">.</span><span class="n">processors</span><span class="o">.</span><span class="n">preprocessors</span><span class="o">.</span><span class="n">squad</span><span class="o">.</span><span class="n">SQUADPreprocessor</span>
</pre></div>
</div>
<p>To evaluate the checkpoint models during training, the validation dataset needs be specified in “–eval_fof” which format is same to “–train_fof”. Multiple datatsets can be included into “–eval_fof” if use the trainer ‘MSKD_MRCTrainer’, otherwise a single validation dataset is expected.</p>
<p>Please note that, if “–train_fof” and “–eval_fof” are given in input arguments, other dataset related parameters, i.e. “–dataset_name”, “–train_file”, and “–eval_file” are ignored.</p>
<p>The following additional command lines show how to train MRC model with TyDiQA+SQuAD, and evaluate on TyDiQA.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>primeqa/mrc/run_mrc.py<span class="w"> </span>--model_name_or_path<span class="w"> </span>xlm-roberta-large<span class="w"> </span><span class="se">\</span>
--train_fof<span class="w"> </span><span class="si">${</span><span class="nv">train_fof_including_tydi_squad</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
--eval_fof<span class="w"> </span><span class="si">${</span><span class="nv">eval_fof_including_tydi</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
--postprocessor<span class="w"> </span>primeqa.mrc.processors.postprocessors.extractive.ExtractivePostProcessor<span class="w"> </span><span class="se">\</span>
--eval_metrics<span class="w"> </span>TyDiF1<span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
</section>
</section>
<section id="special-mrc-features">
<h2>Special MRC Features:<a class="headerlink" href="#special-mrc-features" title="Permalink to this headline">#</a></h2>
<p>PrimeQA also supports special features for MRC systems as follows:</p>
<section id="boolean-questions">
<h3>Boolean Questions<a class="headerlink" href="#boolean-questions" title="Permalink to this headline">#</a></h3>
<p>Answering <a class="reference external" href="https://arxiv.org/abs/1905.10044">Boolean Questions</a> for TyDI. Please read the details of <a class="reference external" href="https://primeqa.github.io/primeqa/api/boolqa/index.html">inference</a> or <a class="reference external" href="https://primeqa.github.io/primeqa/extensions/boolqa/index.html">training</a>:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>primeqa/mrc/run_mrc.py<span class="w"> </span>--model_name_or_path<span class="w"> </span>PrimeQA/tydi-reader_bpes-xlmr_large-20221117<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--output_dir<span class="w"> </span><span class="si">${</span><span class="nv">OUTPUT_DIR</span><span class="si">}</span><span class="w"> </span>--fp16<span class="w"> </span>--overwrite_cache<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">128</span><span class="w"> </span>--overwrite_output_dir<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--do_boolean<span class="w"> </span>--boolean_config<span class="w">  </span>extensions/boolqa/tydi_boolqa_config.json
</pre></div>
</div>
<p>The corresponding model files are available as part of these: <a class="reference external" href="https://huggingface.co/PrimeQA/tydiqa-boolean-question-classifier">Question classifier</a>, <a class="reference external" href="https://huggingface.co/PrimeQA/tydiqa-boolean-answer-classifier">Answer classifier</a>, <a class="reference external" href="https://huggingface.co/PrimeQA/tydiqa-primary-task-xlm-roberta-large">MRC system</a>. This setup is based on the top submission to the minimal answer leaderboard (hidden blind test) for TyDI (as of 7/2/2022).</p>
<p>This yields the following results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">*****</span> <span class="nb">eval</span> <span class="n">metrics</span> <span class="o">*****</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">eval_avg_minimal_f1</span> <span class="o">=</span> <span class="mf">0.7151</span>
<span class="n">eval_avg_minimal_precision</span> <span class="o">=</span> <span class="mf">0.7229</span>
<span class="n">eval_avg_minimal_recall</span> <span class="o">=</span> <span class="mf">0.7097</span>
<span class="n">eval_avg_passage_f1</span> <span class="o">=</span> <span class="mf">0.7447</span>
<span class="n">eval_avg_passage_precision</span> <span class="o">=</span> <span class="mf">0.7496</span>
<span class="n">eval_avg_passage_recall</span> <span class="o">=</span> <span class="mf">0.7433</span>
<span class="n">eval_samples</span> <span class="o">=</span> <span class="mi">18670</span>
</pre></div>
</div>
</section>
<section id="confidence-calibration">
<h3>Confidence Calibration<a class="headerlink" href="#confidence-calibration" title="Permalink to this headline">#</a></h3>
<p>To run <a class="reference external" href="https://arxiv.org/abs/2101.07942">confidence calibration</a> on your fine-tuned model during inference use the following additional command line arguments:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="w">       </span>--output_dropout_rate<span class="w"> </span><span class="m">0</span>.25<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--decoding_times_with_dropout<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--confidence_model_path<span class="w"> </span><span class="si">${</span><span class="nv">CONFIDENCE_MODEL_PATH</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--task_heads<span class="w"> </span>primeqa.mrc.models.heads.extractive.EXTRACTIVE_WITH_CONFIDENCE_HEAD
</pre></div>
</div>
</section>
<section id="list-answers">
<h3>List Answers<a class="headerlink" href="#list-answers" title="Permalink to this headline">#</a></h3>
<p>PrimeQA also supports answering questions to which answers are collective e.g. lists.</p>
<p>For Training/Evaluating questions with lists as answers it is important to include the following argument parameters and values. The answer length must be longer and there are less annotations so the non-null threshold must be 1 (There are no null answers). See <a class="reference external" href="https://github.com/primeqa/primeqa/blob/main/extensions/listqa/README.md">extensions/listqa/README.md</a> for more information and a use case using NQ list data:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>       <span class="o">--</span><span class="n">max_seq_length</span> <span class="mi">512</span> \
       <span class="o">--</span><span class="n">learning_rate</span> <span class="mf">5e-05</span> \
       <span class="o">--</span><span class="n">max_answer_length</span> <span class="mi">1000</span> \
       <span class="o">--</span><span class="n">passage_non_null_threshold</span> <span class="mi">1</span> \
       <span class="o">--</span><span class="n">minimal_non_null_threshold</span> <span class="mi">1</span> \
</pre></div>
</div>
<p>This yields the following results on English only using the TyDi evaluation script with two training strategies. Please note the ListQA models use the NQ list data by using the long answers offsets as the short answer. Further details can be found in <code class="docutils literal notranslate"><span class="pre">extensions/listqa/README.md</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xlm</span><span class="o">-</span><span class="n">roberta</span><span class="o">-</span><span class="n">large</span> <span class="o">-&gt;</span> <span class="n">NQ</span> <span class="n">Lists</span><span class="p">:</span> <span class="n">Minimal</span> <span class="n">F1</span> <span class="o">=</span> <span class="mf">47.88</span>
<span class="n">xlm</span><span class="o">-</span><span class="n">roberta</span><span class="o">-</span><span class="n">large</span> <span class="o">-&gt;</span> <span class="n">PrimeQA</span><span class="o">/</span><span class="n">tydiqa</span><span class="o">-</span><span class="n">primary</span><span class="o">-</span><span class="n">task</span><span class="o">-</span><span class="n">xlm</span><span class="o">-</span><span class="n">roberta</span><span class="o">-</span><span class="n">large</span> <span class="o">-&gt;</span> <span class="n">NQ</span> <span class="n">Lists</span><span class="p">:</span> <span class="n">Minimal</span> <span class="n">F1</span> <span class="o">=</span> <span class="mf">58.44</span> 
</pre></div>
</div>
<p>The trained models are available on HuggingFace: <a class="reference external" href="https://huggingface.co/PrimeQA/listqa_nq-task-xlm-roberta-large">xlm-r-&gt;NQ lists</a> and <a class="reference external" href="https://huggingface.co/PrimeQA/tydiqa-ft-listqa_nq-task-xlm-roberta-large">xlm-r-&gt;TyDi-&gt;NQ lists</a>.</p>
</section>
<section id="table-qa">
<h3>Table QA<a class="headerlink" href="#table-qa" title="Permalink to this headline">#</a></h3>
<p>PrimeQA also supports answering questions over tables.</p>
<p>For training and evaluation of a Table Question Answering model on wikisql dataset run the following script:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="w">       </span>python<span class="w"> </span>primeqa/mrc/run_mrc.py<span class="w"> </span>--modality<span class="w"> </span><span class="s2">&quot;table&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--dataset_name<span class="w"> </span><span class="s2">&quot;wikisql&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--tableqa_config_file<span class="w"> </span><span class="s2">&quot;primeqa/tableqa/tableqa_config.json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--output_dir<span class="w"> </span><span class="s2">&quot;models/wikisql/&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--model_name_or_path<span class="w"> </span><span class="s2">&quot;google/tapas-base&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--do_train<span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--do_eval
</pre></div>
</div>
<p>This runs a <a class="reference external" href="https://aclanthology.org/2020.acl-main.398.pdf">TAPAS</a> based tableQA pipeline.</p>
<p>The current performance on wikisql dev set is:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>*****<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>metrics<span class="w"> </span>*****
Eval<span class="w"> </span>denotation<span class="w"> </span>accuracy:<span class="w"> </span><span class="m">86</span>.78%
</pre></div>
</div>
<p>You can also train the tableqa model on your own custom data by proving own train_file and eval_file. Train the TableQA model on custom data using the above script with the following additional parameters:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="w">       </span>--train_file<span class="w"> </span><span class="s2">&quot;&lt;path_to_train.tsv file&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">       </span>--eval_file<span class="w"> </span><span class="s2">&quot;&lt;path_to_eval.tsv file&quot;</span><span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
<p>The format of dataset required for training and evaluation is:</p>
<p><code class="docutils literal notranslate"><span class="pre">Question_id\tquestion\ttable_path\tanswer_coordinates\tanswer_text</span></code></p>
<p>The tables in csv format should be placed under <code class="docutils literal notranslate"><span class="pre">data_path_root/tables/</span></code>. The tables should have first row as column headers.</p>
<p>Our python <a class="reference external" href="https://github.com/primeqa/primeqa/blob/main/notebooks/tableqa/tableqa_inference.ipynb">notebook</a> shows how to test the pre-trained model available <a class="reference external" href="https://huggingface.co/PrimeQA/tapas-based-tableqa-wikisql-lookup">here</a>.</p>
</section>
</section>
</section>


              </article>
              

              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
</div>
</footer>
  </body>
</html>
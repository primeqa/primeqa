{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12570\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from glob import glob \n",
    "files = glob(\"/dccstor/srosent2/generative/appen/round1_jobs/*json.zip\") #[\"job_1999101.json\",\"job_1988758.json\", \"job_2004889.json\",\"job_2006984.json\", \"job_2022794.json\", \"job_2035917.json\"]\n",
    "\n",
    "seen_ids = set()\n",
    "\n",
    "for file_name in files:\n",
    "    # file_name = \"/dccstor/srosent2/generative/appen/round1_jobs/\" + file\n",
    "    data = pd.read_json(file_name, lines=True)\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        info = row['results']['judgments'][0]\n",
    "        # print(row['results'])\n",
    "            \n",
    "        seen_ids.add(info['unit_data']['question_id'])\n",
    "\n",
    "print(len(seen_ids))\n",
    "# print(seen_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tydi json\n",
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "import spacy\n",
    "\n",
    "# spacy.cli.download('en_core_web_sm')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "train_data_dir = \"/dccstor/srosent2/primeqa/data/nq-lfqa-train/*jsonl\"\n",
    "dev_data_dir = \"/dccstor/srosent2/primeqa/data/dev/nq-lfqa/*jsonl\"\n",
    "\n",
    "train_files = glob.glob(train_data_dir)\n",
    "dev_files = glob.glob(dev_data_dir)\n",
    "\n",
    "def load_json_from_file(gt_file_patterns):\n",
    "    data = []\n",
    "    if gt_file_patterns.endswith('gz'):\n",
    "        f = gzip.open(gt_file_patterns, 'rt', encoding='utf-8')\n",
    "    else:\n",
    "        f = open(gt_file_patterns, 'rt', encoding='utf-8')\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        data.append(json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for train_file in train_files:\n",
    "    train_data.extend(load_json_from_file(train_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3393\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seen_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     not_la \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     16\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(example[\u001b[39m'\u001b[39m\u001b[39mexample_id\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39min\u001b[39;00m seen_ids:\n\u001b[1;32m     18\u001b[0m     seen_dev_ids\u001b[39m.\u001b[39madd(example[\u001b[39m'\u001b[39m\u001b[39mexample_id\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m     seen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seen_ids' is not defined"
     ]
    }
   ],
   "source": [
    "dev_data = []\n",
    "for dev_file in dev_files:\n",
    "    dev_data.extend(load_json_from_file(dev_file))\n",
    "\n",
    "print(len(dev_data))\n",
    "\n",
    "seen = 0\n",
    "not_la = 0\n",
    "seen_dev_ids = set()\n",
    "for example in dev_data:\n",
    "    \n",
    "    qtype = example['type'][0]\n",
    "    \n",
    "    if qtype != 'la':\n",
    "        not_la += 1\n",
    "        continue\n",
    "    if str(example['example_id']) in seen_ids:\n",
    "        seen_dev_ids.add(example['example_id'])\n",
    "        seen += 1\n",
    "print(not_la)\n",
    "print(seen)\n",
    "print(len(seen_dev_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/dccstor/srosent2/primeqa/data/nq-lfqa-train/nq-train-tydiformat4.jsonl',\n",
       " '/dccstor/srosent2/primeqa/data/nq-lfqa-train/nq-train-tydiformat2.jsonl',\n",
       " '/dccstor/srosent2/primeqa/data/nq-lfqa-train/nq-train-tydiformat0.jsonl',\n",
       " '/dccstor/srosent2/primeqa/data/nq-lfqa-train/nq-train-tydiformat1.jsonl',\n",
       " '/dccstor/srosent2/primeqa/data/nq-lfqa-train/nq-train-tydiformat.jsonl',\n",
       " '/dccstor/srosent2/primeqa/data/nq-lfqa-train/nq-train-tydiformat3.jsonl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61499"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# part1 == also 2000?\n",
    "# up to 19505 to get part2 (2000 each)\n",
    "# up to 30209 to get part3 (2000 each)\n",
    "# up to 41213 to get part4 (2000 each)\n",
    "# up to 53351 to get part5 (2000 each)\n",
    "# 64067 part6 (2000)\n",
    "# to end part7 64504 (175)\n",
    "\n",
    "def is_majority_type(types, type):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for t in types:\n",
    "        if t == type:\n",
    "            count += 1\n",
    "    if count >= 3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_appen_data(data, type, exclude_ids, output_file, start):\n",
    "    f = open(output_file, 'w', encoding='UTF8', newline='')\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow([\"question_id\",\"question\",\"title\",\"url\",\"long_answer\",\"minimal_text\"])\n",
    "\n",
    "    count = 0\n",
    "    index = start\n",
    "    lines = []\n",
    "    excluded = 0\n",
    "    for example in data[start:]:\n",
    "        index += 1\n",
    "        # if index >= 19505:\n",
    "        #     continue\n",
    "        # qtype = example['type'][0]\n",
    "        \n",
    "        # if qtype != type:\n",
    "        #     continue\n",
    "\n",
    "        if not is_majority_type(example['type'], type):\n",
    "            continue\n",
    "        \n",
    "        example_id = example['example_id']\n",
    "\n",
    "        if str(example_id) in exclude_ids:\n",
    "            excluded += 1\n",
    "            continue\n",
    "\n",
    "        question = example[\"question_text\"]\n",
    "\n",
    "        q_word = question.split()[0]\n",
    "\n",
    "        annotation = example['annotations'][0]\n",
    "\n",
    "        if annotation == None:\n",
    "            continue\n",
    "\n",
    "        minimal_text = \"\"\n",
    "        if annotation['minimal_answer']['plaintext_start_byte'] != -1:\n",
    "            minimal_text = example['document_plaintext'].encode('utf-8')[annotation['minimal_answer']['plaintext_start_byte']:annotation['minimal_answer']['plaintext_end_byte']].decode('utf-8')\n",
    "            continue\n",
    "        passage_offsets = example['passage_answer_candidates'][annotation['passage_answer']['candidate_index']]\n",
    "        passage_text = example['document_plaintext'].encode('utf-8')[passage_offsets['plaintext_start_byte']:passage_offsets['plaintext_end_byte']].decode('utf-8')\n",
    "        \n",
    "        passage_sentences = \"\"\n",
    "        sentences = nlp(passage_text)\n",
    "        \n",
    "        num_sentences = 0\n",
    "        for sentence in sentences.sents:\n",
    "            num_sentences += 1\n",
    "            passage_sentences += sentence.text + \"&nbsp;\"\n",
    "\n",
    "        if num_sentences < 5:\n",
    "            continue\n",
    "\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "            print(index)\n",
    "        if count > 2000:\n",
    "            break\n",
    "\n",
    "        writer.writerow([str(example_id), question, example['document_title'], example['document_url'], passage_sentences, minimal_text])\n",
    "    print(count)\n",
    "    print(excluded)\n",
    "    f.close()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "get_appen_data(train_data, \"la\", seen_ids, \"/dccstor/srosent2/generative/data_for_appen/full_nq_task_nomin_train_more.tsv\", 0)\n",
    "# get_appen_data(dev_data, \"la\", seen_ids, \"/dccstor/srosent2/generative/data_for_appen/full_nq_task_nomin_dev.tsv\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input</th>\n",
       "      <th>passages</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>-860893014778759502</td>\n",
       "      <td>what does the name judas mean in greek</td>\n",
       "      <td>[{'title': 'Judas Iscariot', 'text': 'The name...</td>\n",
       "      <td>[{'answer': 'The name Judas is a Greek renderi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>-3233216490717507766</td>\n",
       "      <td>where did the name carl jr come from</td>\n",
       "      <td>[{'title': 'Carl's Jr.', 'text': 'Carl Karcher...</td>\n",
       "      <td>[{'answer': 'The first two Carl 's Jr. restaur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10126</th>\n",
       "      <td>-7138712513392194276</td>\n",
       "      <td>fetal hematopoiesis occurs in which structure ...</td>\n",
       "      <td>[{'title': 'Haematopoiesis', 'text': 'In some ...</td>\n",
       "      <td>[{'answer': 'During fetal development , since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251</th>\n",
       "      <td>2170813232674301260</td>\n",
       "      <td>when did krakow become the capital of poland</td>\n",
       "      <td>[{'title': 'Kraków', 'text': 'Kraków ( Polish ...</td>\n",
       "      <td>[{'answer': 'Kraków has been the capital of Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>55946526549723721</td>\n",
       "      <td>what era did the woolly mammoth live in</td>\n",
       "      <td>[{'title': 'Woolly mammoth', 'text': 'The wool...</td>\n",
       "      <td>[{'answer': 'The woolly mammoth is an extinct ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "4835    -860893014778759502   \n",
       "1019   -3233216490717507766   \n",
       "10126  -7138712513392194276   \n",
       "6251    2170813232674301260   \n",
       "5299      55946526549723721   \n",
       "\n",
       "                                                   input  \\\n",
       "4835              what does the name judas mean in greek   \n",
       "1019                where did the name carl jr come from   \n",
       "10126  fetal hematopoiesis occurs in which structure ...   \n",
       "6251        when did krakow become the capital of poland   \n",
       "5299             what era did the woolly mammoth live in   \n",
       "\n",
       "                                                passages  \\\n",
       "4835   [{'title': 'Judas Iscariot', 'text': 'The name...   \n",
       "1019   [{'title': 'Carl's Jr.', 'text': 'Carl Karcher...   \n",
       "10126  [{'title': 'Haematopoiesis', 'text': 'In some ...   \n",
       "6251   [{'title': 'Kraków', 'text': 'Kraków ( Polish ...   \n",
       "5299   [{'title': 'Woolly mammoth', 'text': 'The wool...   \n",
       "\n",
       "                                                  output  \n",
       "4835   [{'answer': 'The name Judas is a Greek renderi...  \n",
       "1019   [{'answer': 'The first two Carl 's Jr. restaur...  \n",
       "10126  [{'answer': 'During fetal development , since ...  \n",
       "6251   [{'answer': 'Kraków has been the capital of Le...  \n",
       "5299   [{'answer': 'The woolly mammoth is an extinct ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load final data and split into train and dev\n",
    "import pandas as pd\n",
    "\n",
    "annotated_data = pd.read_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_single-8.28.23.json\", dtype={'id':str}, lines=True)\n",
    "annotated_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3393\n",
      "['-6570496346595660652', '4111902318448915849', '3599421094587589904', '3367999921663366204', '-2103986527722712835']\n"
     ]
    }
   ],
   "source": [
    "dev_ids = []\n",
    "\n",
    "for item in dev_data:\n",
    "    dev_ids.append(str(item['example_id']))\n",
    "\n",
    "print(len(dev_ids))\n",
    "print(dev_ids[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11941\n",
      "303\n",
      "11638\n"
     ]
    }
   ],
   "source": [
    "dev_annotated_data = annotated_data[annotated_data['id'].isin(dev_ids)]\n",
    "train_annotated_data = annotated_data[~annotated_data['id'].isin(dev_ids)]\n",
    "\n",
    "train_annotated_data.to_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_single-8.28.23_train.json\", lines=True, orient='records')\n",
    "dev_annotated_data.to_json(\"/dccstor/srosent2/generative/appen/NQ_formatted_answered_single-8.28.23_dev.json\", lines=True, orient='records')\n",
    "\n",
    "print(len(annotated_data))\n",
    "print(len(dev_annotated_data))\n",
    "print(len(train_annotated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    }
   ],
   "source": [
    "single_annotated_data = annotated_data[annotated_data['id'].isin(dev_ids)]\n",
    "\n",
    "print(len(single_annotated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8045984229282682032',\n",
       " '8116539286638468011',\n",
       " '-3228156810154352180',\n",
       " '3987125231951435424',\n",
       " '4033741599548472305',\n",
       " '1418137193354531640',\n",
       " '3357197785218509494',\n",
       " '-6535437352408475447',\n",
       " '-7004734840398964545',\n",
       " '7704053979528747207',\n",
       " '-6378513022733673487',\n",
       " '-8716739262777106136',\n",
       " '1465521168294687740',\n",
       " '383188332671341621',\n",
       " '-5390270947453055029',\n",
       " '-7811056010021023549',\n",
       " '-7026292704542519105',\n",
       " '26460100276487942',\n",
       " '-2723957341197782107',\n",
       " '-4175092425154624123']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(annotated_data['id'][0:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('primeqaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "229bd894a0cdb05b7ee80ea2bc43559a301775857073a25e64e4f441f37822ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

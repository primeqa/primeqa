{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "764f905e",
   "metadata": {},
   "source": [
    "# Tutorial: Build a search index using DPR #\n",
    "\n",
    "In this tutorial, we will learn how to build a Neural Search index over your document collection. The algorithm displayed here is called Dense Passage Retrieval (DPR) as described in Karpukhin et al., \"Dense Passage Retrieval for Open-Domain Question Answering\" [here](https://arxiv.org/pdf/2004.04906.pdf).\n",
    "\n",
    "For the purposes of making this tutorial easy to understand we show the steps using a very small document collection. Note that this technique can be used to scale to millions of documents. We have tested upto 21 million Wikipedia passages!!!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fca36ec",
   "metadata": {},
   "source": [
    "## Preparing a Colab Environment to run this tutorial ##\n",
    "\n",
    "Make sure to \"Enable GPU Runtime\" -> make a URL with a page with screenshots on how to do this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5e3426d",
   "metadata": {},
   "source": [
    "## Installing PrimeQA\n",
    "\n",
    "First, we need to include the required modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install --upgrade pip\n",
    "pip install primeqa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e289b31",
   "metadata": {},
   "source": [
    "## Pre-process your document collection here to be ready to be stored in your Neural Search Index.\n",
    "\n",
    "TODO- add some steps after this to ingest from the sample wikipedia docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your input document as a .tsv\n",
    "import pandas as pd\n",
    "url='https://drive.google.com/file/d/1LULJRPgN_hfuI2kG-wH4FUwXCCdDh9zh/view?usp=sharing'\n",
    "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "df = pd.read_csv(url)\n",
    "df.to_csv('input.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DocumentCollection class to convert your input.tsv to the specific format needed by PrimeQA indexer/retriever.\n",
    "from primeqa.ir.util.corpus_reader import DocumentCollection\n",
    "doc_class = DocumentCollection(\"input.tsv\")\n",
    "doc_class.write_corpus_tsv(\"output.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c03fd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "198cfd78",
   "metadata": {},
   "source": [
    "## Initializing the Indexer\n",
    "\n",
    "We initialize a ColBERT indexer which will be used for indexing the embeddings created for each document (passage) in the collection. It takes a passage_embedding_model to create the embedding vectors and a vector_db specification where it stores the embedding vectors to search later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeqa.components.indexer.dense import ColBERTIndexer \n",
    "indexer= ColBERTIndexer (doc_encoder_model_checkpoint = \"/dccstor/colbert-ir/bsiyer/PQLL/experiments/xor_squad_04182023/2023-04/22/17.23.31/checkpoints/colbert.dnn.batch_17524.model\", vector_db='FAISS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer.index(\"output.tsv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20b409ad",
   "metadata": {},
   "source": [
    "## Initializing the Retriever\n",
    "\n",
    "We initialize a ColBERT retriever to search documents from the indexed document corpus.  Note: since we will retrieve the documents based on questions so we need to embed the questions too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from primeqa.components.retriever.dense import ColBERTRetriever\n",
    "retriever = ColBERTRetriever(indexer=indexer,\n",
    "                      query_encoder_model_checkpoint = \"/dccstor/colbert-ir/bsiyer/PQLL/experiments/xor_squad_04182023/2023-04/22/17.23.31/checkpoints/colbert.dnn.batch_17524.model\"\n",
    "                       )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab15199a",
   "metadata": {},
   "source": [
    "## Start asking Questions\n",
    "\n",
    "We're now ready to query the index we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = ['What are some famous inventions by Einstein', \"When did Aple introduce iPhone 7\"]\n",
    "retrieved_doc_ids, passages = retriever.predict(input_texts = question, mode = 'query_list',return_passages=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7d3c2d5",
   "metadata": {},
   "source": [
    "Here are the retrived results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(passages, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

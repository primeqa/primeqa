{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "worker ids:\n",
    "46994197,CA,Redondo Beach, Salim, 21\n",
    "47200615,NY,Ossining, Hee Dong, 21, 5\n",
    "46545976,NY,Newburgh, Eva-Maria, 21, 3\n",
    "46092070,NY,New City, Sara, 18, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "name = {46994197:\"Salim\", 47200615:\"Hee Dong\", 46545976: \"Eva-Maria\", 46092070: \"Sara\"}\n",
    "file_name = \"/dccstor/srosent2/generative/appen/job_1988758NQLFQA.json\"\n",
    "data = pd.read_json(file_name, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skip_workers = {}\n",
    "time_workers = {}\n",
    "num_complete = {}\n",
    "\n",
    "for worker in name:\n",
    "    skip_workers[worker] = 0\n",
    "    num_complete[worker] = 0\n",
    "    # time_workers[worker] = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    info = row['results']['judgments'][0]\n",
    "    # print(row['results'])\n",
    "        \n",
    "    start = datetime.strptime(info['started_at'][11:-6],\"%H:%M:%S\")\n",
    "    end = datetime.strptime(info['created_at'][11:-6],\"%H:%M:%S\")\n",
    "    if info['worker_id'] not in time_workers:\n",
    "        time_workers[info['worker_id']] = end-start\n",
    "    else:\n",
    "        time_workers[info['worker_id']] += end-start\n",
    "    num_complete[info['worker_id']] += 1\n",
    "    print(info['unit_data']['question_id']  + \": \" + info['unit_data']['question'])\n",
    "    print(name[info['worker_id']] + \": \" + str(end-start))\n",
    "    print(\"PARAGRAPH:\")\n",
    "    for sentence in info['unit_data']['long_answer']:\n",
    "        print(sentence)\n",
    "    if 'minimal_answer' in info['unit_data'] and info['unit_data']['minimal_answer'] is not None:\n",
    "        print(\"minimal answer: \" + info['unit_data']['minimal_answer'])\n",
    "    if 'skipthere_is_no_answer' in info['data'] or 'there_is_no_answer' in info['data']:\n",
    "        skip_workers[info['worker_id']] += 1\n",
    "        print(\"SKIP\")\n",
    "    else:\n",
    "        print(\"ANSWER: \")\n",
    "        if 'paragraph_sentences' in info['data']:\n",
    "            for sentence in info['data']['paragraph_sentences']:\n",
    "                print(sentence)\n",
    "        else:\n",
    "            print(\"no sentences selected\")\n",
    "            print(info['data'])\n",
    "        if 'type_your_answer_here_keep_your_answer_as_close_to_the_passage_as_possible_' not in info['data']:\n",
    "        #    print(info['data']['type_your_answer_here_keep_your_answer_as_close_to_the_passage_as_possible_'])\n",
    "        #else:\n",
    "            print(\"no answer provided\")\n",
    "   \n",
    "    print(\"---\")\n",
    "    # break\n",
    "    # print(str(info['worker_id']) + \",\" + info['region'] + \",\" + info['city'] + \",\" + info['started_at'])\n",
    "print(skip_workers)\n",
    "for worker in name:\n",
    "    print(name[worker] + \": \" + str(time_workers[worker]/num_complete[worker]) + \" skip: \" +  str(skip_workers[worker]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "Index(['id', 'data', 'judgments_count', 'state', 'agreement', 'missed_count',\n",
      "       'gold_pool', 'answers_hidden', 'created_at', 'updated_at', 'job_id',\n",
      "       'results'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "name = {47200615:\"Hee Dong\", 46545976: \"Eva Maria\", 46092070: \"Sara\", 45676624: \"Mohamed\", 46373812: \"Chie\", 46545946: \"Joekie\", 46954475: \"Arafat\", 46994197: \"Salim\"}\n",
    "# file_name = \"/dccstor/srosent2/generative/appen/round1_jobs/job_2198088.json.zip\"\n",
    "# data1 = pd.read_json(file_name, lines=True)\n",
    "# print(len(data1))\n",
    "# file_name = \"/dccstor/srosent2/generative/appen/round1_jobs/job_2203926.json.zip\"\n",
    "# data2 = pd.read_json(file_name, lines=True)\n",
    "# print(len(data2))\n",
    "# # data = pd.concat([data1, data2])\n",
    "# # print(len(data))\n",
    "# file_name = \"/dccstor/srosent2/generative/appen/round1_jobs/job_2222665.json.zip\"\n",
    "# data3 = pd.read_json(file_name, lines=True)\n",
    "# print(len(data3))\n",
    "# file_name = \"/dccstor/srosent2/generative/appen/round1_jobs/job_2244326.json.zip\"\n",
    "# data4 = pd.read_json(file_name, lines=True)\n",
    "# print(len(data4))\n",
    "# data = pd.concat([data1, data2, data3, data4])\n",
    "file_name = \"/dccstor/srosent2/generative/appen/round1_jobs/job_2261968.json.zip\"\n",
    "data = pd.read_json(file_name, lines=True)\n",
    "print(len(data))\n",
    "print(data.columns)\n",
    "#data = data.sample(frac = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "def rougeL(answer1, answer2):\n",
    "    scores = scorer.score(answer1, answer2)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_data(data):\n",
    "\n",
    "    avg_rouge_all =  {\"Hee Dong\": [], \"Eva Maria\": [], \"Sara\": [], \"Mohamed\": [], \"Chie\": [], \"Joekie\": [], \"Arafat\": []} \n",
    "    partial =  {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Sara\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0, \"Arafat\": 0} \n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        avg_rouge = {\"Hee Dong\": [], \"Eva Maria\": [], \"Sara\": [], \"Mohamed\": [], \"Chie\": [], \"Joekie\": [], \"Arafat\": []}\n",
    "        print(str(row['data']['question_id']) + \": \" + row['data']['question'])\n",
    "        print(\"Title: \" + str(row['data']['title']))\n",
    "        for sentence in row['data']['long_answer']:\n",
    "            print(sentence)\n",
    "        print(\"---\")\n",
    "        judgements = row['results']['judgments']\n",
    "        skip = set()\n",
    "        scores = {}\n",
    "\n",
    "        i = 0\n",
    "        for i in range(len(judgements)):\n",
    "            answer_type = judgements[i]['data']['how_would_you_describe_the_questionanswer']\n",
    "\n",
    "            if answer_type == 'complete' or answer_type == 'partial':\n",
    "                if answer_type == 'partial':\n",
    "                    partial[name[judgements[i]['worker_id']]] += 1\n",
    "                # if 'type_your_answer_here_keep_your_answer_as_close_to_the_passage_as_possible_' not in judgements[i]['data']:\n",
    "                #     print(\"Error!\")\n",
    "                #     print(judgements[i])\n",
    "                #     continue\n",
    "                # type_your_answer_here_keep_your_answer_as_close_to_the_passage_as_possible_\n",
    "                answer1 = judgements[i]['data']['type_your_answer_here_it_should_be_concise_and_only_come_from_the_passagetitle_']\n",
    "                print(name[judgements[i]['worker_id']] + \": \" + answer1 + \" (\" + answer_type + \")\")\n",
    "                if 'comments_optional' in judgements[i]['data']:\n",
    "                    print(\"comment: \" + judgements[i]['data']['comments_optional'])\n",
    "            else:\n",
    "                skip.add(name[judgements[i]['worker_id']] + \": \" + answer_type)\n",
    "                continue\n",
    "\n",
    "            for j in range(i+1,len(judgements)):\n",
    "                answer_type = judgements[j]['data']['how_would_you_describe_the_questionanswer']\n",
    "\n",
    "                if answer_type == 'complete' or answer_type == 'partial':\n",
    "                    answer2 = judgements[j]['data']['type_your_answer_here_it_should_be_concise_and_only_come_from_the_passagetitle_']\n",
    "                    # print(str(judgements[j]['worker_id']) + \": \" + answer)\n",
    "                else:\n",
    "                    continue\n",
    "                score = rougeL(answer1, answer2)\n",
    "                if name[judgements[i]['worker_id']] == \"Arafat\" or name[judgements[i]['worker_id']] == \"Sara\" \\\n",
    "                     or name[judgements[j]['worker_id']] == \"Arafat\" or name[judgements[j]['worker_id']] == \"Sara\":\n",
    "                    scores[name[judgements[i]['worker_id']] + \"-\" + name[judgements[j]['worker_id']]] = score['rougeL'].fmeasure\n",
    "                    avg_rouge[name[judgements[i]['worker_id']]].append(score['rougeL'].fmeasure)\n",
    "                    avg_rouge[name[judgements[j]['worker_id']]].append(score['rougeL'].fmeasure)\n",
    "        print(\"skip: \" + str(skip))\n",
    "        scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        for score in scores:\n",
    "            print(score)\n",
    "\n",
    "        print(\"Average: \")\n",
    "        for worker in avg_rouge:\n",
    "            if len(avg_rouge[worker]) > 0:\n",
    "                avg = sum(avg_rouge[worker])/len(avg_rouge[worker])\n",
    "                print(worker + \": \" + str(avg))\n",
    "                avg_rouge_all[worker].append(avg)\n",
    "        print(\"-----------------\")\n",
    "\n",
    "        if index > 20:\n",
    "            break\n",
    "    print(\"Annotator| Avg RougeL|# answered\")\n",
    "    print(\"-- | -- | --\")\n",
    "    for worker in avg_rouge_all:\n",
    "        avg = sum(avg_rouge_all[worker])/len(avg_rouge_all[worker])\n",
    "        print(worker + \"|\" + str(avg) + \"|\" + str(len(avg_rouge_all[worker])))\n",
    "        # print(\"partial count: \" + worker + \": \" + str(partial[worker]))\n",
    "\n",
    "process_data(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next code snippet is to analyze data when there is one annotation per example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3818\n",
      "{'id': 6549612615, 'created_at': '2022-12-09T04:10:15+00:00', 'started_at': '2022-12-09T04:04:02+00:00', 'acknowledged_at': None, 'external_type': 'cf_internal', 'golden': False, 'missed': None, 'rejected': None, 'tainted': False, 'country': 'US', 'region': 'NY', 'city': 'Levittown', 'unit_id': 3382327340, 'job_id': 2022794, 'worker_id': 45676624, 'trust': 1.0, 'worker_trust': 0.9549874458874461, 'unit_state': 'finalized', 'data': {'how_would_you_describe_the_questionanswer': 'partial'}, 'unit_data': {'question_id': '8993854018546607757', 'question': 'at the end of a normal exhalation the diaphragm is', 'title': 'Exhalation', 'url': 'https://en.wikipedia.org//w/index.php?title=Exhalation&amp;oldid=843612025', 'long_answer': ['The main reason for exhalation is to rid the body of carbon dioxide , which is the waste product of gas exchange in humans .', 'Air is brought in the body through inhalation .', 'During this process air is taken in through the lungs .', 'Diffusion in the alveoli allows for the exchange of O into the pulmonary capillaries and the removal of CO and other gases from the pulmonary capillaries to be exhaled .', 'In order for the lungs to expel air the diaphragm relaxes , which pushes up on the lungs .', 'The air then flows through the trachea then through the larynx and pharynx to the nasal cavity and oral cavity where it is expelled out of the body .', 'Exhalation takes longer than inhalation since it is believed to facilitate better exchange of gases .', 'Parts of the nervous system help to regulate respiration in humans .', \"The exhaled air is n't just carbon dioxide ; it contains a mixture of other gases .\", 'Human breath contains volatile organic compounds ( VOCs ) .', 'These compounds consist of methanol , isoprene , acetone , ethanol and other alcohols .', 'The exhaled mixture also contains ketones , water and other hydrocarbons .'], 'minimal_text': ''}}\n",
      "667\n",
      "avg length\n",
      "38.70593720857942\n",
      "Annotator | # completed | # answered | # skipped | # non consecutive | # with minimal answer | # sentences selected |  # sentences per answer | # sentences per paragraph\n",
      "-- | -- | -- | -- | -- | -- | -- | -- | --\n",
      "Hee Dong|823|637|186|111|112|1208|2.68|10.22|39.60753532182104\n",
      "Eva Maria|1149|1001|148|117|76|1358|1.59|8.54|31.24175824175824\n",
      "Mohamed|144|110|34|27|10|244|3.21|12.28|30.19090909090909\n",
      "Chie|1013|853|160|218|57|1995|2.88|9.48|45.05041031652989\n",
      "Joekie|674|604|70|191|19|1246|2.33|8.37|42.83940397350993\n",
      "Salim|14|12|2|3|9|14|1.4|6.0|32.5\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "def process_single_data(data):\n",
    "\n",
    "    annotation_count =  {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0, \"Salim\": 0} \n",
    "    skip_count =  {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0, \"Salim\": 0} \n",
    "    sentence_count = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0, \"Salim\": 0} \n",
    "    sentences_per_paragraph = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0, \"Salim\": 0} \n",
    "    num_with_minimal_answer = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0, \"Salim\": 0} \n",
    "    non_consecutive_count = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0, \"Salim\": 0} \n",
    "    answer_len = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0, \"Salim\": 0} \n",
    "    avg_length = 0\n",
    "    avg_noncons_length = 0\n",
    "    noncons_count = 0\n",
    "    total_answered = 0\n",
    "    # csvfile = open('/dccstor/srosent2/generative/appen/job_2035917.non_consecutive.xlsx', 'w', newline='')\n",
    "    all_output = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        judgement = row['results']['judgments'][0]\n",
    "\n",
    "        # if len(row['data']['long_answer']) < 5:\n",
    "        #     continue\n",
    "\n",
    "        if judgement['unit_data']['minimal_text'] != '':\n",
    "            num_with_minimal_answer[name[judgement['worker_id']]] += 1\n",
    "            # continue\n",
    "        \n",
    "        answer_type = judgement['data']['how_would_you_describe_the_questionanswer']\n",
    "        sentences_per_paragraph[name[judgement['worker_id']]] += len(row['data']['long_answer'])\n",
    "\n",
    "        if answer_type == 'complete' or answer_type == 'partial':\n",
    "\n",
    "            if 'type_your_answer_here_it_should_be_concise_and_only_come_from_the_passagetitle_' not in judgement['data']:\n",
    "                print(judgement)\n",
    "                continue\n",
    "            # if answer_type == 'partial':\n",
    "            #     partial[name[judgement['worker_id']]] += 1\n",
    "            if 'paragraph_sentences' in judgement['data']:\n",
    "                sentence_count[name[judgement['worker_id']]] += len(judgement['data']['paragraph_sentences'])\n",
    "            answer1 = judgement['data']['type_your_answer_here_it_should_be_concise_and_only_come_from_the_passagetitle_']\n",
    "            avg_length += len(answer1.split(\" \"))\n",
    "            total_answered += 1\n",
    "            answer_len[name[judgement['worker_id']]] += len(answer1.split(\" \"))\n",
    "\n",
    "            last_consecutive = -1\n",
    "            sent_i = 0\n",
    "            non_consecutive = False\n",
    "            for sentence in row['data']['long_answer']:\n",
    "                if 'paragraph_sentences' in judgement['data'] and sentence in judgement['data']['paragraph_sentences']:\n",
    "                    if last_consecutive != -1 and last_consecutive != sent_i-1:\n",
    "                        non_consecutive = True\n",
    "                        break\n",
    "                    last_consecutive = sent_i\n",
    "                sent_i += 1  \n",
    "\n",
    "            if non_consecutive:\n",
    "                avg_noncons_length += len(answer1.split(\" \"))\n",
    "                noncons_count += 1\n",
    "                output = [str(annotation_count[name[judgement['worker_id']]]) , str(row['data']['question_id']) , row['data']['question'], str(row['data']['title'])]\n",
    "                \n",
    "                sentences = \"\"\n",
    "                for sentence in row['data']['long_answer']:\n",
    "                    if 'paragraph_sentences' in judgement['data'] and sentence in judgement['data']['paragraph_sentences']:\n",
    "                        sentences += \"SELECTED \" + sentence + \"\\n\"\n",
    "                    else:\n",
    "                        sentences += sentence + \"\\n\"\n",
    "                output.append(sentences)\n",
    "                output.append(name[judgement['worker_id']])\n",
    "                output.append(answer1)\n",
    "                output.append(answer_type)\n",
    "                if 'comments_optional' in judgement['data']:\n",
    "                    output.append(judgement['data']['comments_optional'])\n",
    "                all_output.append(output)\n",
    "                non_consecutive_count[name[judgement['worker_id']]] += 1\n",
    "            annotation_count[name[judgement['worker_id']]] += 1\n",
    "        else:\n",
    "            skip_count[name[judgement['worker_id']]] += 1\n",
    "            continue\n",
    "    print(len(all_output))\n",
    "    print(\"avg length\")\n",
    "    print(avg_length/total_answered)\n",
    "    print(\"avg non cons. length\")\n",
    "    print(avg_noncons_length/noncons_count)\n",
    "    # with pd.ExcelWriter(\"/dccstor/srosent2/generative/appen/full_2.6.23.non_consecutive.xlsx\", engine='xlsxwriter') as writer:\n",
    "    #     df = pd.DataFrame(all_output)\n",
    "    #     df.to_excel(writer, sheet_name='Sheet1')\n",
    "    #     workbook  = writer.book\n",
    "    #     worksheet = writer.sheets['Sheet1']\n",
    "    #     cell_format = workbook.add_format({'text_wrap': True})\n",
    "    #     worksheet.set_column('A:Z', cell_format=cell_format)\n",
    "        \n",
    "    print(\"Annotator | # completed | # answered | # skipped | # non consecutive | # with minimal answer | # sentences selected |  # sentences per answer | # sentences per paragraph\")\n",
    "    print(\"-- | -- | -- | -- | -- | -- | -- | -- | --\")\n",
    "    for worker in annotation_count:\n",
    "        print(worker + \"|\" + str(annotation_count[worker] + skip_count[worker]) +  \"|\" +\n",
    "          str(annotation_count[worker]) + \"|\" + str(skip_count[worker]) + \"|\" + str(non_consecutive_count[worker]) + \"|\" + str(num_with_minimal_answer[worker]) + \"|\" + str(sentence_count[worker]) + \"|\" +\n",
    "          str(round(sentence_count[worker]/(annotation_count[worker]-skip_count[worker]),2)) + \"|\" +  str(round(sentences_per_paragraph[worker]/(annotation_count[worker]-skip_count[worker]),2)) + \"|\" + str(answer_len[worker]/annotation_count[worker]))\n",
    "        # print(\"partial count: \" + worker + \": \" + str(partial[worker]))\n",
    "\n",
    "print(len(data))\n",
    "process_single_data(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2095\n",
    "{'id': 6549612615, 'created_at': '2022-12-09T04:10:15+00:00', 'started_at': '2022-12-09T04:04:02+00:00', 'acknowledged_at': None, 'external_type': 'cf_internal', 'golden': False, 'missed': None, 'rejected': None, 'tainted': False, 'country': 'US', 'region': 'NY', 'city': 'Levittown', 'unit_id': 3382327340, 'job_id': 2022794, 'worker_id': 45676624, 'trust': 1.0, 'worker_trust': 0.9549874458874461, 'unit_state': 'finalized', 'data': {'how_would_you_describe_the_questionanswer': 'partial'}, 'unit_data': {'question_id': '8993854018546607757', 'question': 'at the end of a normal exhalation the diaphragm is', 'title': 'Exhalation', 'url': 'https://en.wikipedia.org//w/index.php?title=Exhalation&amp;oldid=843612025', 'long_answer': ['The main reason for exhalation is to rid the body of carbon dioxide , which is the waste product of gas exchange in humans .', 'Air is brought in the body through inhalation .', 'During this process air is taken in through the lungs .', 'Diffusion in the alveoli allows for the exchange of O into the pulmonary capillaries and the removal of CO and other gases from the pulmonary capillaries to be exhaled .', 'In order for the lungs to expel air the diaphragm relaxes , which pushes up on the lungs .', 'The air then flows through the trachea then through the larynx and pharynx to the nasal cavity and oral cavity where it is expelled out of the body .', 'Exhalation takes longer than inhalation since it is believed to facilitate better exchange of gases .', 'Parts of the nervous system help to regulate respiration in humans .', \"The exhaled air is n't just carbon dioxide ; it contains a mixture of other gases .\", 'Human breath contains volatile organic compounds ( VOCs ) .', 'These compounds consist of methanol , isoprene , acetone , ethanol and other alcohols .', 'The exhaled mixture also contains ketones , water and other hydrocarbons .'], 'minimal_text': ''}}\n",
    "307\n",
    "Annotator | # completed | # answered | # skipped | # non consecutive | # with minimal answer | # sentences selected |  # sentences per answer | # sentences per paragraph\n",
    "-- | -- | -- | -- | -- | -- | -- | -- | --\n",
    "Hee Dong|600|452|148|71|112|790|2.6|10.25\n",
    "Eva Maria|569|490|79|57|76|657|1.6|8.09\n",
    "Mohamed|143|109|34|27|10|242|3.23|12.37\n",
    "Chie|608|523|85|114|57|1235|2.82|8.41\n",
    "Joekie|160|137|23|35|19|260|2.28|8.31\n",
    "Salim|14|12|2|3|9|14|1.4|6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2495396943532822225, -229082287897515617, -2264134242434198326, 2079100088522925638, 2980592935468943450, 6161497846937596390, -4959346488900267637, -2465861575714299171, -2189548918642725127, 7098636154491383343, -3933208289628918028, -1257580038851946042, 5121004319758778839, -1399826316214371736, -6946841282838040550, 8427201419256600035, -1584181447791057413, -4084391713873607156, 8777897555648878475, 5808798670950006232, 7898252756426188619, -936565044218557383, -4618864426037979762, 8116928765126546687, -1729923543484435760, -1062046011613182635, -4209352084651040508, 7483313621841077081, 996768280100184490, -8619899755897217555, 923449576656273005, -1275524742182878778, 873564346673136599, -779483661367421641, 1688288076551153504, -1157343340377926175, 662120736332570642, 5866872638910116716, 3998102536607710960, -2951084596378848197, 3037366949322470211, 8713188615749424843, 3103906544916591053, 4947463880421396368, 5461188725342525320, -2705463144889337080, -1371894834665056317, -8629097036726078869, -1968405669239622476, 6386961383946136993, -8064518353303370644, -3923468409561071009, -3433193646038984836, -823486921735600719, -4673381443607457132, -5713405378894535920, 5320436682088004611, 1847562488251456266, 5614935146343238953, -7950989363837485486, -3474041871426097655, 6767902939333911081, -6773951822001912626, -4091415169370123881, 3423000083414541883, 5819608244932418137, -7037257062836974036, 7349695316137912396, 6238924485779903024, 1773018467151937698, 26282907202164485, -659410617702625643, -2131312087518349917, 2061495492169076048, 1371632852875851031, 2670263968390861782, -823708140666796093, -5676493558237617080, 7576561339948093111, 4026300948942185987, 6212681505226949866, -7905905372343327163, -8346119527388758865, 1249598914156603825, -3267717105755108563, 1773549058744658442, 5107688407324157941, 4676002274784316434, -6386286690559682770, -272699795805920544, 5496687065691512443, 7012260037231457401, 147778680095892610, 564840272417677889, -8370806050105689075, 8844782926219157575, -6660928758563057380, -4183869252491173791, -8121883889178313578, 5252049419884102420, 8078065839701854560, -5431175315239443030, -1914944020531368158, 2839799694676987689, -3962441978670574417, -1253276861661765206, 8386324730191864075, -4617073487545247869, 7732774843336374617, -6019826312891091394, 2853325097459087994, -7063680354960177161, -8001564466094034216, 5657612271627174082, 211712399091259750, -8663363023746022502, 7261638553433097701, 4106541976225717010, 8664675285966925401, 7457627639617431907, -8256305667082527285, -2147026272052993881, -4709452665390558548, -4265517280497870183, 6708715174502469602, 2389211900785851505, -4951025187477080523, -3749177814501001596, 896773895186101905, -2312497216715831032, 5365706410020563629, 4068684148045245438, -7917317314516804853, 8824304517892704006, 6401197308716204890, 7321027163416439028, 4311379768849814379, -706037731496174088, -2277978882346195536, -8400502352454998371, 847723125579808866, -9144238222528625698, -2088358219848335172, -3485714005907152096, -5334327453087093295, -2054628228468316263, -7644289541271486372, 7692212667654595924, 4988326746697423597, 8069008391649164179, -5352303832848103685, 4124855109584689671, 4909905163806325087, -7472401351435133103, -2399489377049908954, -6668537295109480193, 5319329934491202773, 539696164695592117, -6703076447246847777, 271525249042112189, -3299155532716770059, -6379860503567435412, -8687340786359128185, 3794450356620929888, 3355180096232411678, -6333085104023663146, -6929866640242544539, 3945883905744097631, 4088290661268897018, -8799334786135262985, 8641449097921979703, -6448570461904598731, 61676953195646420, -7434114389341220504, -2294256020824610735, -5809289061665530022, 9184174252154560462, -4015235538120941066, 1748177535249649888, 8904357863082268359, 655836359378226030, 3176041515418332100, 7239708044866662245, -8255622330472014268, 5739443045617036105, 1605903962310739428, -4427389245878997047, -5760774585715502780, -6667098458549745468, -7962550790027868384, -1218875241352839456, -4298958358784522374, -3081753292173314082, 7812627963583184440, 404731369252436306, 303093955824602175, 1952549940748890096, -4138078544948263349, -2681885798259725675, 1825594767789845231, 7988329761675910071, 82385993877337955, 2787811968687221049, -7377828251210812248, 2445255975430036163, 5567148407602073825, 4949638613124608547, -5925584991124062342, 3588636184585788474, -3264674982292768799, -2406798167614637170, 6007917538066280414, -7497192538060000148, 2303960438245327497, -3548262838546238731, -8781018365983812218, -6833142467846046261, -6338402901950264835, -7869807512840841961, -7046884796034488800, 3693575745763251678, -6132878348591908885, -1919313504241301548, -3019347285558944364, 4302126636828987358, 5022173684691269392, -4709509205047866236, -3714227674854059589, -6800237420245525859, 7468794414379661050, -6336181768549910541, 6956710458361304122, -1121963788203736353, -3431167338713387150, 138713725038644067, 7663406429430503589, 5153457465520635701, 8048522585381607401, -434284248695810364, 3026174202827908652, -1683156601593628060, 8604745961754280555, -250120508191745769, -3630668852329184957, 7287786402792448843, -3135281716449062067, -2140282230594159335, 5201214711968395820, -6108171001798735768, -2523159034151523359, 6498449454399036323, 2467726430222210965, -7090705350443894352, 5940116972435933830, 7770488621251822506, -5388425724260292071, -5252331500235408414, -2019831316732191172, -8291682666347281786, -1376092079019440468, 1519094895362301752, -1958418355207694264, 1294453168870444317, -4302557547054570374, -395463318957786293, 5539784155984675927, 4232550803025393334, -1713121827832885030, -4710620474450900051, 6170717506448616660, 4523736219295215276, 54652590347694060, -1811394137773715812, -7161860190095334095, 3361627022695645375, -3913791558291967751, -1238116540107544753, 6503643630824298963, 3166251051624897512, 4550944961320752421, 8091625215713710904, -7286717993308076775, -7391400212562846984, 9124220649895286940, 1883461416512051223, 7805759075376361901, 5695320212079691221, 2960221046363328616, -1411184700173642743, -1286481036686615960, 6762095862863644169, 1062512425617030836, -1829998971945083069, 4073541956852691520, -6510286824757176315, -8308301572816073278, -1750447400710005062, -5319683884407734497, -5656391955796154520, -7492408127458093340, -2538279974896743258, -9025710588846987152, 6560700610521845615, -2652183708580968768, 4795064992348115658, -2799979436905626723, 6439237669287005775]\n"
     ]
    }
   ],
   "source": [
    "# load the annotations that have already been completed in round 2 setup so they don't get completed again. \n",
    "# keep track of the IDs\n",
    "import glob\n",
    "\n",
    "dir_name = \"/dccstor/srosent2/generative/appen/round2_1.20.2023/job_2035917.round2.*.csv\"\n",
    "files = glob.glob(dir_name)\n",
    "dir_name = \"/dccstor/srosent2/generative/appen/full_2.6.23.round2/*.csv\"\n",
    "files.extend(glob.glob(dir_name))\n",
    "data_ids = []\n",
    "for file_name in files:\n",
    "    seen_data = pd.read_csv(file_name)\n",
    "    data_ids.extend(list(seen_data['id']))\n",
    "print(data_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 6681520194, 'created_at': '2023-09-06T11:51:13+00:00', 'started_at': '2023-09-06T11:49:13+00:00', 'acknowledged_at': None, 'external_type': 'cf_internal', 'golden': False, 'missed': None, 'rejected': None, 'tainted': False, 'country': 'US', 'region': 'New York', 'city': 'New Windsor', 'unit_id': 3493405941, 'job_id': 2261968, 'worker_id': 46545976, 'trust': 1.0, 'worker_trust': 0.9865308641975301, 'unit_state': 'finalized', 'data': {'how_would_you_describe_the_questionanswer': 'complete', 'please_confirm_the_following_before_proceeding_if_you_are_not_skipping_this_question': ['reread']}, 'unit_data': {'question_id': '5092896004240326569', 'question': 'can smooth muscle change the diameter of blood vessels', 'title': 'Vascular smooth muscle', 'url': 'https://en.wikipedia.org//w/index.php?title=Vascular_smooth_muscle&amp;oldid=812798116', 'long_answer': ['α 1 ( \\\\ displaystyle \\\\ alpha _', '( 1 ) ) receptors .', 'Under NE binding α 1 ( \\\\ displaystyle \\\\ alpha _', '( 1 ) ) receptors cause vasoconstriction ( i.e. contraction of the vascular smooth muscle cells decreasing the diameter of the vessels ) .', 'α 1 ( \\\\ displaystyle \\\\ alpha _', '( 1 ) )', 'receptors are activated in response to shock or low blood pressure as a defensive reaction trying to restore the normal blood pressure .', 'Antagonists of α 1 ( \\\\ displaystyle \\\\ alpha _', '( 1 ) ) receptors ( doxazosin , prazosin ) cause vasodilation ( i.e. decrease in vascular smooth muscle tone with increase of vessel diameter and decrease of the blood pressure ) .', '( See also receptor antagonist )'], 'minimal_text': ''}}\n",
      "Hee Dong: 5\n",
      "Chie: 4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "name = {47200615:\"Hee Dong\", 46545976: \"Eva Maria\", 46092070: \"Sara\", 45676624: \"Mohamed\", 46373812: \"Chie\", 46545946: \"Joekie\", 46954475: \"Arafat\", 46994197: \"Salim\"}\n",
    "\n",
    "def appen_round2_check(data, seen_ids=None):\n",
    "\n",
    "    annotation_count =  {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0} #, \"Salim\": 0} \n",
    "    skip_count =  {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0} #, \"Salim\": 0} \n",
    "    sentence_count = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0} #, \"Salim\": 0} \n",
    "    sentences_per_paragraph = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0} #, \"Salim\": 0} \n",
    "    num_with_minimal_answer = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0} #, \"Salim\": 0} \n",
    "    new_task = {\"Hee Dong\": [], \"Chie\": []} #, \"Joekie\": []}\n",
    "    annotators = [\"Hee Dong\", \"Chie\"] #, \"Joekie\"]\n",
    "    \n",
    "    all_output = []\n",
    "    seen_id_count = 0\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "\n",
    "        if seen_ids is not None and int(row['data']['question_id']) in seen_ids:\n",
    "            seen_id_count += 1\n",
    "            continue\n",
    "        judgement = row['results']['judgments'][0]\n",
    "\n",
    "        if judgement['unit_data']['minimal_text'] != '' and name[judgement['worker_id']] in annotators:\n",
    "            num_with_minimal_answer[name[judgement['worker_id']]] += 1\n",
    "            # continue\n",
    "        \n",
    "        answer_type = judgement['data']['how_would_you_describe_the_questionanswer']\n",
    "        if name[judgement['worker_id']] in annotators:\n",
    "            sentences_per_paragraph[name[judgement['worker_id']]] += len(row['data']['long_answer'])\n",
    "\n",
    "        if answer_type == 'complete' or answer_type == 'partial':\n",
    "\n",
    "            if 'type_your_answer_here_it_should_be_concise_and_only_come_from_the_passagetitle_' not in judgement['data']:\n",
    "                print(judgement)\n",
    "                continue\n",
    "            # if answer_type == 'partial':\n",
    "            #     partial[name[judgement['worker_id']]] += 1\n",
    "            if 'paragraph_sentences' in judgement['data'] and name[judgement['worker_id']] in annotators:\n",
    "                sentence_count[name[judgement['worker_id']]] += len(judgement['data']['paragraph_sentences'])\n",
    "            answer1 = judgement['data']['type_your_answer_here_it_should_be_concise_and_only_come_from_the_passagetitle_']\n",
    "\n",
    "            last_consecutive = -1\n",
    "            sent_i = 0\n",
    "            non_consecutive = False\n",
    "            for sentence in row['data']['long_answer']:\n",
    "                if 'paragraph_sentences' in judgement['data'] and sentence in judgement['data']['paragraph_sentences']:\n",
    "                    if last_consecutive != -1 and last_consecutive != sent_i-1:\n",
    "                        non_consecutive = True\n",
    "                        break\n",
    "                    last_consecutive = sent_i\n",
    "                sent_i += 1  \n",
    "\n",
    "            if non_consecutive:\n",
    "                output = [str(row['data']['question_id']) , row['data']['question'], str(row['data']['title'])]\n",
    "                \n",
    "                sentences = \"\"\n",
    "                selected = \"\"\n",
    "                for sentence in row['data']['long_answer']:\n",
    "                    sentences += sentence + \"&nbsp;\"\n",
    "                    if 'paragraph_sentences' in judgement['data'] and sentence in judgement['data']['paragraph_sentences']:\n",
    "                        selected += \"True\"\n",
    "                    else:\n",
    "                        selected += \"False\"\n",
    "                    selected += \"&nbsp;\"\n",
    "                title_used_in_answer = False\n",
    "                if 'title_used_in_answer' in judgement['data']:\n",
    "                    title_used_in_answer = True\n",
    "                output.append(sentences)\n",
    "                output.append(selected)\n",
    "                output.append(title_used_in_answer)\n",
    "                output.append(name[judgement['worker_id']])\n",
    "                output.append(answer1)\n",
    "\n",
    "                random_person = annotators[random.randint(0,len(annotators)-1)]\n",
    "                \n",
    "                while random_person == name[judgement['worker_id']] or len(new_task[random_person]) > 15:\n",
    "                    random_person = annotators[random.randint(0,len(annotators)-1)]\n",
    "                # print(random_person)\n",
    "                new_task[random_person].append(output)\n",
    "                if name[judgement['worker_id']] in annotators:\n",
    "                    annotation_count[name[judgement['worker_id']]] += 1\n",
    "        else:\n",
    "            if name[judgement['worker_id']] in annotators:\n",
    "                skip_count[name[judgement['worker_id']]] += 1\n",
    "            continue\n",
    "\n",
    "    for person in new_task:\n",
    "        df = pd.DataFrame(new_task[person])\n",
    "        print(person + \": \" + str(len(new_task[person])))\n",
    "        df.to_csv(\"/dccstor/srosent2/generative/appen/round2_jobs6/input/job_round2.\" + person + \".csv\", encoding='utf-8', header=[\"id\",\"question\",\"title\",\"long_answer\",\"selected\",\"title_used\",\"worker\",\"answer\"])\n",
    "    print(seen_id_count)\n",
    "    # print(\"Annotator | # completed | # answered | # skipped | # with minimal answer | # sentences selected |  # sentences per answer | # sentences per paragraph\")\n",
    "    # print(\"-- | -- | -- | -- | -- | -- | -- | -- \")\n",
    "    # for worker in annotation_count:\n",
    "    #     print(worker + \"|\" + str(annotation_count[worker]) +  \"|\" +\n",
    "    #       str(annotation_count[worker] - skip_count[worker]) + \"|\" + str(skip_count[worker]) + \"|\" + str(num_with_minimal_answer[worker]) + \"|\" + str(sentence_count[worker]) + \"|\" +\n",
    "    #       str(round(sentence_count[worker]/(annotation_count[worker]-skip_count[worker]),2)) + \"|\" +  str(round(sentences_per_paragraph[worker]/(annotation_count[worker]-skip_count[worker]),2)))\n",
    "    #     # print(\"partial count: \" + worker + \": \" + str(partial[worker]))\n",
    "\n",
    "# file_name = \"/dccstor/srosent2/generative/appen/round1_jobs/job_2145426.json.zip\"\n",
    "# data = pd.read_json(file_name, lines=True)\n",
    "\n",
    "appen_round2_check(data, seen_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n",
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Chie\n",
      "Chie\n",
      "Chie\n",
      "Hee Dong\n",
      "Hee Dong\n",
      "Chie\n",
      "Hee Dong: 74\n",
      "Chie: 186\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_900061/4117677936.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data.append(data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Get ones that were marked as having no answer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "\n",
    "name = {47200615:\"Hee Dong\", 46545976: \"Eva Maria\", 46092070: \"Sara\", 45676624: \"Mohamed\", 46373812: \"Chie\", 46545946: \"Joekie\", 46954475: \"Arafat\", 46994197: \"Salim\"}\n",
    "\n",
    "def appen_round2_noanswer(data, seen_ids=None):\n",
    "\n",
    "    annotation_count =  {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0} #, \"Salim\": 0} \n",
    "    skip_count =  {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0} #, \"Salim\": 0} \n",
    "    sentence_count = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0} #, \"Salim\": 0} \n",
    "    sentences_per_paragraph = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0} #, \"Salim\": 0} \n",
    "    num_with_minimal_answer = {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0} #, \"Salim\": 0} \n",
    "    new_task = {\"Hee Dong\": [], \"Eva Maria\": [], \"Chie\": [], \"Joekie\": []}\n",
    "    annotators = [\"Hee Dong\", \"Eva Maria\", \"Mohamed\", \"Chie\", \"Joekie\"]\n",
    "    \n",
    "    all_output = []\n",
    "    seen_id_count = 0\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "\n",
    "        if seen_ids is not None and int(row['data']['question_id']) in seen_ids:\n",
    "            seen_id_count += 1\n",
    "            continue\n",
    "        judgement = row['results']['judgments'][0]\n",
    "\n",
    "        if judgement['unit_data']['minimal_text'] != '' and name[judgement['worker_id']] in annotators:\n",
    "            num_with_minimal_answer[name[judgement['worker_id']]] += 1\n",
    "            # continue\n",
    "        \n",
    "        answer_type = judgement['data']['how_would_you_describe_the_questionanswer']\n",
    "        if name[judgement['worker_id']] in annotators:\n",
    "            sentences_per_paragraph[name[judgement['worker_id']]] += len(row['data']['long_answer'])\n",
    "\n",
    "        if answer_type == 'complete' or answer_type == 'partial':\n",
    "            continue\n",
    "        else:\n",
    "            if name[judgement['worker_id']] in annotators:\n",
    "                skip_count[name[judgement['worker_id']]] += 1\n",
    "            output = [str(row['data']['question_id']) , row['data']['question'], str(row['data']['title'])]\n",
    "                \n",
    "            sentences = \"\"\n",
    "            for sentence in row['data']['long_answer']:\n",
    "                sentences += sentence + \"&nbsp;\"\n",
    "            output.append(sentences)\n",
    "            output.append(name[judgement['worker_id']])\n",
    "            output.append(answer_type)\n",
    "\n",
    "            random_person = annotators[random.randint(0,len(annotators)-1)]\n",
    "            while random_person == name[judgement['worker_id']] or random_person == \"Mohamed\" or len(new_task[random_person]) > 51:\n",
    "                random_person = annotators[random.randint(0,len(annotators)-1)]\n",
    "            print(random_person)\n",
    "            new_task[random_person].append(output)\n",
    "            if name[judgement['worker_id']] in annotators:\n",
    "                annotation_count[name[judgement['worker_id']]] += 1\n",
    "\n",
    "    for person in new_task:\n",
    "        df = pd.DataFrame(new_task[person])\n",
    "        print(person + \": \" + str(len(new_task[person])))\n",
    "        df.to_csv(\"/dccstor/srosent2/generative/appen/no_answer_round2/job_roundNA.\" + person + \".csv\", encoding='utf-8', header=[\"id\",\"question\",\"title\",\"long_answer\",\"worker\",\"answer_type\"])\n",
    "    print(seen_id_count)\n",
    "\n",
    "paths = glob.glob(\"/dccstor/srosent2/generative/appen/round1_jobs/job_*.json.zip\")\n",
    "\n",
    "for file_name in paths:\n",
    "    data = pd.read_json(file_name, lines=True)\n",
    "    data.append(data, ignore_index=True)\n",
    "# data = pd.DataFrame([pd.read_json(p, typ=\"series\", lines=True) for p in paths])\n",
    "\n",
    "appen_round2_noanswer(data, seen_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "name = {47200615:\"Hee Dong\", 46545976: \"Eva Maria\", 45676624: \"Mohamed\", 46373812: \"Chie\", 46545946: \"Joekie\"}\n",
    "dir_name = \"/dccstor/srosent2/generative/appen/Round2/\"\n",
    "files = os.listdir(dir_name)\n",
    "\n",
    "new_annotations = None\n",
    "gold_annotations = None\n",
    "\n",
    "for file_name in files:\n",
    "    if file_name.endswith('json.zip'):\n",
    "        if new_annotations is None:\n",
    "            new_annotations = pd.read_json(dir_name + file_name, lines=True)\n",
    "        else:\n",
    "            new_annotations = new_annotations.append(pd.read_json(dir_name + file_name, lines=True))\n",
    "    elif file_name.endswith('csv'):\n",
    "        gold_annotations = pd.read_csv(dir_name + file_name, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which pigment determines the colour of human hair\n",
      "Mohamed: Eumelanin, which is behind the colors black , blond , and brown, and Pheomelanin, which is behind the red color, are the two pigments that determine the human hair color.\n",
      "Joekie: Eumelanin determines the hair colors gray, black, blond and brown, and Pheomelanin, determines red hair color.\n",
      "['extra info']\n",
      "Mohamed/Joekie: 0.5454545454545454\n",
      "--\n",
      "when did we start putting shoes on horses\n",
      "Hee Dong: Historians differ on the origin of the horseshoe. Because iron was a valuable commodity, and any worn out items were generally reforged and reused , it is difficult to locate clear archaeological evidence. In 1897 four bronze horseshoes with what are apparently nail holes were found in an Etruscan tomb dated around 400 B.C. The assertion by some historians that the Romans invented the `` mule shoes '' sometime after 100 BC is supported by a reference by Catullus who died in 54 BC.\n",
      "Joekie: Historians differ on the origin of the horseshoe. Because iron was a valuable commodity, and any worn out items were generally reforged and reused , it is difficult to locate clear archaeological evidence. In 1897 four bronze horseshoes with what are apparently nail holes were found in an Etruscan tomb dated around 400 B.C. The assertion by some historians that the Romans invented the `` mule shoes '' sometime after 100 BC is supported by a reference by Catullus who died in 54 BC, however, the reference may have been to the `` hipposandal '' -- leather boots , reinforced by an iron plate , rather than to nailed horseshoes .\n",
      "['missing info']\n",
      "Hee Dong/Joekie: 0.8864864864864864\n",
      "--\n",
      "who trained the continental army at valley forge\n",
      "Eva Maria: Friedrich Wilhelm von Steuben arrived at Valley Forge on February 23 , 1778 , and reported for duty as a volunteer.\n",
      " He turned the volunteers into a great army ''\n",
      "--\n",
      "what impact did the geography of new england have on the farming communities\n",
      "Mohamed: Many people in New England did not farm since the soil and weather  was not suitable for farming.\n",
      "Instead they imported crops and traded products they had to other countries . They also traded furs and livestock products.\n",
      "Joekie: Many people in New England did not farm since the soil and weather was not suitable for farming. Instead they imported crops and traded products they had.\n",
      "['extra info']\n",
      "Mohamed/Joekie: 0.8437499999999999\n",
      "Sara: Many people in New England did not farm since the soil and weather  was not suitable for farming. Instead they imported crops and traded products they had to other countries . They products they traded included fish,  whale, ships, timber, furs and livestock.\"\n",
      "****\n",
      "Sara/Mohamed: 0.782608695652174\n",
      "Sara/Joekie: 0.8860759493670887\n",
      "--\n",
      "what is the function of the endoplasmic reticulm\n",
      "Chie: The endoplasmic reticulum is a type of organelle found in eukaryotic cells that forms an interconnected network of flattened, membrane-enclosed sacs or tube-like structures known as cisternae.  There are two types of endoplasmic reticulum: rough and smooth. The rough endoplasmic reticulum is studded with ribosomes that are the sites of protein synthesis, and the smooth endoplasmic reticulum functions in lipid manufacture and metabolism, the production of steroid hormones, and detoxification.\n",
      "--\n",
      "how did the house of saud come to power\n",
      "Chie: The succession to the Saudi Arabian throne was designed to pass from one son of the first king, Ibn Saud, to another.  The monarchy was hereditary by agnatic seniority until 2006, when a royal decree provided that future Saudi kings are to be elected by a committee of Saudi princes.\n",
      "--\n",
      "who was the chief minister of west bengal\n",
      "Mohamed: Since 1947 , there have been eight Chief Ministers of West Bengal, including Prafulla Chandra Ghosh, Dr Bidhan Chandra Roy, Prafulla Chandra Sen, Jyoti Basu, Buddhadeb Bhattacharya and Mamata Banerjee.\n",
      "--\n",
      "what is the status of the 416 fire in colorado\n",
      "Mohamed: The 416 is active and has had major impacts on tourism and commerce for communities in the southwest portion of Colorado.\n",
      "Joekie: The 416 fire is active and as of July 2, 2018 has burned over 55,000 acres. It is one of the largest wildfires in Colorado 's history and has had major impacts on tourism and commerce.\n",
      "['missing info']\n",
      "Mohamed/Joekie: 0.4482758620689656\n",
      "Avi: The 416 & Burro Fire Complex are active wildfires in the southwestern portion of Colorado in the United States . The fires are predominately within San Juan National Forest , 13 miles north of Durango and 14 miles south of Rico . As of July 2 , 2018 the fires have burned a combined total of over 55,000 acres ( 22,258 ha ) and have cost more than $27 million to contain . It is one of the largest wildfires in Colorado 's history and has had major impacts on tourism and commerce for communities in the southwest portion of the state .\n",
      "****\n",
      "Avi/Mohamed: 0.5263157894736842\n",
      "Avi/Joekie: 0.3247863247863248\n",
      "--\n",
      "in order to better control the conquistadors in the new world the spanish created\n",
      "Eva Maria: The leader of the expedition received clear instructions about their duties towards the army , the native population, the type of military action. The royal official of the army, the veedor, ensured they complied with orders and instructions and preserved the King 's share of the booty.\n",
      "--\n",
      "where was the movie dan in real life filmed\n",
      "Chie: The opening scene was in New Jersey and then Rhode Island in the cities of Newport, East Greenwich, West Greenwich, Jamestown, Westerly, and Providence in November and December 2006.  The opening scene was filmed at Seven Stars Bakery in Providence . The first time Dan is pulled over by the Jamestown, Rhode Island police, he is on Ocean Ave Newport, Rhode Island, then by Mackerel Cove in Jamestown.  The inside shots were filmed at Alley Katz Bowling center, while the exterior shots were filmed at Misquamicut Beach.  The sunset scene with the entire family on the beach was filmed at Napatree Point in Westerly.\n",
      "Joekie: It was filmed in New Jersey and the Rhode Island cities of Newport, East Greenwich, West Greenwich, Jamestown, Westerly, Providence and Misquamicut Beach.\n",
      "['extra info']\n",
      "Chie/Joekie: 0.31746031746031744\n",
      "Sara: The opening scene was in New Jersey and then Rhode Island in the cities of Newport, East Greenwich, West Greenwich, Jamestown, Westerly, and Providence. The opening scene was filmed at Seven Stars Bakery in Providence . Dan is pulled over on Ocean Ave in Newport, Rhode Island and in Jamestown. The date scene was filmed in Westerly. The inside shots were filmed at Alley Katz Bowling center, while the exterior shots were filmed at Misquamicut Beach. The sunset scene with the entire family on the beach was filmed at Napatree Point in Westerly.\n",
      "Sara/Chie: 0.3478260869565218\n",
      "Sara/Joekie: 0.8512820512820513\n",
      "--\n",
      "where is look what you made me do on the charts\n",
      "Chie: In the United States, \"Look What You Made Me Do\" debuted at number seventy-seven on the Billboard Hot 100, powered by its first three days of airplay. One week later, the song ascended from 77 to one on the Hot 100 after its first full week of tracking.  It remained atop the Hot 100 and Streaming Songs charts for a second week.\n",
      "Eva Maria: The song ascended from 77 to one on the Hot 100 after its first full week of tracking, and remained atop the Hot 100 and Streaming Songs charts for a second week.\n",
      "['paraphrase', 'extra info']\n",
      "Chie/Eva Maria: 0.6526315789473683\n",
      "--\n",
      "where was out of the furnace movie filmed\n",
      "Hee Dong: Principal photography of Out of the Furnace began in the Pittsburgh metropolitan area. The majority of filming took place in Braddock , and additional filming was in nearby North Braddock , Imperial , Rankin , and Swissvale. Prison scenes were filmed in the Northern Panhandle of West Virginia , at the former State Penitentiary in Moundsville. Filming also took place in rural Beaver County , including a deer hunting scene in Raccoon Creek State Park and a mill scene in Koppel.\n",
      "--\n",
      "what led to the development of the global positioning system\n",
      "Chie: The GPS project was launched in the United States in 1973 to overcome the limitations of previous navigation systems, integrating ideas from several predecessors, including a number of classified engineering design studies from the 1960s.  It was initially developed for use by the United States military.\n",
      "Eva Maria: It was originally developed for use by the United States military and became fully functional in 1995.\n",
      "['missing info']\n",
      "Chie/Eva Maria: 0.3174603174603175\n",
      "Hans: The GPS project was initially created for US military uses starting in 1973, building on previous ideas from several predecessors , including a number of classified engineering design studies from the 1960s. Civillian usage was permitted from the 1980s.\n",
      "Hans/Chie: 0.14545454545454545\n",
      "Hans/Eva Maria: 0.5714285714285715\n",
      "--\n",
      "difference between active and passive satellite in wikipedia\n",
      "Mohamed: Active satellites amplify the received signal before retransmitting it to the receiver on the ground, while passive satellites do not amplify the signal and only a very small amount of the transmitted energy actually reaches the receiver.\n",
      "Eva Maria: Active satellites amplify the received signal before transmitting it to the receiver on the ground. With passive satellites, the reflected signal is not amplified at the satellite - only a very small amount of transmitted energy reaches the receiver.\n",
      "['paraphrase']\n",
      "Mohamed/Eva Maria: 0.8\n",
      "Salim: Passive satellites only reflect the signal coming from the source toward the direction of the receiver while active satellite will amplify the received signal before retransmission.\n",
      "****\n",
      "Salim/Mohamed: 0.28125\n",
      "Salim/Eva Maria: 0.31746031746031744\n",
      "--\n",
      "where do they shoot guy's grocery games\n",
      "Hee Dong: Guy's Grocery Games Season 1 was shot inside of an actual grocery store , Field 's Market in West Hills , California. For Season 2 , the market was built in a 15,500 square foot warehouse in Santa Rosa , CA.\n",
      "--\n",
      "what is the printscreen key on a laptop\n",
      "Chie: In Microsoft Windows, pressing Prt Sc will capture the entire screen, while pressing the Alt key in combination with Prt Sc will capture the currently selected window.  Pressing Prt Sc with both the left Alt key and left ⇧ Shift pressed turns on a high contrast mode.  Since Windows 8, pressing the ⊞ Win key in combination with Prt Sc (and optionally in addition to the Alt key) will save the captured image to disk.\n",
      "Eva Maria: In Microsoft Windows, pressing Prt Sc will capture the entire screen, whereas pressing the Alt key in combination with Prt Sc will capture the currently selected window.\n",
      "['extra info']\n",
      "Chie/Eva Maria: 0.52\n",
      "--\n",
      "where do sperm gain the ability to​ swim\n",
      "Joekie: Sperm movement is activated by changes in intracellular ion concentration, the ion concentration that provoke motility is different among species .  In some mammals , sperm motility is activated by an increase in pH , calcium ion and cAMP.\n",
      "Eva Maria: .\n",
      "['no']\n",
      "Joekie/Eva Maria: 0\n",
      "Arafat: Sperm movement is activated by changes in intracellular ion concentration. Factors that can cause such changes include: (a) a rise in pH, for example in marine invertebrates and sea urchins, leading to a decrease in intracellular potassium and thus inducing membrane hyperpolarization, (b) a change in cell volume, and (c) in some mammals, an increase in pH, calcium ion and cAMP.\n",
      "Arafat/Joekie: 0\n",
      "Arafat/Eva Maria: 0.45360824742268047\n",
      "--\n",
      "who is awarded the honour of victoria cross\n",
      "Mohamed: The Victoria Cross is awarded to members of the British Armed Forces, people of any military rank in any service and to civilians under military command.\n",
      "Eva Maria: The Victoria Cross, the highest and most prestigious award of the British honours system,  is awarded to members of the British Armed Forces, people of any military rank in any service and to civilians under military command.\n",
      "['missing info']\n",
      "Mohamed/Eva Maria: 0.8253968253968255\n",
      "--\n",
      "where does the royal family of england get their income\n",
      "Mohamed: The royal family of England get their income from a number of sources, including the Sovereign Grant from the UK Parliament, which is a percentage of the annual profits of the Crown Estate, revenues from the Duchies of Lancaster and Cornwall , a parliamentary annuity , and income from private investments .\n",
      "Arafat: The royal family of England get their income from a number of sources, including the Sovereign Grant from the UK Parliament (a percentage of the annual profits of the Crown Estate), revenues from the Duchies of Lancaster and Cornwall , a parliamentary annuity , and income from private investments .\n",
      "Arafat/Mohamed: 0.19047619047619047\n",
      "Arafat/Eva Maria: 0.9791666666666666\n",
      "--\n",
      "who was the doctor that led the research on cte and was criticized by the nfl\n",
      "Joekie: Bennet Omalu published his findings on  ``Chronic Traumatic Encephalopathy in a National Football League Player.'' in the journal of Neurosurgery.  The paper received little attention initially , but members of the NFL 's Mild Traumatic Brain Injury Committee later called for its retraction, characterizing Omalu's description of CTE as \"completely wrong\".\n",
      "Eva Maria: Bennet Omalu and colleagues of the Department of Pathology at the University of Pittsburgh published his findings on ``Chronic Traumatic Encephalopathy in a National Football League Player.'' in the journal of Neurosurgery. In 2006 members of the NFL 's Mild Traumatic Brain Injury ( MTBI ) Committee later called for its retraction,, calling the paper completely wrong.\n",
      "['missing info']\n",
      "Joekie/Eva Maria: 0.6981132075471698\n",
      "--\n",
      "how many countries in africa have a monarchy\n",
      "Joekie: There are many monarchies in Africa, only three are currently sovereign , while the remaining are sub-national monarchies .  Two of these are constitutional monarchies ( Lesotho and Morocco ) , and one is an absolute monarchy ( Swaziland ).\n",
      "Mohamed: There are many monarchies in Africa , including states , territories and countries.\n",
      "['paraphrase', 'extra info']\n",
      "Joekie/Mohamed: 0.3111111111111111\n",
      "--\n",
      "who are the characters in valley of the dolls based on\n",
      "Joekie: In Valley of the Dolls characters were based on such famous figures as Judy Garland , Carole Landis , Dean Martin , and Ethel Merman .  Susann insisted that she unconsciously picked certain people .\n",
      "Mohamed: Valley of the Dolls is considered to be a roman a clef , with its characters based on famous figures as Judy Garland , Carole Landis , Dean Martin , and Ethel Merman, although the author of the novel insisted that the characters were picked up unconsciously.\n",
      "['paraphrase']\n",
      "Joekie/Mohamed: 0.6027397260273971\n",
      "Sara: In Valley of the Dolls characters were based on such famous figures as Judy Garland , Carole Landis , Dean Martin , and Ethel Merman . \n",
      "Sara/Joekie: 0.5846153846153846\n",
      "Sara/Mohamed: 0.846153846153846\n",
      "--\n",
      "who was glumdalclitch how did she help gulliver\n",
      "Chie: Glumdalclitch is a nine-year-old daughter of a giant farmer, a child \"not above forty feet high, being little for her age.\"  She makes Gulliver her pet.   Gulliver grows very fond of the girl, and gives her the pet name of Glumdalclitch who is a skilled seamstress with a talent for making dolls' clothes.\n",
      "Mohamed: Glumdalclitch is a nine-year-old,  forty feet tall daughter of the farmer who captured Gulliver. She made Gulliver her pet, created a bed for him out of a travel case and made him clothes.\n",
      "['grammar', 'paraphrase', 'extra info', 'missing info']\n",
      "Chie/Mohamed: 0.35555555555555557\n",
      "Hans: Glumdalclitch is a 40 foot high, nine-year-old daughter of a giant farmer that received Gulliver as a pet from her father. A skilled streamstress, she makes clothes for Gulliver.\n",
      "****\n",
      "Hans/Chie: 0.393939393939394\n",
      "Hans/Mohamed: 0.41860465116279066\n",
      "--\n",
      "who was the ideal intended audience for romanticism\n",
      "Eva Maria: It had a significant and complex effect on politics , with romantic thinkers influencing liberalism , radicalism , conservatism and nationalism .\n",
      "--\n",
      "facts about the great pyramid of giza built\n",
      "Hee Dong: Initially at 146.5 metres ( 481 feet ) , the Great Pyramid was the tallest man - made structure in the world for more than 3,800 years. Originally, the Great Pyramid was covered by casing stones that formed a smooth outer surface; what is seen today is the underlying core structure. Some of the casing stones that once covered the structure can still be seen around the base. Most accepted construction hypotheses are based on the idea that it was built by moving huge stones from a quarry and dragging and lifting them into place.\n",
      "Mohamed: Initially at 146.5 metres ( 481 feet ) , the Great Pyramid was the tallest man - made structure in the world for more than 3,800 years. It was originally covered by casing stones, some of which can still be found near the base, that formed a smooth outer surface.\n",
      "['paraphrase', 'extra info']\n",
      "Hee Dong/Mohamed: 0.5531914893617021\n",
      "Avi: The pyramid of Giza was built as a tomb over a 10 to 20 - year period concluding around 2560 BC .\n",
      "****\n",
      "Avi/Hee Dong: 0.11764705882352941\n",
      "Avi/Mohamed: 0.10619469026548671\n",
      "--\n",
      "when does an eclipse of the moon occur\n",
      "Joekie: A lunar eclipse occurs when the Moon passes directly behind the Earth into its umbra ( shadow ) ,  this only occurs  when the sun , Earth , and moon are aligned. Hence , a lunar eclipse can occur only the night of a full moon .\n",
      "Mohamed: A lunar eclipse occurs when the Moon passes directly behind the Earth into its umbra. This can occur only when the sun , Earth , and moon are aligned exactly , or very closely so , with the Earth in the middle which is only possible on the night of a full moon .\n",
      "['paraphrase', 'missing info']\n",
      "Joekie/Mohamed: 0.7191011235955055\n",
      "--\n",
      "where do the clicks in south african languages come from\n",
      "Eva Maria: Xhosa is a Nguni Bantu language with click consonants. It is a tonal language ; the same sequence of consonants and vowels can have different meanings , depending on intonation .\n",
      "Mohamed: South African languages are tonal languages, where the same sequence of consonants and vowels can have different meanings, depending on intonation. These languages are known to have click consonants, which are behind the clicks.\n",
      "['paraphrase']\n",
      "Eva Maria/Mohamed: 0.5483870967741935\n",
      "--\n",
      "what is the historical significance of the townshend act\n",
      "Chie: The Townshend Acts were a series of British acts passed beginning in 1767 and relating to the British American colonies in North America.   The Townshend Acts were met with resistance in the colonies, prompting the occupation of Boston by British troops in 1768, which eventually resulted in the Boston Massacre of 1770.\n",
      "Mohamed: The Townshend Acts were passed to raise revenue in the colonies to pay governors and judges salaries and keep them loyal to Great Britain , to enforce compliance with trade regulations more effectively, to punish the province of New York for failing to comply with the 1765 Quartering Act , and to establish the precedent that the British Parliament had the right to tax the colonies .\n",
      "['extra info', 'missing info']\n",
      "Chie/Mohamed: 0.25862068965517243\n",
      "--\n",
      "where is the world's fresh water stored\n",
      "Hee Dong: Only 2.5 -- 2.75 % is fresh water , including 1.75 -- 2 % frozen in glaciers , ice and snow , 0.5 -- 0.75 % as fresh groundwater and soil moisture , and less than 0.01 % of it as surface water in lakes , swamps and rivers. Freshwater lakes contain about 87 % of this fresh surface water , including 29 % in the African Great Lakes , 22 % in Lake Baikal in Russia , 21 % in the North American Great Lakes , and 14 % in other lakes. In areas with no fresh water on the ground surface , fresh water derived from precipitation may , because of its lower density , overlie saline ground water in lenses or layers. Most of the world 's fresh water is frozen in ice sheets.\n",
      "Mohamed: The world's fresh water is stored and can be extracted from glaciers , ice and snow ,  groundwater, soil moisture , lakes, swamps, rivers,  atmosphere and precipitation.\n",
      "['extra info', 'missing info']\n",
      "Hee Dong/Mohamed: 0.19444444444444445\n",
      "Avi: Only 2.5 -- 2.75 % of all the water on Earth is fresh water , including 1.75 -- 2 % frozen in glaciers , ice and snow , 0.5 -- 0.75 % as fresh groundwater and soil moisture , and less than 0.01 % of it as surface water in lakes , swamps and rivers . Freshwater lakes contain about 87 % of this fresh surface water , including 29 % in the African Great Lakes , 22 % in Lake Baikal in Russia , 21 % in the North American Great Lakes , and 14 % in other lakes . Most of the world 's fresh water is frozen in ice sheets .\n",
      "Avi/Hee Dong: 0.23140495867768596\n",
      "Avi/Mohamed: 0.8372093023255813\n",
      "--\n",
      "what is the cost of a project and how one can calculate it\n",
      "Chie: Project managers must understand several basic principles of cost management to be effective in managing project cost.  Important concepts include profits and profit margins, life cycle costing, cash flow analysis, sunk cost, and learning curve theory.  Planning cost management involves determining the policies, procedures, and documentation that will be used for planning, executing, and controlling project cost.  There are several types of cost estimates, including rough order of magnitude (ROM), budgetary, and definitive.  Each type of estimate is done during different stages of the project life cycle, and each has a different level of accuracy.  Several tool and techniques can help you develop cost estimates, including analogous estimating, bottom-up estimating, parametric estimating, and computerized tools.  Determining the budget involves allocating costs to individual work items over time.   Controlling cost includes monitoring cost performance, reviewing changes, and notifying project stakeholders of changes related to cost.  Earned value management is an important method used for measuring project performance.  Earned value management integrates scope, cost, and schedule information.   Several software products can assists with project cost management.  Enterprise project management software and portfolio management software can help managers evaluate data on multiple projects.\n",
      "Mohamed: The cost of a project is estimated as part of the project cost management, which involves profits, profit margins, life cycle costing, cash flow analysis, sunk cost , and learning curve theory. There are several types of cost estimates , including rough order of magnitude, budgetary , and definitive. Estimating the cost is done through several tool and techniques, including analogous estimating , bottom - up estimating , parametric estimating , and computerized tools .\n",
      "['paraphrase', 'extra info', 'missing info']\n",
      "Chie/Mohamed: 0.40310077519379844\n",
      "Avi: Cost of a project is estimated via profits and profit margins , life cycle costing , cash flow analysis , sunk cost , and learning curve theory . The cost is calculated via analogous estimating , bottom - up estimating , parametric estimating , and computerized tools . Determining the budget involves allocating costs to individual work items over time . Controlling cost includes monitoring cost performance , reviewing changes , and notifying project stakeholders of changes related to cost .\n",
      "****\n",
      "Avi/Chie: 0.5074626865671642\n",
      "Avi/Mohamed: 0.46511627906976744\n",
      "--\n",
      "where are tanks most widely used in india why\n",
      "Eva Maria: Tanks are part of an ancient tradition of harvesting and preserving the local rainfall and water from streams and rivers for later use , primarily for agriculture and drinking water.\n",
      "Tank use is especially critical in parts of South India without perennial rainfall where water supply replenishment is dependent on a cycle of dry seasons alternating with monsoon seasons .\n",
      "Salim: Tanks used for harvesting rainfall are used especiallyin parts of South India without perennial rainfall where water supply replenishment is dependent on a cycle of dry seasons alternating with monsoon seasons .\n",
      "Salim/Eva Maria: 0.08163265306122448\n",
      "Salim/Chie: 0.6067415730337079\n",
      "--\n",
      "what do the colours on the olympic rings represent\n",
      "Mohamed: The colors of the rings together with the white of the background included the colors composing every competing nation's flag at the time when the symbol was designed by Baron Pierre de Coubertin in 1912.\n",
      "Chie: The rings are five interlocking rings , colored blue , yellow , black , green and red on a white field, representing the five participating continents : Africa , Asia , America , Australia and Europe.\n",
      "['paraphrase', 'extra info', 'missing info']\n",
      "Mohamed/Chie: 0.125\n",
      "Sara: The colors of the rings together with the white of the background included the colors composing every competing nation's flag.\n",
      "Sara/Mohamed: 0.16326530612244897\n",
      "Sara/Chie: 0.7368421052631579\n",
      "--\n",
      "who sang joshua fought the battle of jericho\n",
      "Hee Dong: The first recorded version of Joshua Fit the Battle of Jericho was by Harrod 's Jubilee Singers , on Paramount Records No. 12116. Later recordings include those by Paul Robeson ( 1925 ) , Mahalia Jackson ( 1958 ) , Clara Ward , and Hugh Laurie ( 2011 ) among many others.\n",
      "Chie: The first recorded version of Joshua Fit the Battle of Jericho was by Harrod 's Jubilee Singers.  Later recordings include those by Paul Robeson , Mahalia Jackson , Clara Ward , and Hugh Laurie among many others.\n",
      "['extra info']\n",
      "Hee Dong/Chie: 0.8947368421052632\n",
      "--\n",
      "what is the difference between senate and house of rep\n",
      "Hee Dong: The members of the House of Representatives serve two - year terms representing the people of a single constituency, known as a `` district ''. Congressional districts are apportioned to states by population using the United States Census results. Each state, regardless of population or size, has two senators. Each senator is elected at - large in their state for a six - year term, with terms staggered, so every two years approximately one - third of the Senate is up for election.\n",
      "Avi: The members of the House of Representatives serve two - year terms representing the people of a single constituency , known as a `` district '' . Each senator is elected at - large in their state for a six - year term , with terms staggered , so every two years approximately one - third of the Senate is up for election . Congressional districts are apportioned to states by population using the United States Census results , provided that each state has at least one congressional representative . Each state , regardless of population or size , has two senators .\n",
      "Avi/Hee Dong: 0.08264462809917354\n",
      "Avi/Chie: 0.646341463414634\n",
      "--\n",
      "who gets the money from go fund me\n",
      "Hee Dong: GoFundMe allows users to create their own website to describe what they are raising money for. GoFundMe generates revenue by automatically deducting a 5 % fee from each donation users receive. In addition to the 5 % that GoFundMe deducts from each transaction, WePay collects 2.9 % and $0.30 from each GoFundMe transaction.\n",
      "Chie: GoFundMe allows users to create their own website to describe what they are raising money for. GoFundMe automatically deducts a 5 % fee from each donation users receive. In addition to the 5 %, WePay collects 2.9 % and $0.30 from each GoFundMe transaction.\n",
      "['extra info']\n",
      "Hee Dong/Chie: 0.9052631578947368\n",
      "--\n",
      "what do you call the top of a column\n",
      "Joekie: At the top of the shaft is a capital , upon which the roof or other architectural elements rest , this decorative element is known as a finial .\n",
      "Chie: At the top of the shaft is a capital , upon which the roof or other architectural elements rest.  In the case of free - standing columns , the decorative elements atop the shaft are known as a finial .\n",
      "['missing info']\n",
      "Joekie/Chie: 0.7741935483870968\n",
      "--\n",
      "how many in n out burgers are in texas\n",
      "Eva Maria: There are 21 restaurant locations in the Dallas -- Fort Worth area , and four in the Austin area .\n",
      "The fall of 2014 saw the restaurant open its 22nd Texas location in Killeen .\n",
      "Chie: There are 21 restaurant locations in the Dallas -- Fort Worth area , and four in the Austin area . The restaurant opened its 22nd Texas location in Killeen in 2014 . They added first locations each in San Antonio and Waco later.\n",
      "['paraphrase', 'missing info']\n",
      "Eva Maria/Chie: 0.7428571428571428\n",
      "Sara: There are at least 24 restaurant locations in Texas including Dallas -- Fort Worth, Austin, San Antonio, and Waco. There are plans to expand to Houston as well.\n",
      "****\n",
      "Sara/Eva Maria: 0.3939393939393939\n",
      "Sara/Chie: 0.3103448275862069\n",
      "--\n",
      "what does the democratic republic of congo flag represent\n",
      "Eva Maria: The national flag of the Democratic Republic of the Congo represents blue for peace, red for `` the blood of the country 's martyrs '' , yellow for the country 's wealth ; and a star for a radiant future for the country .\n",
      "--\n",
      "who is the guy playing the guitar on wwe\n",
      "Hee Dong: On April 10, 2017, Elias Samson debuted on Raw, appearing on the stage briefly during an eight - man tag team match. Samson continued to appear in the background playing this guitar during backstage segments over the next few weeks. On the June 19 episode of Raw, Samson was performing a song in the ring.\n",
      "Chie: On April 10, 2017, Elias Samson debuted on Raw and continued to appear in the background playing this guitar during backstage segments over the next few weeks. Later that week of July 24, WWE began referring to Samson only by his first name of Elias.\n",
      "['paraphrase', 'extra info', 'missing info']\n",
      "Hee Dong/Chie: 0.5656565656565656\n",
      "Salim: Elias Samson who joined the RAW program on WWE in 2017 played the guitar in background segments for several weeks\n",
      "****\n",
      "Salim/Hee Dong: 0.24615384615384614\n",
      "Salim/Chie: 0.24324324324324323\n",
      "--\n",
      "when does izzie get sick in grey's\n",
      "Hee Dong: In the fifth season, she discovers she has metastatic melanoma (Stage IV) which has spread to her liver, skin, and brain, causing the hallucination.\n",
      "--\n",
      "where was king arthur and the legend of the sword filmed\n",
      "Eva Maria: King Arthur: Legend of the Sword was filmed in Windsor Great Park, North Wales, Snowdonia , Tryfan , Nant Gwynant near Beddgelert and Capel Curig , Sieldaig , Loch Torridon and Applecross areas of Wester Ross in the Scottish Highlands, as well as the Quiraing on the Isle of Skye and Warner Brothers Studios in Leavesden.\n",
      "Hee Dong: King Arthur: Legend of the Sword was filmed in Windsor Great Park, in North Wales, in Snowdonia, in the Shieldaig , Loch Torridon, Applecross areas of Wester Ross in the Scottish Highlands, at The Quiraing on the Isle of Skye, and Warner Bros. Studios , Leavesden.\n",
      "['missing info']\n",
      "Eva Maria/Hee Dong: 0.7708333333333333\n",
      "--\n",
      "which stage of the cell cycle is variable\n",
      "Eva Maria: The first phase within interphase , from the end of the previous M phase until the beginning of DNA synthesis , is called G ( G indicating gap ) .\n",
      "The duration of G is highly variable , even among different cells of the same species .\n",
      "Hee Dong: The duration of G (G indicating gap), the first phase within interphase, is highly variable, even among different cells of the same species.\n",
      "['paraphrase']\n",
      "Eva Maria/Hee Dong: 0.5714285714285714\n",
      "Sara: The growth phase, G (indicating gap) which is , from the end of the previous M phase until the beginning of DNA synthesis is highly variable\n",
      "Sara/Eva Maria: 0.37499999999999994\n",
      "Sara/Hee Dong: 0.5846153846153846\n",
      "--\n",
      "what is the meaning of rolls royce logo\n",
      "Joekie: The Spirit of Ecstasy  carries with it a story about secret passion between Montagu , a pioneer of the automobile movement , and editor of The Car Illustrated magazine from 1902 , and the model for the emblem , Eleanor Velasco Thornton .  Their secret love was to remain hidden for more than a decade because Montagu was married and Eleanor was of an impoverished social status.\n",
      "--\n",
      "who held the power in the articles of confederation\n",
      "Mohamed: The federal government held the powers in the Articles of Confederation, which colonies had recognized as belonging to king and parliament.\n",
      "Hee Dong: The federal government received only Articles of Confederation powers which the colonies had recognized as belonging to king and parliament.\n",
      "['extra info']\n",
      "Mohamed/Hee Dong: 0.7804878048780488\n",
      "Hans: In the Article of Confederation, the original 13 states were legally recognized to be independent and sovereign, and only the powers that were identified as belonging to the king and parliament were granted to the Federal Government.\n",
      "****\n",
      "Hans/Mohamed: 0.4210526315789474\n",
      "Hans/Hee Dong: 0.41379310344827586\n",
      "--\n",
      "why is phosphofructokinase a rate-limiting enzyme of glycolysis\n",
      "Mohamed: Phosphofructokinase is a rate-limiting enzyme of glycolysis because of its ablity to regulate glycolysis through allosteric inhibition which enables the cell to increase or decrease the rate of glycolysis in response to the cell 's energy requirements .\n",
      "Hee Dong: Because phosphofructokinase ( PFK ) catalyzes the ATP - dependent phosphorylation to convert fructose - 6 - phosphate into fructose 1 , 6 - bisphosphate and ADP , it is one of the key regulatory and rate limiting steps of glycolysis.\n",
      "['missing info']\n",
      "Mohamed/Hee Dong: 0.1971830985915493\n",
      "--\n",
      "when does the next episode of code black come on\n",
      "Joekie: Code Black was an American medical drama that was canceled by CBS on May 24th, 2018, after three seasons.\n",
      "Hee Dong: On May 24 , 2018 CBS canceled the Code Black series after three seasons.\n",
      "['extra info']\n",
      "Joekie/Hee Dong: 0.37499999999999994\n",
      "--\n",
      "when was five nights at freddy's made\n",
      "Chie: The first Five Nights at Freddy's game was released via Desura on August 8, 2014.  The games that followed were released on November 10, 2014; March 2, 2015; July 23, 2015; and October 7, 2016, respectively.\n",
      "--\n",
      "where did i'm going to disney world start\n",
      "Joekie: `` I 'm going to Disney World ! '' is an advertising slogan used in a series of television commercials by The Walt Disney Company that began airing in 1987 .\n",
      "Hee Dong: `` I 'm going to Disney World ! '' is advertising slogan used in television commercials, began airing in 1987, by The Walt Disney Company.\n",
      "['paraphrase']\n",
      "Joekie/Hee Dong: 0.7346938775510203\n",
      "--\n",
      "describe the impact the minnie ball had on the battlefield during the civil war\n",
      "Joekie: The development of the Minié ball was significant because it was the first projectile which was small enough to be easily put down the barrel of a rifled long gun . Prior to the Minié ball , bullets had to be jammed down the rifle barrel , sometimes with a mallet , and after a relatively small number of shots , gunpowder residue built up in the spiral grooves , which then had to be cleaned out .\n",
      "Hee Dong: The development of the Minié ball was significant because it was the first projectile which was small enough to be easily put down the barrel of a rifled long gun.\n",
      "['extra info']\n",
      "Joekie/Hee Dong: 0.5940594059405941\n",
      "--\n",
      "where did the tradition of black eyed peas on new year's come from\n",
      "Eva Maria: In one Southern tradition , black - eyed peas were a symbol of emancipation for African - Americans who had previously been enslaved , and who after the Civil War were officially freed on New Years Day .\n",
      "Hee Dong: Two popular explanations for the South 's association with peas and good luck dates back to the American Civil War.  The first is associated with General William T. Sherman 's march of the Union Army to the sea , during which they pillaged the Confederates ' food supplies. In another Southern tradition , black - eyed peas was a symbol of emancipation for African - Americans who had previously been enslaved , and who after the Civil War were officially freed on New Years Day.\n",
      "['missing info']\n",
      "Eva Maria/Hee Dong: 0.5535714285714286\n",
      "Hans: There are two popular explanations for the South's association with peas and good luck: one is centered on a myth of the Conferederate General  William T. Sherman 's march of the Union Army to the sea , during which they pillaged the Confederates ' food supplies around New Year's Eve 1965. The other is centered around the official emancipation of slaves on New Year's Eve after the Civil War.\n",
      "****\n",
      "Hans/Eva Maria: 0.5369127516778524\n",
      "Hans/Hee Dong: 0.15533980582524273\n",
      "--\n",
      "Hee Dong: -0.05973902978929881\n",
      "Eva Maria: 0.42612076676187505\n",
      "Mohamed: 0.1676418572708628\n",
      "Chie: 0.31517547703297255\n",
      "Joekie: 0.13513125111769492\n"
     ]
    }
   ],
   "source": [
    "\n",
    "improvement =  {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0}\n",
    "needs_improvement =  {\"Hee Dong\": 0, \"Eva Maria\": 0, \"Mohamed\": 0, \"Chie\": 0, \"Joekie\": 0}\n",
    "\n",
    "all_output = []\n",
    "for index, row in new_annotations.iterrows():\n",
    "    output = []\n",
    "    print(row['data']['question'])\n",
    "    output.append(row['data']['id'])\n",
    "    output.append(row['data']['question'])\n",
    "    gold_annotation = gold_annotations[gold_annotations['ID'] == int(row['data']['id'])]\n",
    "\n",
    "    sentences = \"\"\n",
    "    judgement = row['results']['judgments'][0]\n",
    "    input = row['data']\n",
    "    for sentence in row['data']['long_answer']:\n",
    "        selected = []\n",
    "        if 'long_answer' in input and input['selected'][input['long_answer'].index(sentence)] == 'True':\n",
    "            selected.append(\"1\")\n",
    "        if 'paragraph_sentences' in judgement['data'] and sentence in judgement['data']['paragraph_sentences']:\n",
    "            selected.append(\"2\")\n",
    "        if len(selected) > 0:\n",
    "            sentences += \"SELECTED \" + str(selected) + \": \"\n",
    "        sentences += sentence + \"\\n\"\n",
    "\n",
    "    answer1 = row['data']['answer']\n",
    "    output.append(sentences)\n",
    "    output.append(row['data']['worker'])\n",
    "    output.append(answer1)\n",
    "    print(row['data']['worker'] + \": \" + answer1)\n",
    "    output.append(name[row['results']['judgments'][0]['worker_id']])\n",
    "    output.append(row['results']['judgments'][0]['data']['did_you_need_to_edit_the_answer'])\n",
    "    if 'update_the_answer_here_if_needed' in row['results']['judgments'][0]['data']:\n",
    "        answer2 = row['results']['judgments'][0]['data']['update_the_answer_here_if_needed']\n",
    "        print(name[row['results']['judgments'][0]['worker_id']] + \": \" + answer2)\n",
    "        if 'did_you_need_to_edit_the_answer' in row['results']['judgments'][0]['data']:\n",
    "            print(row['results']['judgments'][0]['data']['did_you_need_to_edit_the_answer'])\n",
    "        rouge1 = rougeL(answer1, answer2)['rougeL'].fmeasure\n",
    "        print(row['data']['worker'] + \"/\" + name[row['results']['judgments'][0]['worker_id']] + \": \" + str(rouge1))\n",
    "        output.append(answer2)\n",
    "        output.append(rouge1)\n",
    "    else:\n",
    "        output.append(\"\")\n",
    "        output.append(\"\")\n",
    "    gold_answer = gold_annotation['Rewritten Answer'].iloc[0]\n",
    "    output.append(gold_annotation['Assigned To'].iloc[0])\n",
    "    if isinstance(gold_answer, str):\n",
    "        needs_improvement[name[row['results']['judgments'][0]['worker_id']]] += 1\n",
    "        print(gold_annotation['Assigned To'].iloc[0] + \": \" + gold_answer)\n",
    "        rouge2 = rougeL(answer2, gold_answer)['rougeL'].fmeasure\n",
    "        rouge3 = rougeL(answer1, gold_answer)['rougeL'].fmeasure\n",
    "        output.append(gold_answer)\n",
    "        output.append(rouge2)\n",
    "        output.append(rouge3)\n",
    "        # if rouge3 > rouge2:\n",
    "        improvement[name[row['results']['judgments'][0]['worker_id']]] += rouge3 - rouge2\n",
    "        if rouge3 -.2 < rouge2:\n",
    "            print(\"****\")\n",
    "        print(gold_annotation['Assigned To'].iloc[0] + \"/\" + row['data']['worker'] + \": \" + str(rouge2))\n",
    "        print(gold_annotation['Assigned To'].iloc[0] + \"/\" + name[row['results']['judgments'][0]['worker_id']] + \": \" + str(rouge3))\n",
    "    else:\n",
    "        output.append(\"\")\n",
    "        output.append(\"\")\n",
    "        output.append(\"\")\n",
    "    print('--')\n",
    "    all_output.append(output)\n",
    "\n",
    "for annotator in improvement:\n",
    "    if improvement[annotator] != 0:\n",
    "        print(annotator + \": \" + str(improvement[annotator]/needs_improvement[annotator]))\n",
    "    else:\n",
    "        print(annotator + \": 0/\" + str(needs_improvement[annotator]))\n",
    "\n",
    "with pd.ExcelWriter(\"/dccstor/srosent2/generative/appen/job_2035917.non_consecutive_followup_round2.xlsx\", engine='xlsxwriter') as writer:\n",
    "    df = pd.DataFrame(all_output)\n",
    "    df.to_excel(writer, sheet_name='Sheet1')\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "    cell_format = workbook.add_format({'text_wrap': True})\n",
    "    worksheet.set_column('A:Z', cell_format=cell_format)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "primeqa4.24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d32919132f66e210a1b695050b8f424e37551142a4189348e2af6a594afe21a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

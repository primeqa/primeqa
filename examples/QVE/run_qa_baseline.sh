#! /bin/bash

dataset_name=HotpotQA
SOURCE_QA_CKPT_DIR=checkpoints/QA_source_only/

echo "##########################################################################"
echo "Source Only Baseline: Pretrain QA model on SQuAD and test it on $dataset_name"
echo "##########################################################################"


if ! [ -d "$SOURCE_QA_CKPT_DIR" ]; then
  echo "##########################################################################"
  echo "$SOURCE_QA_CKPT_DIR does not exist. Begin Training."
  echo "##########################################################################"

    python primeqa/mrc/run_mrc.py --model_name_or_path bert-base-uncased \
        --train_file data/SQuAD.train.jsonl \
        --eval_file data/"$dataset_name".test.jsonl \
        --preprocessor primeqa.mrc.processors.preprocessors.squad.SQUADPreprocessor \
        --postprocessor primeqa.mrc.processors.postprocessors.squad.SQUADPostProcessor \
        --eval_metrics SQUAD \
        --max_seq_length 384 \
        --output_dir $SOURCE_QA_CKPT_DIR \
        --learning_rate 3e-5 \
        --do_train --do_eval --per_device_train_batch_size 12 \
        --per_device_eval_batch_size 64 \
        --save_steps 50000 \
        --overwrite_output_dir --num_train_epochs 3.0 \
        --overwrite_cache
fi

  echo "##########################################################################"
  echo "Train QA model: Source + Target Dev"
  echo "##########################################################################"

      python primeqa/mrc/run_mrc.py --model_name_or_path $SOURCE_QA_CKPT_DIR \
        --train_file data/"$dataset_name".sample.dev.jsonl \
        --eval_file data/"$dataset_name".test.jsonl \
        --preprocessor primeqa.mrc.processors.preprocessors.squad.SQUADPreprocessor \
        --postprocessor primeqa.mrc.processors.postprocessors.squad.SQUADPostProcessor \
        --eval_metrics SQUAD \
        --max_seq_length 384 \
        --output_dir checkpoints/QA_"$dataset_name"_Source_TargetDev \
        --learning_rate 3e-5 \
        --do_train --do_eval --per_device_train_batch_size 12 \
        --per_device_eval_batch_size 64 \
        --save_steps 50000 \
        --overwrite_output_dir --num_train_epochs 3.0 \
        --overwrite_cache

  echo "##########################################################################"
  echo "Train QA model: Source + Target Synthetic Data (generated by Finetuned QG)"
  echo "##########################################################################"

  python primeqa/mrc/run_mrc.py --model_name_or_path $SOURCE_QA_CKPT_DIR \
      --train_file data/"$dataset_name"_QG/"$dataset_name".train.targetfinedtuned.gen.jsonl \
      --eval_file data/"$dataset_name".test.jsonl \
      --preprocessor primeqa.mrc.processors.preprocessors.squad.SQUADPreprocessor \
      --postprocessor primeqa.mrc.processors.postprocessors.squad.SQUADPostProcessor \
      --eval_metrics SQUAD \
      --max_seq_length 384 \
      --output_dir checkpoints/QA_"$dataset_name"_Source_Synthetic \
      --learning_rate 3e-5 \
      --do_train --do_eval --per_device_train_batch_size 12 \
      --per_device_eval_batch_size 64 \
      --save_steps 50000 \
      --overwrite_output_dir --num_train_epochs 2.0 \
      --overwrite_cache

  echo "##########################################################################"
  echo "Train QA model: Source + Target Synthetic Data (generated by Finetuned QG) + Target Dev"
  echo "##########################################################################"

    python primeqa/mrc/run_mrc.py --model_name_or_path checkpoints/QA_"$dataset_name"_Source_Sythetic \
      --train_file  data/"$dataset_name".sample.dev.jsonl \
      --eval_file data/"$dataset_name".test.jsonl \
      --preprocessor primeqa.mrc.processors.preprocessors.squad.SQUADPreprocessor \
      --postprocessor primeqa.mrc.processors.postprocessors.squad.SQUADPostProcessor \
      --eval_metrics SQUAD \
      --max_seq_length 384 \
      --output_dir checkpoints/QA_"$dataset_name"_Source_TargetDev \
      --learning_rate 3e-5 \
      --do_train --do_eval --per_device_train_batch_size 12 \
      --per_device_eval_batch_size 64 \
      --save_steps 50000 \
      --overwrite_output_dir --num_train_epochs 2.0 \
      --overwrite_cache
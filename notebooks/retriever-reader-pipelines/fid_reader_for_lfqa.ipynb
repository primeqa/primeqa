{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for creating a ColBERT index and for training an FiD model for KILT-ELI5 can be found [here](https://github.com/primeqa/primeqa/blob/main/examples/lfqa/README.md)<br>  \n",
    "The ColBERT index is based on the KILT-Wikipedia corpus and an FiD reader is trained on KILT-ELI5.<br>\n",
    "This code requires 300GB memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-11T12:52:05.361802Z",
     "iopub.status.busy": "2022-11-11T12:52:05.361628Z",
     "iopub.status.idle": "2022-11-11T13:09:30.478107Z",
     "shell.execute_reply": "2022-11-11T13:09:30.477697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"time\":\"2023-02-16 20:33:01,912\", \"name\": \"faiss.loader\", \"level\": \"INFO\", \"message\": \"Loading faiss with AVX2 support.\"}\n",
      "{\"time\":\"2023-02-16 20:33:02,177\", \"name\": \"faiss.loader\", \"level\": \"INFO\", \"message\": \"Successfully loaded faiss with AVX2 support.\"}\n",
      "[Feb 16, 20:33:07] #> base_config.py from_path /dccstor/mabornea1/kilt-wikipedia-test/colbert_ir/kilt_wikipedia_eli5_dev_exp/indexes//kilt_wikipedia_eli5_dev_indname/metadata.json\n",
      "[Feb 16, 20:33:07] #> base_config.py from_path args loaded! \n",
      "[Feb 16, 20:33:07] #> base_config.py from_path args replaced ! \n",
      "[Feb 16, 20:33:15] #>>>>> at ColBERT name (model type) : /dccstor/colbert-ir/franzm/experiments/oct2_7_12_1.5e-06/none/2022-10/09/15.21.39/checkpoints/colbert.dnn.batch_91287.model\n",
      "[Feb 16, 20:33:15] #>>>>> at BaseColBERT name (model type) : /dccstor/colbert-ir/franzm/experiments/oct2_7_12_1.5e-06/none/2022-10/09/15.21.39/checkpoints/colbert.dnn.batch_91287.model\n",
      "[Feb 16, 20:33:24] factory model type: xlm-roberta-large\n",
      "[Feb 16, 20:33:38] get query model type: xlm-roberta-large\n",
      "[Feb 16, 20:33:39] get doc model type: xlm-roberta-large\n",
      "[Feb 16, 20:34:11] #> Loading codec...\n",
      "[Feb 16, 20:34:11] #> base_config.py from_path /dccstor/mabornea1/kilt-wikipedia-test/colbert_ir/kilt_wikipedia_eli5_dev_exp/indexes//kilt_wikipedia_eli5_dev_indname/metadata.json\n",
      "[Feb 16, 20:34:11] #> base_config.py from_path args loaded! \n",
      "[Feb 16, 20:34:11] #> base_config.py from_path args replaced ! \n",
      "[Feb 16, 20:34:11] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Feb 16, 20:34:27] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Feb 16, 20:34:28] #> Loading IVF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14635it [00:00, 151857.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 16, 20:34:37] #> XMLR QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "[Feb 16, 20:34:37] #> Input: $ What causes the trail behind jets at high altitude?, \t\t True, \t\t None\n",
      "[Feb 16, 20:34:37] #> Output IDs: torch.Size([32]), tensor([     0,   9748,   4865, 113660,     70, 141037,  50155,     55,    933,\n",
      "            99,  11192,    144,  35810,     32,      2,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1])\n",
      "[Feb 16, 20:34:37] #> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "[Feb 16, 20:34:37] #>>>> colbert query ==\n",
      "[Feb 16, 20:34:37] #>>>>> input_ids: torch.Size([32]), tensor([     0,   9748,   4865, 113660,     70, 141037,  50155,     55,    933,\n",
      "            99,  11192,    144,  35810,     32,      2,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 16, 20:34:38] #>>>> before linear query ==\n",
      "[Feb 16, 20:34:38] #>>>>> Q: torch.Size([32, 1024]), tensor([[-0.9052, -0.0412,  1.6951,  ..., -2.0517, -0.3507,  0.3122],\n",
      "        [-0.6221, -0.3006,  0.1237,  ...,  0.0440, -1.5914, -0.2277],\n",
      "        [-0.4957, -0.5071, -0.0034,  ...,  0.1966, -1.3050, -0.4422],\n",
      "        ...,\n",
      "        [-1.5236, -0.1908,  0.4288,  ...,  0.2573, -1.6916, -0.0264],\n",
      "        [-1.5236, -0.1908,  0.4288,  ...,  0.2573, -1.6916, -0.0264],\n",
      "        [-1.5236, -0.1908,  0.4288,  ...,  0.2573, -1.6916, -0.0264]],\n",
      "       device='cuda:0')\n",
      "[Feb 16, 20:34:38] #>>>>> self.linear query : Parameter containing:\n",
      "tensor([[-0.0301, -0.0307, -0.0115,  ..., -0.0231, -0.0023, -0.0216],\n",
      "        [ 0.0053,  0.0023, -0.0308,  ...,  0.0108,  0.0011,  0.0201],\n",
      "        [-0.0220,  0.0370,  0.0339,  ..., -0.0023, -0.0172,  0.0244],\n",
      "        ...,\n",
      "        [ 0.0222,  0.0115, -0.0246,  ...,  0.0389, -0.0034, -0.0165],\n",
      "        [-0.0146,  0.0392,  0.0131,  ..., -0.0055,  0.0219, -0.0368],\n",
      "        [ 0.0071,  0.0256, -0.0346,  ...,  0.0322,  0.0370,  0.0437]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "[Feb 16, 20:34:38] #>>>> colbert query ==\n",
      "[Feb 16, 20:34:38] #>>>>> Q: torch.Size([32, 128]), tensor([[-0.6113, -0.0486, -0.0424,  ..., -0.3491, -0.5215, -0.3496],\n",
      "        [ 0.1202, -1.1738,  0.6592,  ..., -0.1731, -0.6763,  0.7427],\n",
      "        [ 0.0669, -1.2090,  0.6987,  ..., -0.3379, -0.7612,  0.8989],\n",
      "        ...,\n",
      "        [-0.2238, -0.7944,  0.3328,  ...,  0.1307, -0.7886,  0.1250],\n",
      "        [-0.2238, -0.7944,  0.3328,  ...,  0.1307, -0.7886,  0.1250],\n",
      "        [-0.2238, -0.7944,  0.3328,  ...,  0.1307, -0.7886,  0.1250]],\n",
      "       device='cuda:0', dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.05it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on eval dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BartFiDModelForDownstreamTasks.forward` and have been ignored: example_id. If example_id are not expected by `BartFiDModelForDownstreamTasks.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 14:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": {\n",
      "        \"answers\": {\n",
      "            \"text\": \"The water vapor in the exhaust from the engine is mixed with the cold air, and condenses into ice crystals. \\n\\nThe water is then carried away by the wind, and the air is heated up.  The water vapor condenses and forms clouds.\"\n",
      "        },\n",
      "        \"passages\": [\n",
      "            \"Mitigation of aviation's environmental impact\\n \\\"Aircraft flying at high altitude form condensation trails or contrails in the exhaust plume of their engines. While in the Troposphere these have very little climatic impact. However, jet aircraft cruising in the Stratosphere do create an impact from their contrails, although the extent of the damage to the environment is as yet unknown. Contrails can also trigger the formation of high-altitude Cirrus cloud thus creating a greater climatic effect. A 2015 study found that artificial cloudiness caused by contrail \\\"\\\"outbreaks\\\"\\\" reduce the difference between daytime and nighttime temperatures. The former are decreased and the latter are increased, in comparison\\\"\",\n",
      "            \"Chemtrail conspiracy theory\\n \\\"Contrails, or condensation trails, are \\\"\\\"streaks of condensed water vapor created in the air by an airplane or rocket at high altitudes.\\\"\\\" Fossil fuel combustion (as in piston and jet engines) produces carbon dioxide and water vapor. At high altitudes the air is very cold. Hot humid air from the engine exhaust mixes with the colder surrounding air, causing the water vapor to condense into droplets or ice crystals that form visible clouds. The rate at which contrails dissipate is entirely dependent on weather conditions. If the atmosphere is near saturation, the contrail may exist for some time. Conversely, if\\\"\",\n",
      "            \"Contrail\\n \\\"Contrails (; short for \\\"\\\"condensation trails\\\"\\\") are line-shaped clouds produced by aircraft engine exhaust or changes in air pressure, typically at aircraft cruise altitudes several miles above the Earth's surface. Contrails are composed primarily of water, in the form of ice crystals. The combination of water vapor in aircraft engine exhaust and the low ambient temperatures that exist at high altitudes allows the formation of the trails. Impurities in the engine exhaust from the fuel, including sulfur compounds (0.05% by weight in jet fuel) provide some of the particles that can serve as sites for water droplet growth in the\\\"\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from primeqa.components.retriever.dense import ColBERTRetriever\n",
    "from primeqa.components.reader.generative import GenerativeFiDReader\n",
    "from primeqa.pipelines.qa_pipeline import QAPipeline\n",
    "import json\n",
    "\n",
    "index_root = \"/dccstor/mabornea1/kilt-wikipedia-test/colbert_ir/kilt_wikipedia_eli5_dev_exp/indexes/\"\n",
    "index_name = \"kilt_wikipedia_eli5_dev_indname\"\n",
    "collection = \"/dccstor/mabornea1/kilt-wikipedia-test/passages/kilt_knowledgesource_eli5_dev.tsv\"\n",
    "\n",
    "\n",
    "colbert_retriever = ColBERTRetriever(index_root = index_root, \n",
    "                                     index_name = index_name, \n",
    "                                     collection = collection, \n",
    "                                     max_num_documents = 3)\n",
    "\n",
    "colbert_retriever.load()\n",
    "\n",
    "fid_reader = GenerativeFiDReader()\n",
    "fid_reader.load()\n",
    "\n",
    "lfqa_pipeline = QAPipeline(colbert_retriever, fid_reader)\n",
    "\n",
    "questions = [\"What causes the trail behind jets at high altitude?\"]\n",
    "answers = lfqa_pipeline.run(questions)\n",
    "print(json.dumps(answers, indent=4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 68.71it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761204325de047a08cc9a875119318b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on eval dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BartFiDModelForDownstreamTasks.forward` and have been ignored: example_id. If example_id are not expected by `BartFiDModelForDownstreamTasks.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": {\n",
      "        \"answers\": {\n",
      "            \"text\": \"The idea is that the higher the income, the more you earn, the higher your tax burden. \\n\\nIf you make $100,000, you pay $100.00 in taxes. If you make a million, you only pay $50,000 in taxes, and you pay the same amount of taxes.  \\nIf your income is $100k, you're paying $50k in taxes and you're only paying $30k in tax.  If you earn $100m, you are paying $60k in taxation.  You're paying the same tax rate as someone making $100mil.  So you're still paying the exact same amount, but you're also paying the full amount.  The higher the amount, the lower the tax burden, and the higher you are.  This is why you pay more tax on the top 1% of your income than the bottom 1%. \\n \\nThe reason why you have different tax brackets is because the higher income people are, the less they pay in taxes on their income.  They're paying more taxes on the lower income people, and they're paying less on the higher incomes.  That's why you see the higher tax brackets.  It\"\n",
      "        },\n",
      "        \"passages\": [\n",
      "            \"Tax rate\\n In a proportional tax, the tax rate is fixed and the average tax rate equals this tax rate. In case of tax brackets, commonly used for progressive taxes, the average tax rate increases as taxable income increases through tax brackets, asymptoting to the top tax rate. For example, consider a system with three tax brackets, 10%, 20%, and 30%, where the 10% rate applies to income from $1 to $10,000, the 20% rate applies to income from $10,001 to $20,000, and the 30% rate applies to all income above $20,000. Under this system, someone earning $25,000 would pay $1,000 for\",\n",
      "            \"C corporation\\n \\\"Up through 2017, the Internal Revenue Service (IRS) imposed tax based on the following schedule for \\\"\\\"most corporations\\\"\\\", except \\\"\\\"qualified personal service corporations\\\"\\\" and certain other cases: However, as a result of the Tax Cuts and Jobs Act of 2017, starting in 2018 the tax rate for C corporations dropped a flat 21%, regardless of the level of taxable income. See IRS Publication 542, Corporations for details about taxation of corporations. Section: See also. BULLET: - Corporate tax in the United States BULLET: - Blocker corporation BULLET: - S corporation\\\"\",\n",
      "            \"Income tax in the United States\\n A tax is imposed on net taxable income in the United States by the federal, most state, and some local governments. Income tax is imposed on individuals, corporations, estates, and trusts. The definition of net taxable income for most sub-federal jurisdictions mostly follows the federal definition. The rate of tax at the federal level is graduated; that is, the tax rates on higher amounts of income are higher than on lower amounts. Federal tax rates in 2018 varied from 10% to 37%. Some states and localities impose an income tax at a graduated rate, and some at a flat rate\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Why do we have different tax brackets ? \"]\n",
    "answers = lfqa_pipeline.run(questions)\n",
    "print(json.dumps(answers, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5d039775dffd761dc362a240b88aab365529f2df8e87d6e6e9eecd3e8d89fd4"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "13602d68c84c47bf855058690bcbb4d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "39225597f2cd4f8a9220793edecfc520": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7a378f82e08b4928ab8121940823c0fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_951479c9126444b3ae4b1700349569a6",
       "placeholder": "​",
       "style": "IPY_MODEL_ff5d6d4401c14e448104fe0ce8460106",
       "value": "Running tokenizer on eval dataset: 100%"
      }
     },
     "951479c9126444b3ae4b1700349569a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc825f54d0e3479c8d531ecf1f65224d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e0e466f2c69546f7af50ddb480defe0a",
       "placeholder": "​",
       "style": "IPY_MODEL_13602d68c84c47bf855058690bcbb4d4",
       "value": " 1/1 [00:00&lt;00:00,  5.78ba/s]"
      }
     },
     "e0e466f2c69546f7af50ddb480defe0a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3b07ee914ef448da819b0375e1dfc7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ed9d9367bbd840358cdae26cebfa194f",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_39225597f2cd4f8a9220793edecfc520",
       "value": 1
      }
     },
     "ed9d9367bbd840358cdae26cebfa194f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f42bb66471d2494facaf46d3fb1c8f9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7a378f82e08b4928ab8121940823c0fd",
        "IPY_MODEL_e3b07ee914ef448da819b0375e1dfc7f",
        "IPY_MODEL_dc825f54d0e3479c8d531ecf1f65224d"
       ],
       "layout": "IPY_MODEL_f792b945510749be99aa69889f3a3dc6"
      }
     },
     "f792b945510749be99aa69889f3a3dc6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff5d6d4401c14e448104fe0ce8460106": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

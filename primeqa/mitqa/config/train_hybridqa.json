{
    "per_device_train_batch_size_rr":128,
    "per_device_eval_batch_size_rr":128,
    "rr_model_name":"bert-large-uncased",
    "save_model_path_rr":"data/hybridqa/models/row_retriever/rr.bin",
    "row_retriever_model_name_path":"data/hybridqa/models/row_retriever/rr.bin",
    "pos_frac_per_epoch":[0.51, 0.5, 0.3, 0.1, 0.09],
    "group_frac_per_epoch":[0.0, 0.0, 0.0, 0.0, 0.0],
    "num_train_epochs_rr":3,
    "save_every_niter_rr":1000,
    "max_seq_length":512,
    "per_gpu_train_batch_size":128,
    "train_batch_size":256,
    "per_gpu_eval_batch_size":128,
    "eval_batch_size":128,
    "max_query_length":64,
    "threads":1,
    "null_score_diff_threshold":0.0,
    "n_best_size":20,
    "do_lower_case":true,
    "do_predict_ae":false,
    "do_train_ae":true,
    "do_eval_ae":false,
    "n_gpu":1,
    "max_answer_length":30,
    "model_name_or_path_ae":"bert-large-uncased-whole-word-masking-finetuned-squad",
    "output_dir":"data/hybridqa/models/answer_extractor/",
    "model_type":"bert",
    "doc_stride":128,
    "pred_ans_file":"data/hybridqa/predictions/answer_extractor_output_dev.json",
    "eval_file":"data/hybridqa/ae_input_test.json",
    "data_path_root":"data/hybridqa/",
    "dataset_name":"hybridqa",
    "train_data_path":"data/hybridqa/train.json",
    "dev_data_path":"data/hybridqa/dev.json"
}

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT &#8212; PrimeQA  documentation</title>
<link rel="stylesheet" href="../../../_static/plex.css" type="text/css">

<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="icon" sizes="16x16" type="image/png" href="../../../_static/primeqa_logo.png" />
    <link rel="icon" sizes="32x32" type="image/png" href="../../../_static/primeqa_logo.png" />
    <link rel="apple-touch-icon" sizes="180x180" type="image/png" href="../../../_static/primeqa_logo.png" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/design-tabs.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
<script async
    src="https://api.countapi.xyz/hit/mnlp-qa-dev-2.sl.cloud9.ibm.com/visits?callback=callbackCounter"></script>
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="light">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    <p class="title logo__title">PrimeQA: The Prime Repository for QA</p>
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../installation.html">
  Installation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../development.html">
  Development
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../testing.html">
  Testing
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../index.html">
  API
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/primeqa/primeqa/" rel="noopener" target="_blank" title="GitHub"><img src="https://badgen.net/github/stars/primeqa/primeqa?icon=github" class="icon-link-image" alt="GitHub"/></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://join.slack.com/t/primeqaworkspace/shared_invite/zt-1edc4fn7n-6aUO0CCvDOMOLb0drROwSw" rel="noopener" target="_blank" title="Slack"><img src="https://cdn.bfldr.com/5H442O3W/at/pl546j-7le8zk-6gwiyo/Slack_Mark.svg?auto=webp&format=png" class="icon-link-image" alt="Slack"/></a>
        </li>
      </ul>
      </div>
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="primeqa.ir.dense.html">
   dense
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="primeqa.ir.dense.colbert_top.html">
     colbert_top
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active has-children">
      <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.html">
       colbert
      </a>
      <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
      <label for="toctree-checkbox-3">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul class="current">
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.data.html">
         data
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.distillation.html">
         distillation
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.evaluation.html">
         evaluation
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.index.html">
         index
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.indexer.html">
         indexer
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.indexing.html">
         indexing
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.infra.html">
         infra
        </a>
       </li>
       <li class="toctree-l4 current active">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.modeling.html">
         modeling
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.parameters.html">
         parameters
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.ranking.html">
         ranking
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.run_indexer.html">
         run_indexer
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.run_searcher.html">
         run_searcher
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.run_trainer.html">
         run_trainer
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.search.html">
         search
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.searcher.html">
         searcher
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.trainer.html">
         trainer
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.training.html">
         training
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.utilities.html">
         utilities
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.colbert.utils.html">
         utils
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="primeqa.ir.dense.colbert_top.utility.html">
       utility
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
      <label for="toctree-checkbox-4">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.utility.evaluate.html">
         evaluate
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.utility.preprocess.html">
         preprocess
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.utility.rankings.html">
         rankings
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.utility.supervision.html">
         supervision
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="primeqa.ir.dense.colbert_top.utility.utils.html">
         utils
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="primeqa.ir.run_bm25_retrieval.html">
   run_bm25_retrieval
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="primeqa.ir.run_bm25_retrieval.get_language_id.html">
     primeqa.ir.run_bm25_retrieval.get_language_id
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="primeqa.ir.run_bm25_retrieval.handle_args.html">
     primeqa.ir.run_bm25_retrieval.handle_args
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="primeqa.ir.run_bm25_retrieval.load_queries.html">
     primeqa.ir.run_bm25_retrieval.load_queries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="primeqa.ir.run_bm25_retrieval.main.html">
     primeqa.ir.run_bm25_retrieval.main
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="primeqa.ir.run_bm25_retrieval.run_search.html">
     primeqa.ir.run_bm25_retrieval.run_search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="primeqa.ir.run_bm25_retrieval.write_colbert_ranking_tsv.html">
     primeqa.ir.run_bm25_retrieval.write_colbert_ranking_tsv
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="primeqa.ir.run_bm25_retrieval.write_search_results.html">
     primeqa.ir.run_bm25_retrieval.write_search_results
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="primeqa.ir.run_bm25_retrieval.write_xorqa_json.html">
     primeqa.ir.run_bm25_retrieval.write_xorqa_json
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="primeqa.ir.run_ir.html">
   run_ir
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="primeqa.ir.run_ir.main.html">
     primeqa.ir.run_ir.main
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="primeqa.ir.run_ir.ProcessArguments.html">
     primeqa.ir.run_ir.ProcessArguments
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="primeqa.ir.sparse.html">
   sparse
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="primeqa.ir.sparse.bm25_engine.html">
     bm25_engine
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.bm25_engine.BM25Engine.html">
       primeqa.ir.sparse.bm25_engine.BM25Engine
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="primeqa.ir.sparse.config.html">
     config
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.config.BM25Config.html">
       primeqa.ir.sparse.config.BM25Config
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.config.IndexingArguments.html">
       primeqa.ir.sparse.config.IndexingArguments
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.config.SearchArguments.html">
       primeqa.ir.sparse.config.SearchArguments
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="primeqa.ir.sparse.indexer.html">
     indexer
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.indexer.PyseriniIndexer.html">
       primeqa.ir.sparse.indexer.PyseriniIndexer
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="primeqa.ir.sparse.retriever.html">
     retriever
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.retriever.BaseRetriever.html">
       primeqa.ir.sparse.retriever.BaseRetriever
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.retriever.PyseriniRetriever.html">
       primeqa.ir.sparse.retriever.PyseriniRetriever
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="primeqa.ir.sparse.utils.html">
     utils
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.utils.get_language_id.html">
       primeqa.ir.sparse.utils.get_language_id
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.utils.load_queries.html">
       primeqa.ir.sparse.utils.load_queries
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.utils.write_colbert_ranking_tsv.html">
       primeqa.ir.sparse.utils.write_colbert_ranking_tsv
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.utils.write_search_results.html">
       primeqa.ir.sparse.utils.write_search_results
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.sparse.utils.write_xorqa_json.html">
       primeqa.ir.sparse.utils.write_xorqa_json
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="primeqa.ir.util.html">
   util
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="primeqa.ir.util.corpus_reader.html">
     corpus_reader
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.util.corpus_reader.corpus_reader.html">
       primeqa.ir.util.corpus_reader.corpus_reader
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.util.corpus_reader.is_tsv.html">
       primeqa.ir.util.corpus_reader.is_tsv
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.util.corpus_reader.list_corpus_files.html">
       primeqa.ir.util.corpus_reader.list_corpus_files
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.util.corpus_reader.lookup_by_aliases.html">
       primeqa.ir.util.corpus_reader.lookup_by_aliases
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="primeqa.ir.util.corpus_reader.Passage.html">
       primeqa.ir.util.corpus_reader.Passage
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      <div class="custom-right-section" style="padding: 2rem 0 0 0">
        <button onclick="window.open('https://github.com/primeqa/primeqa/discussions','_blank')" class="bootstrap-btn">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" style="width: 1em; height: 1em;">
                        <!-- Font Awesome Pro 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) -->
                        <path style="fill: #459db9"
                                d="M96 224c35.3 0 64-28.7 64-64s-28.7-64-64-64-64 28.7-64 64 28.7 64 64 64zm448 0c35.3 0 64-28.7 64-64s-28.7-64-64-64-64 28.7-64 64 28.7 64 64 64zm32 32h-64c-17.6 0-33.5 7.1-45.1 18.6 40.3 22.1 68.9 62 75.1 109.4h66c17.7 0 32-14.3 32-32v-32c0-35.3-28.7-64-64-64zm-256 0c61.9 0 112-50.1 112-112S381.9 32 320 32 208 82.1 208 144s50.1 112 112 112zm76.8 32h-8.3c-20.8 10-43.9 16-68.5 16s-47.6-6-68.5-16h-8.3C179.6 288 128 339.6 128 403.2V432c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48v-28.8c0-63.6-51.6-115.2-115.2-115.2zm-223.7-13.4C161.5 263.1 145.6 256 128 256H64c-35.3 0-64 28.7-64 64v32c0 17.7 14.3 32 32 32h65.9c6.3-47.4 34.9-87.3 75.2-109.4z" />
                </svg>&nbsp;Start a Discussion!</button>
        <button onclick="showSource()" class="bootstrap-btn"><svg xmlns="http://www.w3.org/2000/svg"
                        viewBox="0 0 640 512" style="width: 1em; height: 1em;">
                        <!--! Font Awesome Pro 6.1.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc. -->
                        <path style="fill: #459db9"
                                d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z" />
                </svg>&nbsp;Show Source</button>
        <!-- <p style="color: #459db9">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" style="width: 1em; height: 1em;">
                        <path style="fill: #459db9"
                                d="M96 224c35.3 0 64-28.7 64-64s-28.7-64-64-64-64 28.7-64 64 28.7 64 64 64zm448 0c35.3 0 64-28.7 64-64s-28.7-64-64-64-64 28.7-64 64 28.7 64 64 64zm32 32h-64c-17.6 0-33.5 7.1-45.1 18.6 40.3 22.1 68.9 62 75.1 109.4h66c17.7 0 32-14.3 32-32v-32c0-35.3-28.7-64-64-64zm-256 0c61.9 0 112-50.1 112-112S381.9 32 320 32 208 82.1 208 144s50.1 112 112 112zm76.8 32h-8.3c-20.8 10-43.9 16-68.5 16s-47.6-6-68.5-16h-8.3C179.6 288 128 339.6 128 403.2V432c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48v-28.8c0-63.6-51.6-115.2-115.2-115.2zm-223.7-13.4C161.5 263.1 145.6 256 128 256H64c-35.3 0-64 28.7-64 64v32c0 17.7 14.3 32 32 32h65.9c6.3-47.4 34.9-87.3 75.2-109.4z" />
                </svg>&nbsp;<span id="visits"></span>
        </p> -->
        <img src="_static/img/PrimeQA.png" alt="primeqa" width="100"
                style="display: block;margin-left: auto;margin-right: auto;" />
</div>

<script>
        function showSource() {
                window.open("../../../_sources/api/ir/_autosummary/primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.rst.txt", '_blank');
        }

        function hRefGitHub() {
                window.open('', '_blank');
        }
        // function callbackCounter(response) {
        //         document.getElementById('visits').innerText = response.value;
        // }
</script>
    </div>
    
    <div class="toc-item">
      

<nav id="bd-toc-nav">
    
</nav>
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="primeqa-ir-dense-colbert-top-colbert-modeling-hf-colbert-hf-colbert">
<h1>primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT<a class="headerlink" href="#primeqa-ir-dense-colbert-top-colbert-modeling-hf-colbert-hf-colbert" title="Permalink to this headline">#</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.</span></span><span class="sig-name descname"><span class="pre">HF_ColBERT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colbert_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.models.bert.modeling_bert.BertPreTrainedModel</span></code></p>
<p>Shallow wrapper around HuggingFace transformers. All new parameters should be defined at this level.</p>
<p>This makes sure <cite>{from,save}_pretrained</cite> and <cite>init_weights</cite> are applied to new parameters correctly.</p>
<p class="rubric">Methods</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_memory_hooks" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_memory_hooks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_memory_hooks</span></code></a></p></td>
<td><p>Add a memory hook before and after each sub-module forward pass to record increase in memory consumption.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_module" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_module</span></code></a></p></td>
<td><p>Adds a child module to the current module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.adjust_logits_during_generation" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.adjust_logits_during_generation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adjust_logits_during_generation</span></code></a></p></td>
<td><p>Implement in subclasses of [<cite>PreTrainedModel</cite>] for custom behavior to adjust the logits in the generate method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.apply" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a></p></td>
<td><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.beam_sample" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.beam_sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">beam_sample</span></code></a></p></td>
<td><p>Generates sequences for models with a language modeling head using beam search with multinomial sampling.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.beam_search" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.beam_search"><code class="xref py py-obj docutils literal notranslate"><span class="pre">beam_search</span></code></a></p></td>
<td><p>Generates sequences for models with a language modeling head using beam search decoding.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.bfloat16" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.bfloat16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bfloat16</span></code></a></p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.buffers" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">buffers</span></code></a></p></td>
<td><p>Returns an iterator over module buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.children" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">children</span></code></a></p></td>
<td><p>Returns an iterator over immediate children modules.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.compute_transition_beam_scores" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.compute_transition_beam_scores"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_transition_beam_scores</span></code></a></p></td>
<td><p>compute the transition probabilities of sequences given generation scores and beam indices</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.constrained_beam_search" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.constrained_beam_search"><code class="xref py py-obj docutils literal notranslate"><span class="pre">constrained_beam_search</span></code></a></p></td>
<td><p>Generates sequences for models with a language modeling head using beam search decoding.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cpu" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cpu</span></code></a></p></td>
<td><p>Moves all model parameters and buffers to the CPU.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_extended_attention_mask_for_decoder</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cuda" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cuda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda</span></code></a></p></td>
<td><p>Moves all model parameters and buffers to the GPU.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.double" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.double"><code class="xref py py-obj docutils literal notranslate"><span class="pre">double</span></code></a></p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">double</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.estimate_tokens" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.estimate_tokens"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_tokens</span></code></a></p></td>
<td><p>Helper function to estimate the total number of tokens from the model inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.eval" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eval</span></code></a></p></td>
<td><p>Sets the module in evaluation mode.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.extra_repr" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.extra_repr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extra_repr</span></code></a></p></td>
<td><p>Set the extra representation of the module</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.float" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code></a></p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">float</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.floating_point_ops" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.floating_point_ops"><code class="xref py py-obj docutils literal notranslate"><span class="pre">floating_point_ops</span></code></a></p></td>
<td><p>Get number of (optionally, non-embeddings) floating-point operations for the forward and backward passes of a batch with this transformer model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.forward" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a></p></td>
<td><p>Defines the computation performed at every call.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.from_pretrained" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.from_pretrained"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_pretrained</span></code></a></p></td>
<td><p>Instantiate a pretrained pytorch model from a pre-trained model configuration.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.generate" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.generate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate</span></code></a></p></td>
<td><p>Generates sequences for models with a language modeling head.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_buffer" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_buffer</span></code></a></p></td>
<td><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_extended_attention_mask" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_extended_attention_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_extended_attention_mask</span></code></a></p></td>
<td><p>Makes broadcastable attention and causal masks so that future and masked tokens are ignored.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_extra_state" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_extra_state</span></code></a></p></td>
<td><p>Returns any extra state to include in the module's state_dict.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_head_mask" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_head_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_head_mask</span></code></a></p></td>
<td><p>Prepare the head mask if needed.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_input_embeddings" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_input_embeddings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_input_embeddings</span></code></a></p></td>
<td><p>Returns the model's input embeddings.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_output_embeddings" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_output_embeddings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_output_embeddings</span></code></a></p></td>
<td><p>Returns the model's output embeddings.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_parameter" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_parameter</span></code></a></p></td>
<td><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_position_embeddings</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_submodule" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_submodule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_submodule</span></code></a></p></td>
<td><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throws an error.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.gradient_checkpointing_disable" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.gradient_checkpointing_disable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient_checkpointing_disable</span></code></a></p></td>
<td><p>Deactivates gradient checkpointing for the current model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.gradient_checkpointing_enable" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.gradient_checkpointing_enable"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gradient_checkpointing_enable</span></code></a></p></td>
<td><p>Activates gradient checkpointing for the current model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.greedy_search" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.greedy_search"><code class="xref py py-obj docutils literal notranslate"><span class="pre">greedy_search</span></code></a></p></td>
<td><p>Generates sequences for models with a language modeling head using greedy decoding.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.group_beam_search" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.group_beam_search"><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_beam_search</span></code></a></p></td>
<td><p>Generates sequences for models with a language modeling head using beam search decoding.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.half" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.half"><code class="xref py py-obj docutils literal notranslate"><span class="pre">half</span></code></a></p></td>
<td><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">half</span></code> datatype.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.init_weights" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.init_weights"><code class="xref py py-obj docutils literal notranslate"><span class="pre">init_weights</span></code></a></p></td>
<td><p>If needed prunes and maybe initializes weights.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.invert_attention_mask" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.invert_attention_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">invert_attention_mask</span></code></a></p></td>
<td><p>Invert an attention mask (e.g., switches 0.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_state_dict</span></code></a></p></td>
<td><p>Copies parameters and buffers from <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_tf_weights" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_tf_weights"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_tf_weights</span></code></a></p></td>
<td><p>Load tf checkpoints in a pytorch model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.modules" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">modules</span></code></a></p></td>
<td><p>Returns an iterator over all modules in the network.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_buffers" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_buffers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_buffers</span></code></a></p></td>
<td><p>Returns an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_children" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_children"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_children</span></code></a></p></td>
<td><p>Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_modules" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_modules"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_modules</span></code></a></p></td>
<td><p>Returns an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_parameters" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">named_parameters</span></code></a></p></td>
<td><p>Returns an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.num_parameters" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.num_parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">num_parameters</span></code></a></p></td>
<td><p>Get number of (optionally, trainable or non-embeddings) parameters in the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.parameters" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.parameters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">parameters</span></code></a></p></td>
<td><p>Returns an iterator over module parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.post_init" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.post_init"><code class="xref py py-obj docutils literal notranslate"><span class="pre">post_init</span></code></a></p></td>
<td><p>A method executed at the end of each Transformer model initialization, to execute code that needs the model's modules properly initialized (such as weight initialization).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.prepare_inputs_for_generation" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.prepare_inputs_for_generation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare_inputs_for_generation</span></code></a></p></td>
<td><p>Implement in subclasses of [<cite>PreTrainedModel</cite>] for custom behavior to prepare inputs in the generate method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.prune_heads" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.prune_heads"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prune_heads</span></code></a></p></td>
<td><p>Prunes heads of the base model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.push_to_hub" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.push_to_hub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">push_to_hub</span></code></a></p></td>
<td><p>Upload the model checkpoint to the  Model Hub while synchronizing a local clone of the repo in <cite>repo_path_or_name</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">raw_tokenizer_from_pretrained</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_backward_hook" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_backward_hook</span></code></a></p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_buffer" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_buffer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_buffer</span></code></a></p></td>
<td><p>Adds a buffer to the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_for_auto_class" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_for_auto_class"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_for_auto_class</span></code></a></p></td>
<td><p>Register this class with a given auto class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_forward_hook" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_forward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_hook</span></code></a></p></td>
<td><p>Registers a forward hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_forward_pre_hook" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_forward_pre_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_forward_pre_hook</span></code></a></p></td>
<td><p>Registers a forward pre-hook on the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_full_backward_hook" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_full_backward_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_full_backward_hook</span></code></a></p></td>
<td><p>Registers a backward hook on the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_module" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_module</span></code></a></p></td>
<td><p>Alias for <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_module" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_parameter" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_parameter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">register_parameter</span></code></a></p></td>
<td><p>Adds a parameter to the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.requires_grad_" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.requires_grad_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">requires_grad_</span></code></a></p></td>
<td><p>Change if autograd should record operations on parameters in this module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.reset_memory_hooks_state" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.reset_memory_hooks_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset_memory_hooks_state</span></code></a></p></td>
<td><p>Reset the <cite>mem_rss_diff</cite> attribute of each module (see [<cite>~modeling_utils.ModuleUtilsMixin.add_memory_hooks</cite>]).</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize_position_embeddings</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.resize_token_embeddings" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.resize_token_embeddings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize_token_embeddings</span></code></a></p></td>
<td><p>Resizes input token embeddings matrix of the model if <cite>new_num_tokens != config.vocab_size</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">retrieve_modules_from_names</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.sample" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.sample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sample</span></code></a></p></td>
<td><p>Generates sequences for models with a language modeling head using multinomial sampling.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.save_pretrained" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.save_pretrained"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_pretrained</span></code></a></p></td>
<td><p>Save a model and its configuration file to a directory, so that it can be re-loaded using the <cite>[`~PreTrainedModel.from_pretrained</cite>]` class method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.set_extra_state" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.set_extra_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_extra_state</span></code></a></p></td>
<td><p>This function is called from <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state found within the <cite>state_dict</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.set_input_embeddings" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.set_input_embeddings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_input_embeddings</span></code></a></p></td>
<td><p>Set model's input embeddings.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.share_memory" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.share_memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">share_memory</span></code></a></p></td>
<td><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">state_dict</span></code></a></p></td>
<td><p>Returns a dictionary containing a whole state of the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.tie_weights" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.tie_weights"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tie_weights</span></code></a></p></td>
<td><p>Tie the weights between the input embeddings and the output embeddings.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.to" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to</span></code></a></p></td>
<td><p>Moves and/or casts the parameters and buffers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.to_empty" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.to_empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_empty</span></code></a></p></td>
<td><p>Moves the parameters and buffers to the specified device without copying storage.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.train" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a></p></td>
<td><p>Sets the module in training mode.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.type" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">type</span></code></a></p></td>
<td><p>Casts all parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dst_type</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.xpu" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.xpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">xpu</span></code></a></p></td>
<td><p>Moves all model parameters and buffers to the XPU.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.zero_grad" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.zero_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zero_grad</span></code></a></p></td>
<td><p>Sets gradients of all model parameters to zero.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Attributes</p>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">T_destination</span></code></p></td>
<td><p>alias of TypeVar('T_destination', bound=<code class="xref py py-class docutils literal notranslate"><span class="pre">Mapping</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code>])</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.base_model" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.base_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">base_model</span></code></a></p></td>
<td><p>The main body of the model.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">base_model_prefix</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.device" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">device</span></code></a></p></td>
<td><p>The device on which the module is (assuming that all the module parameters are on the same device).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dtype" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dtype</span></code></a></p></td>
<td><p>The dtype of the module (assuming that all the module parameters have the same dtype).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dummy_inputs" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dummy_inputs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dummy_inputs</span></code></a></p></td>
<td><p>Dummy inputs to do a forward pass in the network.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">dump_patches</span></code></p></td>
<td><p>This allows better BC support for <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.framework" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.framework"><code class="xref py py-obj docutils literal notranslate"><span class="pre">framework</span></code></a></p></td>
<td><p>Identifies that this is a PyTorch model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.is_gradient_checkpointing" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.is_gradient_checkpointing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_gradient_checkpointing</span></code></a></p></td>
<td><p>Whether gradient checkpointing is activated for this model or not.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_parallelizable</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">main_input_name</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_gradient_checkpointing</span></code></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.__call__" title="Permalink to this definition">#</a></dt>
<dd><p>Call self as a function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_memory_hooks">
<span class="sig-name descname"><span class="pre">add_memory_hooks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_memory_hooks" title="Permalink to this definition">#</a></dt>
<dd><p>Add a memory hook before and after each sub-module forward pass to record increase in memory consumption.</p>
<p>Increase in memory consumption is stored in a <cite>mem_rss_diff</cite> attribute for each module and can be reset to zero
with <cite>model.reset_memory_hooks_state()</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_module" title="Permalink to this definition">#</a></dt>
<dd><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>string</em>)  name of the child module. The child module can be
accessed from this module using the given name</p></li>
<li><p><strong>module</strong> (<em>Module</em>)  child module to be added to the module.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.adjust_logits_during_generation">
<span class="sig-name descname"><span class="pre">adjust_logits_during_generation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.FloatTensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.FloatTensor</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.adjust_logits_during_generation" title="Permalink to this definition">#</a></dt>
<dd><p>Implement in subclasses of [<cite>PreTrainedModel</cite>] for custom behavior to adjust the logits in the generate method.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.apply" title="Permalink to this definition">#</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>)
as well as self. Typical use includes initializing the parameters of a model
(see also <span class="xref std std-ref">nn-init-doc</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> -&gt; None)  function to be applied to each submodule</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 1.,  1.],</span>
<span class="go">        [ 1.,  1.]])</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 1.,  1.],</span>
<span class="go">        [ 1.,  1.]])</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.base_model">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">base_model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.nn.modules.module.Module</span></em><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.base_model" title="Permalink to this definition">#</a></dt>
<dd><p>The main body of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><cite>torch.nn.Module</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.beam_sample">
<span class="sig-name descname"><span class="pre">beam_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beam_scorer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.generation_beam_search.BeamScorer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_processor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_logits_process.LogitsProcessorList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criteria</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_stopping_criteria.StoppingCriteriaList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_warper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_logits_process.LogitsProcessorList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_attentions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_hidden_states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict_in_generate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synced_gpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">model_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_utils.BeamSampleEncoderDecoderOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.BeamSampleDecoderOnlyOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.LongTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.beam_sample" title="Permalink to this definition">#</a></dt>
<dd><p>Generates sequences for models with a language modeling head using beam search with multinomial sampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<cite>torch.LongTensor</cite> of shape <cite>(batch_size, sequence_length)</cite>)  The sequence used as a prompt for the generation.</p></li>
<li><p><strong>beam_scorer</strong> (<cite>BeamScorer</cite>)  A derived instance of [<cite>BeamScorer</cite>] that defines how beam hypotheses are constructed, stored and
sorted during generation. For more information, the documentation of [<cite>BeamScorer</cite>] should be read.</p></li>
<li><p><strong>logits_processor</strong> (<cite>LogitsProcessorList</cite>, <em>optional</em>)  An instance of [<cite>LogitsProcessorList</cite>]. List of instances of class derived from [<cite>LogitsProcessor</cite>]
used to modify the prediction scores of the language modeling head applied at each generation step.</p></li>
<li><p><strong>stopping_criteria</strong> (<cite>StoppingCriteriaList</cite>, <em>optional</em>)  An instance of [<cite>StoppingCriteriaList</cite>]. List of instances of class derived from [<cite>StoppingCriteria</cite>]
used to tell if the generation loop should stop.</p></li>
<li><p><strong>logits_warper</strong> (<cite>LogitsProcessorList</cite>, <em>optional</em>)  An instance of [<cite>LogitsProcessorList</cite>]. List of instances of class derived from [<cite>LogitsWarper</cite>] used
to warp the prediction score distribution of the language modeling head applied before multinomial
sampling at each generation step.</p></li>
<li><p><strong>max_length</strong> (<cite>int</cite>, <em>optional</em>, defaults to 20)  <strong>DEPRECATED</strong>. Use <cite>logits_processor</cite> or <cite>stopping_criteria</cite> directly to cap the number of generated
tokens. The maximum length of the sequence to be generated.</p></li>
<li><p><strong>pad_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>padding</em> token.</p></li>
<li><p><strong>eos_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>end-of-sequence</em> token.</p></li>
<li><p><strong>output_attentions</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the attentions tensors of all attention layers. See <cite>attentions</cite> under
returned tensors for more details.</p></li>
<li><p><strong>output_hidden_states</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the hidden states of all layers. See <cite>hidden_states</cite> under returned tensors
for more details.</p></li>
<li><p><strong>output_scores</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the prediction scores. See <cite>scores</cite> under returned tensors for more details.</p></li>
<li><p><strong>return_dict_in_generate</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return a [<cite>~file_utils.ModelOutput</cite>] instead of a plain tuple.</p></li>
<li><p><strong>synced_gpus</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether to continue running the while loop until max_length (needed for ZeRO stage 3)</p></li>
<li><p><strong>model_kwargs</strong>  Additional model specific kwargs will be forwarded to the <cite>forward</cite> function of the model. If model is
an encoder-decoder model the kwargs should include <cite>encoder_outputs</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[<cite>~generation_utils.BeamSampleDecoderOnlyOutput</cite>], [<cite>~generation_utils.BeamSampleEncoderDecoderOutput</cite>] or
<cite>torch.LongTensor</cite>: A <cite>torch.LongTensor</cite> containing the generated tokens (default behaviour) or a
[<cite>~generation_utils.BeamSampleDecoderOnlyOutput</cite>] if <cite>model.config.is_encoder_decoder=False</cite> and
<cite>return_dict_in_generate=True</cite> or a [<cite>~generation_utils.BeamSampleEncoderDecoderOutput</cite>] if
<cite>model.config.is_encoder_decoder=True</cite>.</p>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a>python
&gt;&gt;&gt; from transformers import (
     AutoTokenizer,
     AutoModelForSeq2SeqLM,
     LogitsProcessorList,
     MinLengthLogitsProcessor,
     TopKLogitsWarper,
     TemperatureLogitsWarper,
     BeamSearchScorer,
 )
&gt;&gt;&gt; import torch</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_input_str</span> <span class="o">=</span> <span class="s2">&quot;translate English to German: How old are you?&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">encoder_input_str</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># lets run beam search using 3 beams</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_beams</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># define decoder start token ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_beams</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_start_token_id</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># add encoder_outputs to model keyword arguments</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
<span class="gp">... </span>    <span class="s2">&quot;encoder_outputs&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">get_encoder</span><span class="p">()(</span>
<span class="gp">... </span>        <span class="n">encoder_input_ids</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">num_beams</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span>    <span class="p">)</span>
<span class="gp">... </span><span class="p">}</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate beam scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">beam_scorer</span> <span class="o">=</span> <span class="n">BeamSearchScorer</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_length</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">num_beams</span><span class="o">=</span><span class="n">num_beams</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate logits processors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logits_processor</span> <span class="o">=</span> <span class="n">LogitsProcessorList</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[</span><span class="n">MinLengthLogitsProcessor</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">)]</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate logits processors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logits_warper</span> <span class="o">=</span> <span class="n">LogitsProcessorList</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[</span>
<span class="gp">... </span>        <span class="n">TopKLogitsWarper</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span>
<span class="gp">... </span>        <span class="n">TemperatureLogitsWarper</span><span class="p">(</span><span class="mf">0.7</span><span class="p">),</span>
<span class="gp">... </span>    <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">beam_sample</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">input_ids</span><span class="p">,</span> <span class="n">beam_scorer</span><span class="p">,</span> <span class="n">logits_processor</span><span class="o">=</span><span class="n">logits_processor</span><span class="p">,</span> <span class="n">logits_warper</span><span class="o">=</span><span class="n">logits_warper</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go">```</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.beam_search">
<span class="sig-name descname"><span class="pre">beam_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beam_scorer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.generation_beam_search.BeamScorer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_processor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_logits_process.LogitsProcessorList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criteria</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_stopping_criteria.StoppingCriteriaList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_attentions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_hidden_states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict_in_generate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synced_gpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">model_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_utils.BeamSearchEncoderDecoderOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.BeamSearchDecoderOnlyOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.LongTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.beam_search" title="Permalink to this definition">#</a></dt>
<dd><p>Generates sequences for models with a language modeling head using beam search decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<cite>torch.LongTensor</cite> of shape <cite>(batch_size, sequence_length)</cite>)  The sequence used as a prompt for the generation.</p></li>
<li><p><strong>beam_scorer</strong> (<cite>BeamScorer</cite>)  An derived instance of [<cite>BeamScorer</cite>] that defines how beam hypotheses are constructed, stored and
sorted during generation. For more information, the documentation of [<cite>BeamScorer</cite>] should be read.</p></li>
<li><p><strong>logits_processor</strong> (<cite>LogitsProcessorList</cite>, <em>optional</em>)  An instance of [<cite>LogitsProcessorList</cite>]. List of instances of class derived from [<cite>LogitsProcessor</cite>]
used to modify the prediction scores of the language modeling head applied at each generation step.</p></li>
<li><p><strong>stopping_criteria</strong> (<cite>StoppingCriteriaList</cite>, <em>optional</em>)  An instance of [<cite>StoppingCriteriaList</cite>]. List of instances of class derived from [<cite>StoppingCriteria</cite>]
used to tell if the generation loop should stop.</p></li>
<li><p><strong>max_length</strong> (<cite>int</cite>, <em>optional</em>, defaults to 20)  <strong>DEPRECATED</strong>. Use <cite>logits_processor</cite> or <cite>stopping_criteria</cite> directly to cap the number of generated
tokens. The maximum length of the sequence to be generated.</p></li>
<li><p><strong>pad_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>padding</em> token.</p></li>
<li><p><strong>eos_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>end-of-sequence</em> token.</p></li>
<li><p><strong>output_attentions</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the attentions tensors of all attention layers. See <cite>attentions</cite> under
returned tensors for more details.</p></li>
<li><p><strong>output_hidden_states</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the hidden states of all layers. See <cite>hidden_states</cite> under returned tensors
for more details.</p></li>
<li><p><strong>output_scores</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the prediction scores. See <cite>scores</cite> under returned tensors for more details.</p></li>
<li><p><strong>return_dict_in_generate</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return a [<cite>~file_utils.ModelOutput</cite>] instead of a plain tuple.</p></li>
<li><p><strong>synced_gpus</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether to continue running the while loop until max_length (needed for ZeRO stage 3)</p></li>
<li><p><strong>model_kwargs</strong>  Additional model specific kwargs will be forwarded to the <cite>forward</cite> function of the model. If model is
an encoder-decoder model the kwargs should include <cite>encoder_outputs</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[<cite>generation_utilsBeamSearchDecoderOnlyOutput</cite>], [<cite>~generation_utils.BeamSearchEncoderDecoderOutput</cite>] or
<cite>torch.LongTensor</cite>: A <cite>torch.LongTensor</cite> containing the generated tokens (default behaviour) or a
[<cite>~generation_utils.BeamSearchDecoderOnlyOutput</cite>] if <cite>model.config.is_encoder_decoder=False</cite> and
<cite>return_dict_in_generate=True</cite> or a [<cite>~generation_utils.BeamSearchEncoderDecoderOutput</cite>] if
<cite>model.config.is_encoder_decoder=True</cite>.</p>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a>python
&gt;&gt;&gt; from transformers import (
     AutoTokenizer,
     AutoModelForSeq2SeqLM,
     LogitsProcessorList,
     MinLengthLogitsProcessor,
     BeamSearchScorer,
 )
&gt;&gt;&gt; import torch</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_input_str</span> <span class="o">=</span> <span class="s2">&quot;translate English to German: How old are you?&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">encoder_input_str</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># lets run beam search using 3 beams</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_beams</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># define decoder start token ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_beams</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_start_token_id</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># add encoder_outputs to model keyword arguments</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
<span class="gp">... </span>    <span class="s2">&quot;encoder_outputs&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">get_encoder</span><span class="p">()(</span>
<span class="gp">... </span>        <span class="n">encoder_input_ids</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">num_beams</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span>    <span class="p">)</span>
<span class="gp">... </span><span class="p">}</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate beam scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">beam_scorer</span> <span class="o">=</span> <span class="n">BeamSearchScorer</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">num_beams</span><span class="o">=</span><span class="n">num_beams</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate logits processors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logits_processor</span> <span class="o">=</span> <span class="n">LogitsProcessorList</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[</span>
<span class="gp">... </span>        <span class="n">MinLengthLogitsProcessor</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">),</span>
<span class="gp">... </span>    <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">beam_search</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">beam_scorer</span><span class="p">,</span> <span class="n">logits_processor</span><span class="o">=</span><span class="n">logits_processor</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go">```</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.bfloat16">
<span class="sig-name descname"><span class="pre">bfloat16</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.bfloat16" title="Permalink to this definition">#</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.buffers">
<span class="sig-name descname"><span class="pre">buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.buffers" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an iterator over module buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>)  if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>torch.Tensor</em>  module buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.children" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an iterator over immediate children modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em>  a child module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.compute_transition_beam_scores">
<span class="sig-name descname"><span class="pre">compute_transition_beam_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequences</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beam_indices</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.compute_transition_beam_scores" title="Permalink to this definition">#</a></dt>
<dd><p>compute the transition probabilities of sequences given generation
scores and beam indices</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.config_class">
<span class="sig-name descname"><span class="pre">config_class</span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.config_class" title="Permalink to this definition">#</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">transformers.models.bert.configuration_bert.BertConfig</span></code></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.constrained_beam_search">
<span class="sig-name descname"><span class="pre">constrained_beam_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constrained_beam_scorer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.generation_beam_search.ConstrainedBeamSearchScorer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_processor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_logits_process.LogitsProcessorList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criteria</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_stopping_criteria.StoppingCriteriaList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_attentions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_hidden_states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict_in_generate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synced_gpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">model_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_utils.BeamSearchEncoderDecoderOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.BeamSearchDecoderOnlyOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.LongTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.constrained_beam_search" title="Permalink to this definition">#</a></dt>
<dd><p>Generates sequences for models with a language modeling head using beam search decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<cite>torch.LongTensor</cite> of shape <cite>(batch_size, sequence_length)</cite>)  The sequence used as a prompt for the generation.</p></li>
<li><p><strong>constrained_beam_scorer</strong> (<cite>ConstrainedBeamSearchScorer</cite>)  A derived instance of [<cite>BeamScorer</cite>] that defines how beam hypotheses are constructed, stored and
sorted during generation, while satisfying a list of positive constraints. For more information, the
documentation of [<cite>ConstrainedBeamSearchScorer</cite>] should be read.</p></li>
<li><p><strong>logits_processor</strong> (<cite>LogitsProcessorList</cite>, <em>optional</em>)  An instance of [<cite>LogitsProcessorList</cite>]. List of instances of class derived from [<cite>LogitsProcessor</cite>]
used to modify the prediction scores of the language modeling head applied at each generation step.</p></li>
<li><p><strong>stopping_criteria</strong> (<cite>StoppingCriteriaList</cite>, <em>optional</em>)  An instance of [<cite>StoppingCriteriaList</cite>]. List of instances of class derived from [<cite>StoppingCriteria</cite>]
used to tell if the generation loop should stop.</p></li>
<li><p><strong>logits_warper</strong> (<cite>LogitsProcessorList</cite>, <em>optional</em>)  An instance of [<cite>LogitsProcessorList</cite>]. List of instances of class derived from [<cite>LogitsWarper</cite>] used
to warp the prediction score distribution of the language modeling head applied before multinomial
sampling at each generation step.</p></li>
<li><p><strong>max_length</strong> (<cite>int</cite>, <em>optional</em>, defaults to 20)  <strong>DEPRECATED</strong>. Use <cite>logits_processor</cite> or <cite>stopping_criteria</cite> directly to cap the number of generated
tokens. The maximum length of the sequence to be generated.</p></li>
<li><p><strong>pad_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>padding</em> token.</p></li>
<li><p><strong>eos_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>end-of-sequence</em> token.</p></li>
<li><p><strong>output_attentions</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the attentions tensors of all attention layers. See <cite>attentions</cite> under
returned tensors for more details.</p></li>
<li><p><strong>output_hidden_states</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the hidden states of all layers. See <cite>hidden_states</cite> under returned tensors
for more details.</p></li>
<li><p><strong>output_scores</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the prediction scores. See <cite>scores</cite> under returned tensors for more details.</p></li>
<li><p><strong>return_dict_in_generate</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return a [<cite>~file_utils.ModelOutput</cite>] instead of a plain tuple.</p></li>
<li><p><strong>synced_gpus</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether to continue running the while loop until max_length (needed for ZeRO stage 3)</p></li>
<li><p><strong>model_kwargs</strong>  Additional model specific kwargs will be forwarded to the <cite>forward</cite> function of the model. If model is
an encoder-decoder model the kwargs should include <cite>encoder_outputs</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[<cite>generation_utilsBeamSearchDecoderOnlyOutput</cite>], [<cite>~generation_utils.BeamSearchEncoderDecoderOutput</cite>] or
<cite>torch.LongTensor</cite>: A <cite>torch.LongTensor</cite> containing the generated tokens (default behaviour) or a
[<cite>~generation_utils.BeamSearchDecoderOnlyOutput</cite>] if <cite>model.config.is_encoder_decoder=False</cite> and
<cite>return_dict_in_generate=True</cite> or a [<cite>~generation_utils.BeamSearchEncoderDecoderOutput</cite>] if
<cite>model.config.is_encoder_decoder=True</cite>.</p>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id9"><span class="problematic" id="id10">``</span></a><a href="#id11"><span class="problematic" id="id12">`</span></a>python
&gt;&gt;&gt; from transformers import (
     AutoTokenizer,
     AutoModelForSeq2SeqLM,
     LogitsProcessorList,
     MinLengthLogitsProcessor,
     ConstrainedBeamSearchScorer,
     PhrasalConstraint,
 )
&gt;&gt;&gt; import torch</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_input_str</span> <span class="o">=</span> <span class="s2">&quot;translate English to German: How old are you?&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">encoder_input_str</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># lets run beam search using 3 beams</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_beams</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># define decoder start token ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_beams</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_start_token_id</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># add encoder_outputs to model keyword arguments</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
<span class="gp">... </span>    <span class="s2">&quot;encoder_outputs&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">get_encoder</span><span class="p">()(</span>
<span class="gp">... </span>        <span class="n">encoder_input_ids</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">num_beams</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span>    <span class="p">)</span>
<span class="gp">... </span><span class="p">}</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">constraint_str</span> <span class="o">=</span> <span class="s2">&quot;sind&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">constraint_token_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">constraint_str</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># slice to remove eos token</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">constraints</span> <span class="o">=</span> <span class="p">[</span><span class="n">PhrasalConstraint</span><span class="p">(</span><span class="n">token_ids</span><span class="o">=</span><span class="n">constraint_token_ids</span><span class="p">)]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate beam scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">beam_scorer</span> <span class="o">=</span> <span class="n">ConstrainedBeamSearchScorer</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="n">num_beams</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate logits processors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logits_processor</span> <span class="o">=</span> <span class="n">LogitsProcessorList</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[</span>
<span class="gp">... </span>        <span class="n">MinLengthLogitsProcessor</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">),</span>
<span class="gp">... </span>    <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">constrained_beam_search</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">input_ids</span><span class="p">,</span> <span class="n">beam_scorer</span><span class="p">,</span> <span class="n">constraints</span><span class="o">=</span><span class="n">constraints</span><span class="p">,</span> <span class="n">logits_processor</span><span class="o">=</span><span class="n">logits_processor</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go"># =&gt; [&#39;Wie alter sind Sie?&#39;]</span>
<span class="go">```</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cpu" title="Permalink to this definition">#</a></dt>
<dd><p>Moves all model parameters and buffers to the CPU.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.device</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cuda" title="Permalink to this definition">#</a></dt>
<dd><p>Moves all model parameters and buffers to the GPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on GPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>)  if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.device">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.device</span></em><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.device" title="Permalink to this definition">#</a></dt>
<dd><p>The device on which the module is (assuming that all the module parameters are on the same
device).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><cite>torch.device</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.double" title="Permalink to this definition">#</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">double</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dtype">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.dtype</span></em><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dtype" title="Permalink to this definition">#</a></dt>
<dd><p>The dtype of the module (assuming that all the module parameters have the same dtype).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><cite>torch.dtype</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dummy_inputs">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dummy_inputs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dummy_inputs" title="Permalink to this definition">#</a></dt>
<dd><p>Dummy inputs to do a forward pass in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><cite>Dict[str, torch.Tensor]</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.estimate_tokens">
<span class="sig-name descname"><span class="pre">estimate_tokens</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.estimate_tokens" title="Permalink to this definition">#</a></dt>
<dd><p>Helper function to estimate the total number of tokens from the model inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs</strong> (<cite>dict</cite>)  The model inputs.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The total number of tokens.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><cite>int</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.eval" title="Permalink to this definition">#</a></dt>
<dd><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code>.</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.eval()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.extra_repr" title="Permalink to this definition">#</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.float" title="Permalink to this definition">#</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">float</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.floating_point_ops">
<span class="sig-name descname"><span class="pre">floating_point_ops</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.floating_point_ops" title="Permalink to this definition">#</a></dt>
<dd><p>Get number of (optionally, non-embeddings) floating-point operations for the forward and backward passes of a
batch with this transformer model. Default approximation neglects the quadratic dependency on the number of
tokens (valid if <cite>12 * d_model &lt;&lt; sequence_length</cite>) as laid out in [this
paper](<a class="reference external" href="https://arxiv.org/pdf/2001.08361.pdf">https://arxiv.org/pdf/2001.08361.pdf</a>) section 2.1. Should be overridden for transformers with parameter
re-use e.g. Albert or Universal Transformers, or if doing long-range modeling with very high sequence lengths.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<cite>int</cite>)  The batch size for the forward pass.</p></li>
<li><p><strong>sequence_length</strong> (<cite>int</cite>)  The number of tokens in each line of the batch.</p></li>
<li><p><strong>exclude_embeddings</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>)  Whether or not to count embedding and softmax operations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The number of floating-point operations.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><cite>int</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.framework">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">framework</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.framework" title="Permalink to this definition">#</a></dt>
<dd><p>Identifies that this is a PyTorch model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.from_pretrained">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name_or_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">colbert_config</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.from_pretrained" title="Permalink to this definition">#</a></dt>
<dd><p>Instantiate a pretrained pytorch model from a pre-trained model configuration.</p>
<p>The model is set in evaluation mode by default using <cite>model.eval()</cite> (Dropout modules are deactivated). To train
the model, you should first set it back in training mode with <cite>model.train()</cite>.</p>
<p>The warning <em>Weights from XXX not initialized from pretrained model</em> means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.</p>
<p>The warning <em>Weights from XXX not used in YYY</em> means that the layer XXX is not used by YYY, therefore those
weights are discarded.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pretrained_model_name_or_path</strong> (<cite>str</cite> or <cite>os.PathLike</cite>, <em>optional</em>)  <p>Can be either:</p>
<blockquote>
<div><ul>
<li><p>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <cite>bert-base-uncased</cite>, or namespaced under a
user or organization name, like <cite>dbmdz/bert-base-german-cased</cite>.</p></li>
<li><p>A path to a <em>directory</em> containing model weights saved using
[<cite>~PreTrainedModel.save_pretrained</cite>], e.g., <cite>./my_model_directory/</cite>.</p></li>
<li><p>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <cite>./tf_model/model.ckpt.index</cite>). In
this case, <cite>from_tf</cite> should be set to <cite>True</cite> and a configuration object should be provided as
<cite>config</cite> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</p></li>
<li><p>A path or url to a model folder containing a <em>flax checkpoint file</em> in <em>.msgpack</em> format (e.g,
<cite>./flax_model/</cite> containing <cite>flax_model.msgpack</cite>). In this case, <cite>from_flax</cite> should be set to
<cite>True</cite>.</p></li>
<li><p><cite>None</cite> if you are both providing the configuration and state dictionary (resp. with keyword
arguments <cite>config</cite> and <cite>state_dict</cite>).</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>model_args</strong> (sequence of positional arguments, <em>optional</em>)  All remaining positional arguments will be passed to the underlying models <cite>__init__</cite> method.</p></li>
<li><p><strong>config</strong> (<cite>Union[PretrainedConfig, str, os.PathLike]</cite>, <em>optional</em>)  <p>Can be either:</p>
<blockquote>
<div><ul>
<li><p>an instance of a class derived from [<cite>PretrainedConfig</cite>],</p></li>
<li><p>a string or path valid as input to [<cite>~PretrainedConfig.from_pretrained</cite>].</p></li>
</ul>
</div></blockquote>
<p>Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<blockquote>
<div><ul>
<li><p>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</p></li>
<li><p>The model was saved using [<cite>~PreTrainedModel.save_pretrained</cite>] and is reloaded by supplying the
save directory.</p></li>
<li><p>The model is loaded by supplying a local directory as <cite>pretrained_model_name_or_path</cite> and a
configuration JSON file named <em>config.json</em> is found in the directory.</p></li>
</ul>
</div></blockquote>
</p></li>
<li><p><strong>state_dict</strong> (<cite>Dict[str, torch.Tensor]</cite>, <em>optional</em>)  <p>A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using [<cite>~PreTrainedModel.save_pretrained</cite>] and
[<cite>~PreTrainedModel.from_pretrained</cite>] is not a simpler option.</p>
</p></li>
<li><p><strong>cache_dir</strong> (<cite>Union[str, os.PathLike]</cite>, <em>optional</em>)  Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.</p></li>
<li><p><strong>from_tf</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Load the model weights from a TensorFlow checkpoint save file (see docstring of
<cite>pretrained_model_name_or_path</cite> argument).</p></li>
<li><p><strong>from_flax</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Load the model weights from a Flax checkpoint save file (see docstring of
<cite>pretrained_model_name_or_path</cite> argument).</p></li>
<li><p><strong>ignore_mismatched_sizes</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to raise an error if some of the weights from the checkpoint do not have the same size
as the weights of the model (if for instance, you are instantiating a model with 10 labels from a
checkpoint with 3 labels).</p></li>
<li><p><strong>force_download</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.</p></li>
<li><p><strong>resume_download</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.</p></li>
<li><p><strong>proxies</strong> (<cite>Dict[str, str]</cite>, <em>optional</em>)  A dictionary of proxy servers to use by protocol or endpoint, e.g., <cite>{http: foo.bar:3128,
http://hostname: foo.bar:4012}</cite>. The proxies are used on each request.</p></li>
<li><p><strong>output_loading_info</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.</p></li>
<li><p><strong>local_files_only</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to only look at local files (i.e., do not try to download the model).</p></li>
<li><p><strong>use_auth_token</strong> (<cite>str</cite> or <em>bool</em>, <em>optional</em>)  The token to use as HTTP bearer authorization for remote files. If <cite>True</cite>, will use the token generated
when running <cite>transformers-cli login</cite> (stored in <cite>~/.huggingface</cite>).</p></li>
<li><p><strong>revision</strong> (<cite>str</cite>, <em>optional</em>, defaults to <cite>main</cite>)  The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <cite>revision</cite> can be any
identifier allowed by git.</p></li>
<li><p><strong>mirror</strong> (<cite>str</cite>, <em>optional</em>)  Mirror source to accelerate downloads in China. If you are from China and have an accessibility
problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.
Please refer to the mirror site for more information.</p></li>
<li><p><strong>_fast_init</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <a href="#id13"><span class="problematic" id="id14">``</span></a><cite>True</cite>)  Whether or not to disable fast initialization.</p></li>
<li><p><strong>low_cpu_mem_usage</strong> (<cite>bool`</cite>, <em>optional</em>, defaults to <a href="#id15"><span class="problematic" id="id16">``</span></a><cite>False</cite>)  Tries to not use more than 1x model size in CPU memory (including peak memory) while loading the model.
This is an experimental feature and a subject to change at any moment.</p></li>
<li><p><strong>torch_dtype</strong> (<cite>str</cite> or <cite>torch.dtype</cite>, <em>optional</em>)  <p>Override the default <cite>torch.dtype</cite> and load the model under this dtype. If <cite>auto</cite> is passed the dtype
will be automatically derived from the models weights.</p>
<p>&lt;Tip warning={true}&gt;</p>
<p>One should only disable <em>_fast_init</em> to ensure backwards compatibility with <cite>transformers.__version__ &lt;
4.6.0</cite> for seeded model initialization. This argument will be removed at the next major version. See
[pull request 11471](<a class="reference external" href="https://github.com/huggingface/transformers/pull/11471">https://github.com/huggingface/transformers/pull/11471</a>) for more information.</p>
<p>&lt;/Tip&gt;</p>
</p></li>
<li><p><strong>kwargs</strong> (remaining dictionary of keyword arguments, <em>optional</em>)  <p>Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<cite>output_attentions=True</cite>). Behaves differently depending on whether a <cite>config</cite> is provided or
automatically loaded:</p>
<blockquote>
<div><ul>
<li><p>If a configuration is provided with <cite>config</cite>, <cite>**kwargs</cite> will be directly passed to the
underlying models <cite>__init__</cite> method (we assume all relevant updates to the configuration have
already been done)</p></li>
<li><p>If a configuration is not provided, <cite>kwargs</cite> will be first passed to the configuration class
initialization function ([<cite>~PretrainedConfig.from_pretrained</cite>]). Each key of <cite>kwargs</cite> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <cite>kwargs</cite> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying models <cite>__init__</cite> function.</p></li>
</ul>
</div></blockquote>
</p></li>
</ul>
</dd>
</dl>
<p>&lt;Tip&gt;</p>
<p>Passing <cite>use_auth_token=True`</cite> is required when you want to use a private model.</p>
<p>&lt;/Tip&gt;</p>
<p>&lt;Tip&gt;</p>
<p>Activate the special [offline-mode](<a class="reference external" href="https://huggingface.co/transformers/installation.html#offline-mode">https://huggingface.co/transformers/installation.html#offline-mode</a>) to
use this method in a firewalled environment.</p>
<p>&lt;/Tip&gt;</p>
<p>Examples:</p>
<p><a href="#id17"><span class="problematic" id="id18">``</span></a><a href="#id19"><span class="problematic" id="id20">`</span></a>python
&gt;&gt;&gt; from transformers import BertConfig, BertModel</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Download model and configuration from huggingface.co and cache.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Model was saved using *save_pretrained(&#39;./test/saved_model/&#39;)* (for example purposes, not runnable).</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./test/saved_model/&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Update configuration during loading.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span> <span class="o">==</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading from a TF checkpoint file instead of a PyTorch model (slower, for example purposes, not runnable).</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">config</span> <span class="o">=</span> <span class="n">BertConfig</span><span class="o">.</span><span class="n">from_json_file</span><span class="p">(</span><span class="s2">&quot;./tf_model/my_tf_model_config.json&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./tf_model/my_tf_checkpoint.ckpt.index&quot;</span><span class="p">,</span> <span class="n">from_tf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading from a Flax checkpoint file instead of a PyTorch model (slower)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span> <span class="n">from_flax</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">```</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.generate">
<span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">do_sample</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">early_stopping</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_beams</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">typical_p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repetition_penalty</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bad_words_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">length_penalty</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">no_repeat_ngram_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_no_repeat_ngram_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_return_sequences</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_time</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_new_tokens</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder_start_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cache</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_beam_groups</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diversity_penalty</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix_allowed_tokens_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_processor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_logits_process.LogitsProcessorList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criteria</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_stopping_criteria.StoppingCriteriaList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">constraints</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_beam_constraints.Constraint</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_attentions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_hidden_states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict_in_generate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forced_bos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">forced_eos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_invalid_values</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synced_gpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">model_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_utils.GreedySearchEncoderDecoderOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.GreedySearchDecoderOnlyOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.SampleEncoderDecoderOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.SampleDecoderOnlyOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.BeamSearchEncoderDecoderOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.BeamSearchDecoderOnlyOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.BeamSampleEncoderDecoderOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.BeamSampleDecoderOnlyOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.LongTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.generate" title="Permalink to this definition">#</a></dt>
<dd><p>Generates sequences for models with a language modeling head. The method currently supports greedy decoding,
multinomial sampling, beam-search decoding, and beam-search multinomial sampling.</p>
<p>Apart from <cite>inputs</cite>, all the arguments below will default to the value of the attribute of the same name inside
the [<cite>PretrainedConfig</cite>] of the model. The default values indicated are the default values of those config.</p>
<p>Most of these parameters are explained in more detail in [this blog
post](<a class="reference external" href="https://huggingface.co/blog/how-to-generate">https://huggingface.co/blog/how-to-generate</a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<cite>torch.Tensor</cite> of shape <a href="#id21"><span class="problematic" id="id22">`</span></a>(batch_size, sequence_length)  </p></li>
<li><p><strong>`</strong> (<em>feature_dim</em><em>)</em><em>` or</em>)  The sequence used as a prompt for the generation or as model inputs to the encoder. If <cite>None</cite> the
method initializes it with <cite>bos_token_id</cite> and a batch size of 1. For decoder-only models <cite>inputs</cite>
should of in the format of <cite>input_ids</cite>. For encoder-decoder models <em>inputs</em> can represent any of
<cite>input_ids</cite>, <cite>input_values</cite>, <cite>input_features</cite>, or <cite>pixel_values</cite>.</p></li>
<li><p><strong>max_length</strong> (<cite>int</cite>, <em>optional</em>, defaults to <cite>model.config.max_length</cite>)  The maximum length of the sequence to be generated.</p></li>
<li><p><strong>max_new_tokens</strong> (<cite>int</cite>, <em>optional</em>, defaults to None)  The maximum numbers of tokens to generate, ignore the current number of tokens. Use either
<cite>max_new_tokens</cite> or <cite>max_length</cite> but not both, they serve the same purpose.</p></li>
<li><p><strong>min_length</strong> (<cite>int</cite>, <em>optional</em>, defaults to 10)  The minimum length of the sequence to be generated.</p></li>
<li><p><strong>do_sample</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to use sampling ; use greedy decoding otherwise.</p></li>
<li><p><strong>early_stopping</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether to stop the beam search when at least <cite>num_beams</cite> sentences are finished per batch or not.</p></li>
<li><p><strong>num_beams</strong> (<cite>int</cite>, <em>optional</em>, defaults to 1)  Number of beams for beam search. 1 means no beam search.</p></li>
<li><p><strong>temperature</strong> (<cite>float</cite>, <em>optional</em>, defaults to 1.0)  The value used to module the next token probabilities.</p></li>
<li><p><strong>top_k</strong> (<cite>int</cite>, <em>optional</em>, defaults to 50)  The number of highest probability vocabulary tokens to keep for top-k-filtering.</p></li>
<li><p><strong>top_p</strong> (<cite>float</cite>, <em>optional</em>, defaults to 1.0)  If set to float &lt; 1, only the most probable tokens with probabilities that add up to <cite>top_p</cite> or higher
are kept for generation.</p></li>
<li><p><strong>repetition_penalty</strong> (<cite>float</cite>, <em>optional</em>, defaults to 1.0)  The parameter for repetition penalty. 1.0 means no penalty. See [this
paper](<a class="reference external" href="https://arxiv.org/pdf/1909.05858.pdf">https://arxiv.org/pdf/1909.05858.pdf</a>) for more details.</p></li>
<li><p><strong>pad_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>padding</em> token.</p></li>
<li><p><strong>bos_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>beginning-of-sequence</em> token.</p></li>
<li><p><strong>eos_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>end-of-sequence</em> token.</p></li>
<li><p><strong>length_penalty</strong> (<cite>float</cite>, <em>optional</em>, defaults to 1.0)  Exponential penalty to the length. 1.0 means no penalty. Set to values &lt; 1.0 in order to encourage the
model to generate shorter sequences, to a value &gt; 1.0 in order to encourage the model to produce longer
sequences.</p></li>
<li><p><strong>no_repeat_ngram_size</strong> (<cite>int</cite>, <em>optional</em>, defaults to 0)  If set to int &gt; 0, all ngrams of that size can only occur once.</p></li>
<li><p><strong>encoder_no_repeat_ngram_size</strong> (<cite>int</cite>, <em>optional</em>, defaults to 0)  If set to int &gt; 0, all ngrams of that size that occur in the <cite>encoder_input_ids</cite> cannot occur in the
<cite>decoder_input_ids</cite>.</p></li>
<li><p><strong>bad_words_ids</strong> (<cite>List[List[int]]</cite>, <em>optional</em>)  List of token ids that are not allowed to be generated. In order to get the token ids of the words that
should not appear in the generated text, use <cite>tokenizer(bad_words, add_prefix_space=True,
add_special_tokens=False).input_ids</cite>.</p></li>
<li><p><strong>num_return_sequences</strong> (<cite>int</cite>, <em>optional</em>, defaults to 1)  The number of independently computed returned sequences for each element in the batch.</p></li>
<li><p><strong>max_time</strong> (<cite>float</cite>, <em>optional</em>, defaults to None)  The maximum amount of time you allow the computation to run for in seconds. generation will still
finish the current pass after allocated time has been passed.</p></li>
<li><p><strong>attention_mask</strong> (<cite>torch.LongTensor</cite> of shape <cite>(batch_size, sequence_length)</cite>, <em>optional</em>)  Mask to avoid performing attention on padding token indices. Mask values are in <cite>[0, 1]</cite>, 1 for tokens
that are not masked, and 0 for masked tokens. If not provided, will default to a tensor the same shape
as <cite>input_ids</cite> that masks the pad token. [What are attention masks?](../glossary#attention-mask)</p></li>
<li><p><strong>decoder_start_token_id</strong> (<cite>int</cite>, <em>optional</em>)  If an encoder-decoder model starts decoding with a different token than <em>bos</em>, the id of that token.</p></li>
<li><p><strong>use_cache</strong>  (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>):
Whether or not the model should use the past last key/values attentions (if applicable to the model) to
speed up decoding.</p></li>
<li><p><strong>num_beam_groups</strong> (<cite>int</cite>, <em>optional</em>, defaults to 1)  Number of groups to divide <cite>num_beams</cite> into in order to ensure diversity among different groups of
beams. [this paper](<a class="reference external" href="https://arxiv.org/pdf/1610.02424.pdf">https://arxiv.org/pdf/1610.02424.pdf</a>) for more details.</p></li>
<li><p><strong>diversity_penalty</strong> (<cite>float</cite>, <em>optional</em>, defaults to 0.0)  This value is subtracted from a beams score if it generates a token same as any beam from other group
at a particular time. Note that <cite>diversity_penalty</cite> is only effective if <cite>group beam search</cite> is
enabled.</p></li>
<li><p><strong>prefix_allowed_tokens_fn</strong>  (<cite>Callable[[int, torch.Tensor], List[int]]</cite>, <em>optional</em>):
If provided, this function constraints the beam search to allowed tokens only at each step. If not
provided no constraint is applied. This function takes 2 arguments: the batch ID <cite>batch_id</cite> and
<cite>input_ids</cite>. It has to return a list with the allowed tokens for the next generation step conditioned
on the batch ID <cite>batch_id</cite> and the previously generated tokens <cite>inputs_ids</cite>. This argument is useful
for constrained generation conditioned on the prefix, as described in [Autoregressive Entity
Retrieval](<a class="reference external" href="https://arxiv.org/abs/2010.00904">https://arxiv.org/abs/2010.00904</a>).</p></li>
<li><p><strong>logits_processor</strong> (<cite>LogitsProcessorList</cite>, <em>optional</em>)  Custom logits processors that complement the default logits processors built from arguments and a
models config. If a logit processor is passed that is already created with the arguments or a models
config an error is thrown. This feature is intended for advanced users.</p></li>
<li><p><strong>stopping_criteria</strong> (<cite>StoppingCriteriaList</cite>, <em>optional</em>)  Custom stopping criteria that complement the default stopping criteria built from arguments and a
models config. If a stopping criteria is passed that is already created with the arguments or a
models config an error is thrown. This feature is intended for advanced users.</p></li>
<li><p><strong>constraints</strong> (<cite>List[Constraint]</cite>, <em>optional</em>)  Custom constraints that can be added to the generation to ensure that the output will contain the use
of certain tokens as defined by <cite>Constraint</cite> objects, in the most sensible way possible.</p></li>
<li><p><strong>output_attentions</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the attentions tensors of all attention layers. See <cite>attentions</cite> under
returned tensors for more details.</p></li>
<li><p><strong>output_hidden_states</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the hidden states of all layers. See <cite>hidden_states</cite> under returned tensors
for more details.</p></li>
<li><p><strong>output_scores</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the prediction scores. See <cite>scores</cite> under returned tensors for more details.</p></li>
<li><p><strong>return_dict_in_generate</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return a [<cite>~file_utils.ModelOutput</cite>] instead of a plain tuple.</p></li>
<li><p><strong>forced_bos_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the token to force as the first generated token after the <cite>decoder_start_token_id</cite>. Useful
for multilingual models like [mBART](../model_doc/mbart) where the first generated token needs to be
the target language token.</p></li>
<li><p><strong>forced_eos_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the token to force as the last generated token when <cite>max_length</cite> is reached.</p></li>
<li><p><strong>remove_invalid_values</strong> (<cite>bool</cite>, <em>optional</em>)  Whether to remove possible <em>nan</em> and <em>inf</em> outputs of the model to prevent the generation method to
crash. Note that using <cite>remove_invalid_values</cite> can slow down generation.</p></li>
<li><p><strong>synced_gpus</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether to continue running the while loop until max_length (needed for ZeRO stage 3)</p></li>
<li><p><strong>model_kwargs</strong>  Additional model specific kwargs will be forwarded to the <cite>forward</cite> function of the model. If the model
is an encoder-decoder model, encoder specific kwargs should not be prefixed and decoder specific kwargs
should be prefixed with <em>decoder_</em>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A [<cite>~file_utils.ModelOutput</cite>] (if
<cite>return_dict_in_generate=True</cite> or when <cite>config.return_dict_in_generate=True</cite>) or a <cite>torch.FloatTensor</cite>.</p>
<blockquote>
<div><p>If the model is <em>not</em> an encoder-decoder model (<cite>model.config.is_encoder_decoder=False</cite>), the possible
[<cite>~file_utils.ModelOutput</cite>] types are:</p>
<blockquote>
<div><ul class="simple">
<li><p>[<cite>~generation_utils.GreedySearchDecoderOnlyOutput</cite>],</p></li>
<li><p>[<cite>~generation_utils.SampleDecoderOnlyOutput</cite>],</p></li>
<li><p>[<cite>~generation_utils.BeamSearchDecoderOnlyOutput</cite>],</p></li>
<li><p>[<cite>~generation_utils.BeamSampleDecoderOnlyOutput</cite>]</p></li>
</ul>
</div></blockquote>
<p>If the model is an encoder-decoder model (<cite>model.config.is_encoder_decoder=True</cite>), the possible
[<cite>~file_utils.ModelOutput</cite>] types are:</p>
<blockquote>
<div><ul class="simple">
<li><p>[<cite>~generation_utils.GreedySearchEncoderDecoderOutput</cite>],</p></li>
<li><p>[<cite>~generation_utils.SampleEncoderDecoderOutput</cite>],</p></li>
<li><p>[<cite>~generation_utils.BeamSearchEncoderDecoderOutput</cite>],</p></li>
<li><p>[<cite>~generation_utils.BeamSampleEncoderDecoderOutput</cite>]</p></li>
</ul>
</div></blockquote>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>[<cite>~file_utils.ModelOutput</cite>] or <cite>torch.LongTensor</cite></p>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id23"><span class="problematic" id="id24">``</span></a><a href="#id25"><span class="problematic" id="id26">`</span></a>python
&gt;&gt;&gt; from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilgpt2&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilgpt2&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># do greedy decoding without providing a prompt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">document</span> <span class="o">=</span> <span class="p">(</span>
<span class="gp">... </span>    <span class="s2">&quot;at least two people were killed in a suspected bomb attack on a passenger bus &quot;</span>
<span class="gp">... </span>    <span class="s2">&quot;in the strife-torn southern philippines on monday , the military said.&quot;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># encode input context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">document</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate 3 independent sequences using beam search decoding (5 beams)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># with T5 encoder-decoder model conditioned on short news article.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilgpt2&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilgpt2&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_context</span> <span class="o">=</span> <span class="s2">&quot;The dog&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># encode input context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">input_context</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate 3 candidates using sampling</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;ctrl&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;ctrl&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># &quot;Legal&quot; is one of the control codes for ctrl</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_context</span> <span class="o">=</span> <span class="s2">&quot;Legal My neighbor is&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># encode input context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">input_context</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span> <span class="n">use_fast</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_context</span> <span class="o">=</span> <span class="s2">&quot;My cute dog&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># get tokens of words that should not be generated</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bad_words_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[</span><span class="s2">&quot;idiot&quot;</span><span class="p">,</span> <span class="s2">&quot;stupid&quot;</span><span class="p">,</span> <span class="s2">&quot;shut up&quot;</span><span class="p">],</span> <span class="n">add_prefix_space</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># encode input context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">input_context</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># generate sequences without allowing bad_words to be generated</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bad_words_ids</span><span class="o">=</span><span class="n">bad_words_ids</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go">```</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_buffer" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this methods functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong>  The fully-qualified string name of the buffer
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The buffer referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong>  If the target string references an invalid
    path or resolves to something that is not a
    buffer</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_extended_attention_mask">
<span class="sig-name descname"><span class="pre">get_extended_attention_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">attention_mask:</span> <span class="pre">torch.Tensor,</span> <span class="pre">input_shape:</span> <span class="pre">typing.Tuple[int],</span> <span class="pre">device:</span> <span class="pre">&lt;property</span> <span class="pre">object</span> <span class="pre">at</span> <span class="pre">0x7fcd9e1c3d10&gt;</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_extended_attention_mask" title="Permalink to this definition">#</a></dt>
<dd><p>Makes broadcastable attention and causal masks so that future and masked tokens are ignored.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attention_mask</strong> (<cite>torch.Tensor</cite>)  Mask with ones indicating tokens to attend to, zeros for tokens to ignore.</p></li>
<li><p><strong>input_shape</strong> (<cite>Tuple[int]</cite>)  The shape of the input to the model.</p></li>
<li><p><strong>device</strong>  (<cite>torch.device</cite>):
The device of the input to the model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><cite>torch.Tensor</cite> The extended attention mask, with a the same dtype as <cite>attention_mask.dtype</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Any</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_extra_state" title="Permalink to this definition">#</a></dt>
<dd><p>Returns any extra state to include in the modules state_dict.
Implement this and a corresponding <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.set_extra_state" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.set_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_extra_state()</span></code></a> for your module
if you need to store extra state. This function is called when building the
modules <cite>state_dict()</cite>.</p>
<p>Note that extra state should be pickleable to ensure working serialization
of the state_dict. We only provide provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Any extra state to store in the modules state_dict</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_head_mask">
<span class="sig-name descname"><span class="pre">get_head_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">head_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_hidden_layers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_attention_chunked</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_head_mask" title="Permalink to this definition">#</a></dt>
<dd><p>Prepare the head mask if needed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>head_mask</strong> (<cite>torch.Tensor</cite> with shape <cite>[num_heads]</cite> or <cite>[num_hidden_layers x num_heads]</cite>, <em>optional</em>)  The mask indicating if we should keep the heads or not (1.0 for keep, 0.0 for discard).</p></li>
<li><p><strong>num_hidden_layers</strong> (<cite>int</cite>)  The number of hidden layers in the model.</p></li>
<li><p><strong>is_attention_chunked</strong>  (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>):
Whether or not the attentions scores are computed by chunks or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><cite>torch.Tensor</cite> with shape <cite>[num_hidden_layers x batch x num_heads x seq_length x seq_length]</cite> or list with
<cite>[None]</cite> for each layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_input_embeddings">
<span class="sig-name descname"><span class="pre">get_input_embeddings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.Module</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_input_embeddings" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the models input embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A torch module mapping vocabulary to hidden states.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><cite>nn.Module</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_output_embeddings">
<span class="sig-name descname"><span class="pre">get_output_embeddings</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.Module</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_output_embeddings" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the models output embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A torch module mapping hidden states to vocabulary.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><cite>nn.Module</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_parameter">
<span class="sig-name descname"><span class="pre">get_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.parameter.Parameter</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_parameter" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this methods functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong>  The fully-qualified string name of the Parameter
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Parameter referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Parameter</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong>  If the target string references an invalid
    path or resolves to something that is not an
    <code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.Module</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_submodule" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists,
otherwise throws an error.</p>
<p>For example, lets say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To check whether or not we have the <code class="docutils literal notranslate"><span class="pre">linear</span></code> submodule, we
would call <code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.linear&quot;)</span></code>. To check whether
we have the <code class="docutils literal notranslate"><span class="pre">conv</span></code> submodule, we would call
<code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.net_c.conv&quot;)</span></code>.</p>
<p>The runtime of <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> is bounded by the degree
of module nesting in <code class="docutils literal notranslate"><span class="pre">target</span></code>. A query against
<code class="docutils literal notranslate"><span class="pre">named_modules</span></code> achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists, <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> should always be
used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong>  The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The submodule referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.Module</p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AttributeError</strong>  If the target string references an invalid
    path or resolves to something that is not an
    <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.gradient_checkpointing_disable">
<span class="sig-name descname"><span class="pre">gradient_checkpointing_disable</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.gradient_checkpointing_disable" title="Permalink to this definition">#</a></dt>
<dd><p>Deactivates gradient checkpointing for the current model.</p>
<p>Note that in other frameworks this feature can be referred to as activation checkpointing or checkpoint
activations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.gradient_checkpointing_enable">
<span class="sig-name descname"><span class="pre">gradient_checkpointing_enable</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.gradient_checkpointing_enable" title="Permalink to this definition">#</a></dt>
<dd><p>Activates gradient checkpointing for the current model.</p>
<p>Note that in other frameworks this feature can be referred to as activation checkpointing or checkpoint
activations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.greedy_search">
<span class="sig-name descname"><span class="pre">greedy_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_processor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_logits_process.LogitsProcessorList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criteria</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_stopping_criteria.StoppingCriteriaList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_attentions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_hidden_states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict_in_generate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synced_gpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">model_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_utils.GreedySearchEncoderDecoderOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.GreedySearchDecoderOnlyOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.LongTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.greedy_search" title="Permalink to this definition">#</a></dt>
<dd><p>Generates sequences for models with a language modeling head using greedy decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<cite>torch.LongTensor</cite> of shape <cite>(batch_size, sequence_length)</cite>)  The sequence used as a prompt for the generation.</p></li>
<li><p><strong>logits_processor</strong> (<cite>LogitsProcessorList</cite>, <em>optional</em>)  An instance of [<cite>LogitsProcessorList</cite>]. List of instances of class derived from [<cite>LogitsProcessor</cite>]
used to modify the prediction scores of the language modeling head applied at each generation step.</p></li>
<li><p><strong>stopping_criteria</strong> (<cite>StoppingCriteriaList</cite>, <em>optional</em>)  An instance of [<cite>StoppingCriteriaList</cite>]. List of instances of class derived from [<cite>StoppingCriteria</cite>]
used to tell if the generation loop should stop.</p></li>
<li><p><strong>max_length</strong> (<cite>int</cite>, <em>optional</em>, defaults to 20)  <strong>DEPRECATED</strong>. Use <cite>logits_processor</cite> or <cite>stopping_criteria</cite> directly to cap the number of generated
tokens. The maximum length of the sequence to be generated.</p></li>
<li><p><strong>pad_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>padding</em> token.</p></li>
<li><p><strong>eos_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>end-of-sequence</em> token.</p></li>
<li><p><strong>output_attentions</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the attentions tensors of all attention layers. See <cite>attentions</cite> under
returned tensors for more details.</p></li>
<li><p><strong>output_hidden_states</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the hidden states of all layers. See <cite>hidden_states</cite> under returned tensors
for more details.</p></li>
<li><p><strong>output_scores</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the prediction scores. See <cite>scores</cite> under returned tensors for more details.</p></li>
<li><p><strong>return_dict_in_generate</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return a [<cite>~file_utils.ModelOutput</cite>] instead of a plain tuple.</p></li>
<li><p><strong>synced_gpus</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether to continue running the while loop until max_length (needed for ZeRO stage 3)</p></li>
<li><p><strong>model_kwargs</strong>  Additional model specific keyword arguments will be forwarded to the <cite>forward</cite> function of the model.
If model is an encoder-decoder model the kwargs should include <cite>encoder_outputs</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[<cite>~generation_utils.GreedySearchDecoderOnlyOutput</cite>], [<cite>~generation_utils.GreedySearchEncoderDecoderOutput</cite>]
or <cite>torch.LongTensor</cite>: A <cite>torch.LongTensor</cite> containing the generated tokens (default behaviour) or a
[<cite>~generation_utils.GreedySearchDecoderOnlyOutput</cite>] if <cite>model.config.is_encoder_decoder=False</cite> and
<cite>return_dict_in_generate=True</cite> or a [<cite>~generation_utils.GreedySearchEncoderDecoderOutput</cite>] if
<cite>model.config.is_encoder_decoder=True</cite>.</p>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id27"><span class="problematic" id="id28">``</span></a><a href="#id29"><span class="problematic" id="id30">`</span></a>python
&gt;&gt;&gt; from transformers import (
     AutoTokenizer,
     AutoModelForCausalLM,
     LogitsProcessorList,
     MinLengthLogitsProcessor,
 )</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># set pad_token_id to eos_token_id because GPT2 does not have a EOS token</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_prompt</span> <span class="o">=</span> <span class="s2">&quot;Today is a beautiful day, and&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">input_prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate logits processors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logits_processor</span> <span class="o">=</span> <span class="n">LogitsProcessorList</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[</span>
<span class="gp">... </span>        <span class="n">MinLengthLogitsProcessor</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">),</span>
<span class="gp">... </span>    <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">greedy_search</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">logits_processor</span><span class="o">=</span><span class="n">logits_processor</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go">```</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.group_beam_search">
<span class="sig-name descname"><span class="pre">group_beam_search</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beam_scorer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">transformers.generation_beam_search.BeamScorer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_processor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_logits_process.LogitsProcessorList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criteria</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_stopping_criteria.StoppingCriteriaList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_attentions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_hidden_states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict_in_generate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synced_gpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">model_kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.group_beam_search" title="Permalink to this definition">#</a></dt>
<dd><p>Generates sequences for models with a language modeling head using beam search decoding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<cite>torch.LongTensor</cite> of shape <cite>(batch_size, sequence_length)</cite>)  The sequence used as a prompt for the generation.</p></li>
<li><p><strong>beam_scorer</strong> (<cite>BeamScorer</cite>)  An derived instance of [<cite>BeamScorer</cite>] that defines how beam hypotheses are constructed, stored and
sorted during generation. For more information, the documentation of [<cite>BeamScorer</cite>] should be read.</p></li>
<li><p><strong>logits_processor</strong> (<cite>LogitsProcessorList</cite>, <em>optional</em>)  An instance of [<cite>LogitsProcessorList</cite>]. List of instances of class derived from [<cite>LogitsProcessor</cite>]
used to modify the prediction scores of the language modeling head applied at each generation step.</p></li>
<li><p><strong>stopping_criteria</strong> (<cite>StoppingCriteriaList</cite>, <em>optional</em>)  An instance of [<cite>StoppingCriteriaList</cite>]. List of instances of class derived from [<cite>StoppingCriteria</cite>]
used to tell if the generation loop should stop.</p></li>
<li><p><strong>max_length</strong> (<cite>int</cite>, <em>optional</em>, defaults to 20)  <strong>DEPRECATED</strong>. Use <cite>logits_processor</cite> or <cite>stopping_criteria</cite> directly to cap the number of generated
tokens. The maximum length of the sequence to be generated.</p></li>
<li><p><strong>pad_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>padding</em> token.</p></li>
<li><p><strong>eos_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>end-of-sequence</em> token.</p></li>
<li><p><strong>output_attentions</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the attentions tensors of all attention layers. See <cite>attentions</cite> under
returned tensors for more details.</p></li>
<li><p><strong>output_hidden_states</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the hidden states of all layers. See <cite>hidden_states</cite> under returned tensors
for more details.</p></li>
<li><p><strong>output_scores</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the prediction scores. See <cite>scores</cite> under returned tensors for more details.</p></li>
<li><p><strong>return_dict_in_generate</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return a [<cite>~file_utils.ModelOutput</cite>] instead of a plain tuple.</p></li>
<li><p><strong>synced_gpus</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether to continue running the while loop until max_length (needed for ZeRO stage 3)</p></li>
<li><p><strong>model_kwargs</strong>  Additional model specific kwargs that will be forwarded to the <cite>forward</cite> function of the model. If
model is an encoder-decoder model the kwargs should include <cite>encoder_outputs</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[<cite>~generation_utils.BeamSearchDecoderOnlyOutput</cite>], [<cite>~generation_utils.BeamSearchEncoderDecoderOutput</cite>] or
<cite>torch.LongTensor</cite>: A <cite>torch.LongTensor</cite> containing the generated tokens (default behaviour) or a
[<cite>~generation_utils.BeamSearchDecoderOnlyOutput</cite>] if [<cite>~generation_utils.BeamSearchDecoderOnlyOutput</cite>] if
<cite>model.config.is_encoder_decoder=False</cite> and <cite>return_dict_in_generate=True</cite> or a
[<cite>~generation_utils.BeamSearchEncoderDecoderOutput</cite>] if <cite>model.config.is_encoder_decoder=True</cite>.</p>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id31"><span class="problematic" id="id32">``</span></a><a href="#id33"><span class="problematic" id="id34">`</span></a>python
&gt;&gt;&gt; from transformers import (
     AutoTokenizer,
     AutoModelForSeq2SeqLM,
     LogitsProcessorList,
     MinLengthLogitsProcessor,
     HammingDiversityLogitsProcessor,
     BeamSearchScorer,
 )
&gt;&gt;&gt; import torch</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;t5-base&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_input_str</span> <span class="o">=</span> <span class="s2">&quot;translate English to German: How old are you?&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">encoder_input_str</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># lets run diverse beam search using 6 beams</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">num_beams</span> <span class="o">=</span> <span class="mi">6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># define decoder start token ids</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_beams</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_start_token_id</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># add encoder_outputs to model keyword arguments</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span>
<span class="gp">... </span>    <span class="s2">&quot;encoder_outputs&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">get_encoder</span><span class="p">()(</span>
<span class="gp">... </span>        <span class="n">encoder_input_ids</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">num_beams</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span>    <span class="p">)</span>
<span class="gp">... </span><span class="p">}</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate beam scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">beam_scorer</span> <span class="o">=</span> <span class="n">BeamSearchScorer</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">max_length</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">num_beams</span><span class="o">=</span><span class="n">num_beams</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">num_beam_groups</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate logits processors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logits_processor</span> <span class="o">=</span> <span class="n">LogitsProcessorList</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[</span>
<span class="gp">... </span>        <span class="n">HammingDiversityLogitsProcessor</span><span class="p">(</span><span class="mf">5.5</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">num_beam_groups</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
<span class="gp">... </span>        <span class="n">MinLengthLogitsProcessor</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">),</span>
<span class="gp">... </span>    <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">group_beam_search</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">input_ids</span><span class="p">,</span> <span class="n">beam_scorer</span><span class="p">,</span> <span class="n">logits_processor</span><span class="o">=</span><span class="n">logits_processor</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go">```</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.half" title="Permalink to this definition">#</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">half</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.init_weights">
<span class="sig-name descname"><span class="pre">init_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.init_weights" title="Permalink to this definition">#</a></dt>
<dd><p>If needed prunes and maybe initializes weights.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.invert_attention_mask">
<span class="sig-name descname"><span class="pre">invert_attention_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder_attention_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.invert_attention_mask" title="Permalink to this definition">#</a></dt>
<dd><p>Invert an attention mask (e.g., switches 0. and 1.).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>encoder_attention_mask</strong> (<cite>torch.Tensor</cite>)  An attention mask.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The inverted attention mask.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><cite>torch.Tensor</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.is_gradient_checkpointing">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">is_gradient_checkpointing</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.is_gradient_checkpointing" title="Permalink to this definition">#</a></dt>
<dd><p>Whether gradient checkpointing is activated for this model or not.</p>
<p>Note that in other frameworks this feature can be referred to as activation checkpointing or checkpoint
activations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">collections.OrderedDict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Copies parameters and buffers from <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into
this module and its descendants. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this modules <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<em>dict</em>)  a dict containing parameters and
persistent buffers.</p></li>
<li><p><strong>strict</strong> (<em>bool</em><em>, </em><em>optional</em>)  whether to strictly enforce that the keys
in <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this modules
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>missing_keys</strong> is a list of str containing the missing keys</p></li>
<li><p><strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a parameter or buffer is registered as <code class="docutils literal notranslate"><span class="pre">None</span></code> and its corresponding key
exists in <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>, <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> will raise a
<code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_tf_weights">
<span class="sig-name descname"><span class="pre">load_tf_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tf_checkpoint_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_tf_weights" title="Permalink to this definition">#</a></dt>
<dd><p>Load tf checkpoints in a pytorch model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.modules" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an iterator over all modules in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em>  a module in the network</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="go">        print(idx, &#39;-&gt;&#39;, m)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_buffers" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>)  prefix to prepend to all buffer names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>)  if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(string, torch.Tensor)</em>  Tuple containing the name and buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_children">
<span class="sig-name descname"><span class="pre">named_children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_children" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>(string, Module)</em>  Tuple containing a name and child module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_modules">
<span class="sig-name descname"><span class="pre">named_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Set</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_modules" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>memo</strong>  a memo to store the set of modules already added to the result</p></li>
<li><p><strong>prefix</strong>  a prefix that will be added to the name of the module</p></li>
<li><p><strong>remove_duplicate</strong>  whether to remove the duplicated module instances in the result
or not</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(string, Module)</em>  Tuple of name and module</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="go">        print(idx, &#39;-&gt;&#39;, m)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.nn.parameter.Parameter</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.named_parameters" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<em>str</em>)  prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<em>bool</em>)  if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(string, Parameter)</em>  Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.num_parameters">
<span class="sig-name descname"><span class="pre">num_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">only_trainable</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude_embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.num_parameters" title="Permalink to this definition">#</a></dt>
<dd><p>Get number of (optionally, trainable or non-embeddings) parameters in the module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>only_trainable</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return only the number of trainable parameters</p></li>
<li><p><strong>exclude_embeddings</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return only the number of non-embeddings parameters</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The number of parameters.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><cite>int</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Iterator</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.parameter.Parameter</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.parameters" title="Permalink to this definition">#</a></dt>
<dd><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<em>bool</em>)  if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>Parameter</em>  module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.post_init">
<span class="sig-name descname"><span class="pre">post_init</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.post_init" title="Permalink to this definition">#</a></dt>
<dd><p>A method executed at the end of each Transformer model initialization, to execute code that needs the models
modules properly initialized (such as weight initialization).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.prepare_inputs_for_generation">
<span class="sig-name descname"><span class="pre">prepare_inputs_for_generation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.prepare_inputs_for_generation" title="Permalink to this definition">#</a></dt>
<dd><p>Implement in subclasses of [<cite>PreTrainedModel</cite>] for custom behavior to prepare inputs in the generate method.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.prune_heads">
<span class="sig-name descname"><span class="pre">prune_heads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">heads_to_prune</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.prune_heads" title="Permalink to this definition">#</a></dt>
<dd><p>Prunes heads of the base model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>heads_to_prune</strong> (<cite>Dict[int, List[int]]</cite>)  Dictionary with keys being selected layer indices (<cite>int</cite>) and associated values being the list of heads
to prune in said layer (list of <cite>int</cite>). For instance {1: [0, 2], 2: [2, 3]} will prune heads 0 and 2 on
layer 1 and heads 2 and 3 on layer 2.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.push_to_hub">
<span class="sig-name descname"><span class="pre">push_to_hub</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">repo_path_or_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repo_url</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_temp_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">commit_message</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">organization</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">private</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_auth_token</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">model_card_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.push_to_hub" title="Permalink to this definition">#</a></dt>
<dd><p>Upload the model checkpoint to the  Model Hub while synchronizing a local clone of the repo in
<cite>repo_path_or_name</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>repo_path_or_name</strong> (<cite>str</cite>, <em>optional</em>)  Can either be a repository name for your model in the Hub or a path to a local folder (in which case
the repository will have the name of that local folder). If not specified, will default to the name
given by <cite>repo_url</cite> and a local directory with that name will be created.</p></li>
<li><p><strong>repo_url</strong> (<cite>str</cite>, <em>optional</em>)  Specify this in case you want to push to an existing repository in the hub. If unspecified, a new
repository will be created in your namespace (unless you specify an <cite>organization</cite>) with <cite>repo_name</cite>.</p></li>
<li><p><strong>use_temp_dir</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to clone the distant repo in a temporary directory or in <cite>repo_path_or_name</cite> inside the
current working directory. This will slow things down if you are making changes in an existing repo
since you will need to clone the repo before every push.</p></li>
<li><p><strong>commit_message</strong> (<cite>str</cite>, <em>optional</em>)  Message to commit while pushing. Will default to <cite>add model</cite>.</p></li>
<li><p><strong>organization</strong> (<cite>str</cite>, <em>optional</em>)  Organization in which you want to push your model (you must be a member of this organization).</p></li>
<li><p><strong>private</strong> (<cite>bool</cite>, <em>optional</em>)  Whether or not the repository created should be private (requires a paying subscription).</p></li>
<li><p><strong>use_auth_token</strong> (<cite>bool</cite> or <cite>str</cite>, <em>optional</em>)  The token to use as HTTP bearer authorization for remote files. If <cite>True</cite>, will use the token generated
when running <cite>transformers-cli login</cite> (stored in <cite>~/.huggingface</cite>). Will default to <cite>True</cite> if
<cite>repo_url</cite> is not specified.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The url of the commit of your model in the given repository.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><cite>str</cite></p>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id35"><span class="problematic" id="id36">``</span></a><a href="#id37"><span class="problematic" id="id38">`</span></a>python
from transformers import AutoModel</p>
<p>model = AutoModel.from_pretrained(bert-base-cased)</p>
<p># Push the model to your namespace with the name my-finetuned-bert and have a local clone in the
# <em>my-finetuned-bert</em> folder.
model.push_to_hub(my-finetuned-bert)</p>
<p># Push the model to your namespace with the name my-finetuned-bert with no local clone.
model.push_to_hub(my-finetuned-bert, use_temp_dir=True)</p>
<p># Push the model to an organization with the name my-finetuned-bert and have a local clone in the
# <em>my-finetuned-bert</em> folder.
model.push_to_hub(my-finetuned-bert, organization=huggingface)</p>
<p># Make a change to an existing repo that has been cloned locally in <em>my-finetuned-bert</em>.
model.push_to_hub(my-finetuned-bert, repo_url=<a class="reference external" href="https://huggingface.co/sgugger/my-finetuned-bert">https://huggingface.co/sgugger/my-finetuned-bert</a>)
<a href="#id39"><span class="problematic" id="id40">``</span></a><a href="#id41"><span class="problematic" id="id42">`</span></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.hooks.RemovableHandle</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_backward_hook" title="Permalink to this definition">#</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>This function is deprecated in favor of <code class="xref py py-meth docutils literal notranslate"><span class="pre">register_full_backward_hook()</span></code> and
the behavior of this function will change in future versions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_buffer" title="Permalink to this definition">#</a></dt>
<dd><p>Adds a buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorms <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the modules state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">persistent</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this modules
<a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>string</em>)  name of the buffer. The buffer can be accessed
from this module using the given name</p></li>
<li><p><strong>tensor</strong> (<em>Tensor</em><em> or </em><em>None</em>)  buffer to be registered. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations
that run on buffers, such as <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cuda" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>, are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
the buffer is <strong>not</strong> included in the modules <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
<li><p><strong>persistent</strong> (<em>bool</em>)  whether the buffer is part of this modules
<a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_for_auto_class">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">register_for_auto_class</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">auto_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'AutoModel'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_for_auto_class" title="Permalink to this definition">#</a></dt>
<dd><p>Register this class with a given auto class. This should only be used for custom models as the ones in the
library are already mapped with an auto class.</p>
<p>&lt;Tip warning={true}&gt;</p>
<p>This API is experimental and may have some slight breaking changes in the next releases.</p>
<p>&lt;/Tip&gt;</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>auto_class</strong> (<cite>str</cite> or <cite>type</cite>, <em>optional</em>, defaults to <cite>AutoModel</cite>)  The auto class to register this new model with.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.hooks.RemovableHandle</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_forward_hook" title="Permalink to this definition">#</a></dt>
<dd><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.forward" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.
It should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>The input contains only the positional arguments given to the module.
Keyword arguments wont be passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>.
The hook can modify the output. It can modify the input inplace but
it will not have effect on forward since this is called after
<a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.forward" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.hooks.RemovableHandle</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_forward_pre_hook" title="Permalink to this definition">#</a></dt>
<dd><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.forward" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.
It should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>The input contains only the positional arguments given to the module.
Keyword arguments wont be passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>.
The hook can modify the input. User can either return a tuple or a
single modified value in the hook. We will wrap the value into a tuple
if a single value is returned(unless that value is already a tuple).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.hooks.RemovableHandle</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_full_backward_hook" title="Permalink to this definition">#</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to module
inputs are computed. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in
subsequent computations. <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for all non-Tensor
arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Modules forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_module">
<span class="sig-name descname"><span class="pre">register_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_module" title="Permalink to this definition">#</a></dt>
<dd><p>Alias for <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_module" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_parameter">
<span class="sig-name descname"><span class="pre">register_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.parameter.Parameter</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.register_parameter" title="Permalink to this definition">#</a></dt>
<dd><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>string</em>)  name of the parameter. The parameter can be accessed
from this module using the given name</p></li>
<li><p><strong>param</strong> (<em>Parameter</em><em> or </em><em>None</em>)  parameter to be added to the module. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations that run on parameters, such as <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cuda" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>,
are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the parameter is <strong>not</strong> included in the
modules <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.requires_grad_" title="Permalink to this definition">#</a></dt>
<dd><p>Change if autograd should record operations on parameters in this
module.</p>
<p>This method sets the parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<p>See <span class="xref std std-ref">locally-disable-grad-doc</span> for a comparison between
<cite>.requires_grad_()</cite> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<em>bool</em>)  whether autograd should record operations on
parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.reset_memory_hooks_state">
<span class="sig-name descname"><span class="pre">reset_memory_hooks_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.reset_memory_hooks_state" title="Permalink to this definition">#</a></dt>
<dd><p>Reset the <cite>mem_rss_diff</cite> attribute of each module (see [<cite>~modeling_utils.ModuleUtilsMixin.add_memory_hooks</cite>]).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.resize_token_embeddings">
<span class="sig-name descname"><span class="pre">resize_token_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_num_tokens</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.sparse.Embedding</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.resize_token_embeddings" title="Permalink to this definition">#</a></dt>
<dd><p>Resizes input token embeddings matrix of the model if <cite>new_num_tokens != config.vocab_size</cite>.</p>
<p>Takes care of tying weights embeddings afterwards if the model class has a <cite>tie_weights()</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>new_num_tokens</strong> (<cite>int</cite>, <em>optional</em>)  The number of new tokens in the embedding matrix. Increasing the size will add newly initialized
vectors at the end. Reducing the size will remove vectors from the end. If not provided or <cite>None</cite>, just
returns a pointer to the input tokens <cite>torch.nn.Embedding</cite> module of the model without doing anything.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Pointer to the input tokens Embeddings Module of the model.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><cite>torch.nn.Embedding</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_processor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_logits_process.LogitsProcessorList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_criteria</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_stopping_criteria.StoppingCriteriaList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits_warper</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_logits_process.LogitsProcessorList</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos_token_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_attentions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_hidden_states</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_scores</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_dict_in_generate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">synced_gpus</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">model_kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers.generation_utils.SampleEncoderDecoderOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">transformers.generation_utils.SampleDecoderOnlyOutput</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.LongTensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.sample" title="Permalink to this definition">#</a></dt>
<dd><p>Generates sequences for models with a language modeling head using multinomial sampling.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_ids</strong> (<cite>torch.LongTensor</cite> of shape <cite>(batch_size, sequence_length)</cite>)  The sequence used as a prompt for the generation.</p></li>
<li><p><strong>logits_processor</strong> (<cite>LogitsProcessorList</cite>, <em>optional</em>)  An instance of [<cite>LogitsProcessorList</cite>]. List of instances of class derived from [<cite>LogitsProcessor</cite>]
used to modify the prediction scores of the language modeling head applied at each generation step.</p></li>
<li><p><strong>stopping_criteria</strong> (<cite>StoppingCriteriaList</cite>, <em>optional</em>)  An instance of [<cite>StoppingCriteriaList</cite>]. List of instances of class derived from [<cite>StoppingCriteria</cite>]
used to tell if the generation loop should stop.</p></li>
<li><p><strong>logits_warper</strong> (<cite>LogitsProcessorList</cite>, <em>optional</em>)  An instance of [<cite>LogitsProcessorList</cite>]. List of instances of class derived from [<cite>LogitsWarper</cite>] used
to warp the prediction score distribution of the language modeling head applied before multinomial
sampling at each generation step.</p></li>
<li><p><strong>max_length</strong> (<cite>int</cite>, <em>optional</em>, defaults to 20)  <strong>DEPRECATED</strong>. Use <cite>logits_processor</cite> or <cite>stopping_criteria</cite> directly to cap the number of generated
tokens. The maximum length of the sequence to be generated.</p></li>
<li><p><strong>pad_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>padding</em> token.</p></li>
<li><p><strong>eos_token_id</strong> (<cite>int</cite>, <em>optional</em>)  The id of the <em>end-of-sequence</em> token.</p></li>
<li><p><strong>output_attentions</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the attentions tensors of all attention layers. See <cite>attentions</cite> under
returned tensors for more details.</p></li>
<li><p><strong>output_hidden_states</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the hidden states of all layers. See <cite>hidden_states</cite> under returned tensors
for more details.</p></li>
<li><p><strong>output_scores</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return the prediction scores. See <cite>scores</cite> under returned tensors for more details.</p></li>
<li><p><strong>return_dict_in_generate</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether or not to return a [<cite>~file_utils.ModelOutput</cite>] instead of a plain tuple.</p></li>
<li><p><strong>synced_gpus</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  Whether to continue running the while loop until max_length (needed for ZeRO stage 3)</p></li>
<li><p><strong>model_kwargs</strong>  Additional model specific kwargs will be forwarded to the <cite>forward</cite> function of the model. If model is
an encoder-decoder model the kwargs should include <cite>encoder_outputs</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[<cite>~generation_utils.SampleDecoderOnlyOutput</cite>], [<cite>~generation_utils.SampleEncoderDecoderOutput</cite>] or
<cite>torch.LongTensor</cite>: A <cite>torch.LongTensor</cite> containing the generated tokens (default behaviour) or a
[<cite>~generation_utils.SampleDecoderOnlyOutput</cite>] if <cite>model.config.is_encoder_decoder=False</cite> and
<cite>return_dict_in_generate=True</cite> or a [<cite>~generation_utils.SampleEncoderDecoderOutput</cite>] if
<cite>model.config.is_encoder_decoder=True</cite>.</p>
</dd>
</dl>
<p>Examples:</p>
<p><a href="#id43"><span class="problematic" id="id44">``</span></a><a href="#id45"><span class="problematic" id="id46">`</span></a>python
&gt;&gt;&gt; from transformers import (
     AutoTokenizer,
     AutoModelForCausalLM,
     LogitsProcessorList,
     MinLengthLogitsProcessor,
     TopKLogitsWarper,
     TemperatureLogitsWarper,
 )</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># set pad_token_id to eos_token_id because GPT2 does not have a EOS token</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input_prompt</span> <span class="o">=</span> <span class="s2">&quot;Today is a beautiful day, and&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">input_prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate logits processors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logits_processor</span> <span class="o">=</span> <span class="n">LogitsProcessorList</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[</span>
<span class="gp">... </span>        <span class="n">MinLengthLogitsProcessor</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">eos_token_id</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">),</span>
<span class="gp">... </span>    <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># instantiate logits processors</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logits_warper</span> <span class="o">=</span> <span class="n">LogitsProcessorList</span><span class="p">(</span>
<span class="gp">... </span>    <span class="p">[</span>
<span class="gp">... </span>        <span class="n">TopKLogitsWarper</span><span class="p">(</span><span class="mi">50</span><span class="p">),</span>
<span class="gp">... </span>        <span class="n">TemperatureLogitsWarper</span><span class="p">(</span><span class="mf">0.7</span><span class="p">),</span>
<span class="gp">... </span>    <span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">logits_processor</span><span class="o">=</span><span class="n">logits_processor</span><span class="p">,</span> <span class="n">logits_warper</span><span class="o">=</span><span class="n">logits_warper</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated:&quot;</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go">```</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.save_pretrained">
<span class="sig-name descname"><span class="pre">save_pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">save_directory:</span> <span class="pre">typing.Union[str,</span> <span class="pre">os.PathLike],</span> <span class="pre">save_config:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True,</span> <span class="pre">state_dict:</span> <span class="pre">typing.Optional[dict]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">save_function:</span> <span class="pre">typing.Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">save&gt;,</span> <span class="pre">push_to_hub:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">**kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.save_pretrained" title="Permalink to this definition">#</a></dt>
<dd><p>Save a model and its configuration file to a directory, so that it can be re-loaded using the
<cite>[`~PreTrainedModel.from_pretrained</cite>]` class method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_directory</strong> (<cite>str</cite> or <cite>os.PathLike</cite>)  Directory to which to save. Will be created if it doesnt exist.</p></li>
<li><p><strong>save_config</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>True</cite>)  Whether or not to save the config of the model. Useful when in distributed training like TPUs and need
to call this function on all processes. In this case, set <cite>save_config=True</cite> only on the main process
to avoid race conditions.</p></li>
<li><p><strong>state_dict</strong> (nested dictionary of <cite>torch.Tensor</cite>)  The state dictionary of the model to save. Will default to <cite>self.state_dict()</cite>, but can be used to only
save parts of the model or if special precautions need to be taken when recovering the state dictionary
of a model (like when using model parallelism).</p></li>
<li><p><strong>save_function</strong> (<cite>Callable</cite>)  The function to use to save the state dictionary. Useful on distributed training like TPUs when one
need to replace <cite>torch.save</cite> by another method.</p></li>
<li><p><strong>push_to_hub</strong> (<cite>bool</cite>, <em>optional</em>, defaults to <cite>False</cite>)  <p>Whether or not to push your model to the Hugging Face model hub after saving it.</p>
<p>&lt;Tip warning={true}&gt;</p>
<p>Using <cite>push_to_hub=True</cite> will synchronize the repository you are pushing to with <cite>save_directory</cite>,
which requires <cite>save_directory</cite> to be a local clone of the repo you are pushing to if its an existing
folder. Pass along <cite>temp_dir=True</cite> to use a temporary directory instead.</p>
<p>&lt;/Tip&gt;</p>
</p></li>
<li><p><strong>kwargs</strong>  Additional key word arguments passed along to the [<cite>~file_utils.PushToHubMixin.push_to_hub</cite>] method.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.set_extra_state" title="Permalink to this definition">#</a></dt>
<dd><p>This function is called from <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state
found within the <cite>state_dict</cite>. Implement this function and a corresponding
<a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_extra_state" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.get_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_extra_state()</span></code></a> for your module if you need to store extra state within its
<cite>state_dict</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>state</strong> (<em>dict</em>)  Extra state from the <cite>state_dict</cite></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.set_input_embeddings">
<span class="sig-name descname"><span class="pre">set_input_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.set_input_embeddings" title="Permalink to this definition">#</a></dt>
<dd><p>Set models input embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>value</strong> (<cite>nn.Module</cite>)  A module mapping vocabulary to hidden states.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.share_memory">
<span class="sig-name descname"><span class="pre">share_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.share_memory" title="Permalink to this definition">#</a></dt>
<dd><p>See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.state_dict" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a dictionary containing a whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to <code class="docutils literal notranslate"><span class="pre">None</span></code> are not included.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary containing a whole state of the module</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>dict</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.tie_weights">
<span class="sig-name descname"><span class="pre">tie_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.tie_weights" title="Permalink to this definition">#</a></dt>
<dd><p>Tie the weights between the input embeddings and the output embeddings.</p>
<p>If the <cite>torchscript</cite> flag is set in the configuration, cant handle parameter sharing so we are cloning the
weights instead.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.to" title="Permalink to this definition">#</a></dt>
<dd><p>Moves and/or casts the parameters and buffers.</p>
<p>This can be called as</p>
<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memory_format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.channels_last</span></span></em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Its signature is similar to <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code>, but only accepts
floating point or complex <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dtype" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dtype"><code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code></a>s. In addition, this method will
only cast the floating point or complex parameters and buffers to <a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dtype" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.dtype"><code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code></a>
(if given). The integral parameters and buffers will be moved
<a class="reference internal" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.device" title="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.device"><code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code></a>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>See below for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>)  the desired device of the parameters
and buffers in this module</p></li>
<li><p><strong>dtype</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code>)  the desired floating point or complex dtype of
the parameters and buffers in this module</p></li>
<li><p><strong>tensor</strong> (<em>torch.Tensor</em>)  Tensor whose dtype and device are the desired
dtype and device for all parameters and buffers in this module</p></li>
<li><p><strong>memory_format</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.memory_format</span></code>)  the desired memory
format for 4D parameters and buffers in this module (keyword
only argument)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gpu1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">gpu1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16, device=&#39;cuda:1&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.3741+0.j,  0.2382+0.j],</span>
<span class="go">        [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cdouble</span><span class="p">))</span>
<span class="go">tensor([[0.6122+0.j, 0.1150+0.j],</span>
<span class="go">        [0.6122+0.j, 0.1150+0.j],</span>
<span class="go">        [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.device</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.to_empty" title="Permalink to this definition">#</a></dt>
<dd><p>Moves the parameters and buffers to the specified device without copying storage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>)  The desired device of the parameters
and buffers in this module.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.train" title="Permalink to this definition">#</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>)  whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.type">
<span class="sig-name descname"><span class="pre">type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.dtype</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.type" title="Permalink to this definition">#</a></dt>
<dd><p>Casts all parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dst_type</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dst_type</strong> (<em>type</em><em> or </em><em>string</em>)  the desired type</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.device</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.nn.modules.module.T</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.xpu" title="Permalink to this definition">#</a></dt>
<dd><p>Moves all model parameters and buffers to the XPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<em>int</em><em>, </em><em>optional</em>)  if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#primeqa.ir.dense.colbert_top.colbert.modeling.hf_colbert.HF_ColBERT.zero_grad" title="Permalink to this definition">#</a></dt>
<dd><p>Sets gradients of all model parameters to zero. See similar function
under <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code> for more context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>set_to_none</strong> (<em>bool</em>)  instead of setting to zero, set the grads to None.
See <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code> for details.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>


              </article>
              

              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
</div>
</footer>
  </body>
</html>